{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Session 5: Generative Models\n",
    "\n",
    "<p class=\"lead\">\n",
    "<a href=\"https://www.kadenze.com/courses/creative-applications-of-deep-learning-with-tensorflow/info\">Creative Applications of Deep Learning with Google's Tensorflow</a><br />\n",
    "<a href=\"http://pkmital.com\">Parag K. Mital</a><br />\n",
    "<a href=\"https://www.kadenze.com\">Kadenze, Inc.</a>\n",
    "</p>\n",
    "\n",
    "<a name=\"learning-goals\"></a>\n",
    "## Learning Goals\n",
    "\n",
    "\n",
    "<!-- MarkdownTOC autolink=true autoanchor=true bracket=round -->\n",
    "\n",
    "- [Introduction](#introduction)\n",
    "- [Generative Adversarial Networks](#generative-adversarial-networks)\n",
    "    - [Input Pipelines](#input-pipelines)\n",
    "    - [GAN/DCGAN](#gandcgan)\n",
    "    - [Extensions](#extensions)\n",
    "- [Recurrent Networks](#recurrent-networks)\n",
    "    - [Basic RNN Cell](#basic-rnn-cell)\n",
    "    - [LSTM RNN Cell](#lstm-rnn-cell)\n",
    "    - [GRU RNN Cell](#gru-rnn-cell)\n",
    "- [Character Langauge Model](#character-langauge-model)\n",
    "    - [Setting up the Data](#setting-up-the-data)\n",
    "    - [Creating the Model](#creating-the-model)\n",
    "    - [Loss](#loss)\n",
    "    - [Clipping the Gradient](#clipping-the-gradient)\n",
    "    - [Training](#training)\n",
    "    - [Extensions](#extensions-1)\n",
    "- [DRAW Network](#draw-network)\n",
    "- [Future](#future)\n",
    "- [Homework](#homework)\n",
    "- [Examples](#examples)\n",
    "- [Reading](#reading)\n",
    "\n",
    "<!-- /MarkdownTOC -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# First check the Python version\n",
    "import sys\n",
    "if sys.version_info < (3,4):\n",
    "    print('You are running an older version of Python!\\n\\n',\n",
    "          'You should consider updating to Python 3.4.0 or',\n",
    "          'higher as the libraries built for this course',\n",
    "          'have only been tested in Python 3.4 and higher.\\n')\n",
    "    print('Try installing the Python 3.5 version of anaconda'\n",
    "          'and then restart `jupyter notebook`:\\n',\n",
    "          'https://www.continuum.io/downloads\\n\\n')\n",
    "\n",
    "# Now get necessary libraries\n",
    "try:\n",
    "    import os\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from skimage.transform import resize\n",
    "    from skimage import data\n",
    "    from scipy.misc import imresize\n",
    "    from scipy.ndimage.filters import gaussian_filter\n",
    "    import IPython.display as ipyd\n",
    "    import tensorflow as tf\n",
    "    from libs import utils, gif, datasets, dataset_utils, nb_utils\n",
    "except ImportError as e:\n",
    "    print(\"Make sure you have started notebook in the same directory\",\n",
    "          \"as the provided zip file which includes the 'libs' folder\",\n",
    "          \"and the file 'utils.py' inside of it.  You will NOT be able\",\n",
    "          \"to complete this assignment unless you restart jupyter\",\n",
    "          \"notebook inside the directory created by extracting\",\n",
    "          \"the zip file or cloning the github repo.\")\n",
    "    print(e)\n",
    "\n",
    "# We'll tell matplotlib to inline any drawn figures like so:\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style> .rendered_html code { \n",
       "    padding: 2px 4px;\n",
       "    color: #c7254e;\n",
       "    background-color: #f9f2f4;\n",
       "    border-radius: 4px;\n",
       "} </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bit of formatting because I don't like the default inline code style:\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"\"\"<style> .rendered_html code { \n",
    "    padding: 2px 4px;\n",
    "    color: #c7254e;\n",
    "    background-color: #f9f2f4;\n",
    "    border-radius: 4px;\n",
    "} </style>\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a name=\"introduction\"></a>\n",
    "# Introduction\n",
    "\n",
    "So far we've seen the basics of neural networks, how they can be used for encoding large datasets, or for predicting labels.  We've also seen how to interrogate the deeper representations that networks learn in order to help with their objective, and how amplifying some of these objectives led to creating deep dream.  Finally, we saw how the representations in deep nets trained on object recognition are capable of representing both style and content, and how we could independently manipulate a new image to have the style of one image, and the content of another.\n",
    "\n",
    "In this session we'll start to explore some more generative models.  We've already seen how an autoencoder is composed of both an encoder which takes an input and represents it into some hidden state vector.  From this hidden state vector, a decoder is capable of resynthesizing the original input, though with some loss.  So think back to the decoders that we've already built.  It has an internal state, and from that state, it can express the entire distribution of the original data, that is, it can express any possible image that is has seen.\n",
    "\n",
    "**We call that a generative model as it is capable of generating the distribution of the data.  Contrast this to the latter half of Session 3 when we saw how we label an image using supervised learning.  This model is really trying to discriminate the data distribution based on the extra labels that we have.  So this is another helpful distinction with machine learning algorithms, ones that are generative and others that are discriminative.**\n",
    "\n",
    "In this session, we'll explore more generative models, and states can be used to generate data in two other very powerful generative networks, one based on game theory called the generative adversarial network, and another capable of remembering and forgetting over time, allowing us to model dynamic content and sequences, called the recurrent neural network.\n",
    "\n",
    "<a name=\"generative-adversarial-networks\"></a>\n",
    "# Generative Adversarial Networks\n",
    "\n",
    "In session 3, we were briefly introduced to the Variational Autoencoder.  This network was very powerful because it encompasses a very strong idea.  And that idea is measuring distance not necessarily based on pixels, but in some \"semantic space\".  And I mentioned then that we'd see another type of network capable of generating even better images of CelebNet.\n",
    "\n",
    "So this is where we're heading...\n",
    "\n",
    "We're now going to see how to do that using what's called the generative adversarial network.\n",
    "\n",
    "The generative adversarial network is actually two networks.  One called the generator, and another called the discriminator.  The basic idea is the generator is trying to create things which look like the training data.  So for images, more images that look like the training data.  The discriminator has to guess whether what its given is a real training example.  Or whether its the output of the generator.  By training one after another, you ensure neither are ever too strong, but both grow stronger together.  The discriminator is also learning a distance function!  This is pretty cool because we no longer need to measure pixel-based distance, but we learn the distance function entirely!\n",
    "\n",
    "The Generative Adversarial Network, or GAN, for short, are in a way, very similar to the autoencoder we created in session 3.  Or at least the implementation of it is.  The discriminator is a lot like the encoder part of this network, except instead of going down to the 64 dimensions we used in our autoencoder, we'll reduce our input down to a single value, yes or no, 0 or 1, denoting yes its a true training example, or no, it's a generated one.\n",
    "\n",
    "And the generator network is exactly like the decoder of the autoencoder.  Except, there is nothing feeding into this inner layer.  It is just on its own.  From whatever vector of hidden values it starts off with, it will generate a new example meant to look just like the training data.  One pitfall of this model is there is no explicit encoding of an input.  Meaning, you can't take an input and find what would possibly generate it.  However, there are recent extensions to this model which make it more like the autoencoder framework, allowing it to do this.\n",
    "\n",
    "<a name=\"input-pipelines\"></a>\n",
    "## Input Pipelines\n",
    "\n",
    "Before we get started, we're going to need to work with a very large image dataset, the CelebNet dataset.  In session 1, we loaded this dataset but only grabbed the first 1000 images.  That's because loading all 200 thousand images would take up a lot of memory which we'd rather not have to do.  And in Session 3 we were introduced again to the CelebNet and Sita Sings the Blues which required us to load a lot of images.  I glossed over the details of the input pipeline then so we could focus on learning the basics of neural networks.  But I think now we're ready to see how to handle some larger datasets.\n",
    "\n",
    "Tensorflow provides operations for taking a list of files, using that list to load the data pointed to it, decoding that file's data as an image, and creating shuffled minibatches.  All of this is put into a queue and managed by queuerunners and coordinators.\n",
    "\n",
    "As you may have already seen in the Variational Autoencoder's code, I've provided a simple interface for creating such an input pipeline using image files which will also apply cropping and reshaping of images in the pipeline so you don't have to deal with any of it.  Let's see how we can use it to load the CelebNet dataset.\n",
    "\n",
    "\n",
    "Let's first get the list of all the CelebNet files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from libs.datasets import CELEB\n",
    "files = CELEB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "And then create our input pipeline to create shuffled minibatches and crop the images to a standard shape.  This will require us to specify the list of files, how large each minibatch is, how many epochs we want to run for, and how we want the images to be cropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from libs.dataset_utils import create_input_pipeline\n",
    "batch_size = 100\n",
    "n_epochs = 10\n",
    "input_shape = [218, 178, 3]\n",
    "crop_shape = [64, 64, 3]\n",
    "crop_factor = 0.8\n",
    "batch = create_input_pipeline(\n",
    "    files=files,\n",
    "    batch_size=batch_size,\n",
    "    n_epochs=n_epochs,\n",
    "    crop_shape=crop_shape,\n",
    "    crop_factor=crop_factor,\n",
    "    shape=input_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Then when we are ready to use the batch generator, we'll need to create a `Coordinator` and specify this to tensorflow using the `start_queue_runners` method in order to provide the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(sess=sess, coord=coord)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We can grab our data using our `batch` generator like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 64, 64, 3)\n",
      "float32 255.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1724714c2b0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17240a07978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch_xs = sess.run(batch)\n",
    "# We get batch_size at a time, so 100\n",
    "print(batch_xs.shape)\n",
    "# The datatype is float32 since what is what we use in the tensorflow graph\n",
    "# And the max value still has the original image range from 0-255\n",
    "print(batch_xs.dtype, np.max(batch_xs))\n",
    "# So to plot it, we'll need to divide by 255.\n",
    "plt.imshow(batch_xs[0] / 255.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's see how to make use of this while we train a generative adversarial network!\n",
    "\n",
    "<a name=\"gandcgan\"></a>\n",
    "## GAN/DCGAN\n",
    "\n",
    "Inside the libs directory, you'll find `gan.py` which shows how to create a generative adversarial network with or without convolution, and how to train it using the CelebNet dataset.  Let's step through the code and then I'll show you what it's capable of doing.\n",
    "\n",
    "-- **Code demonstration transcribed for deeper understanding.** -- \n",
    "1. Main GAN Method\n",
    "    1. \n",
    "        * Creating a placeholder then scaling it to get -1 to 1\n",
    "        * Creating image summary for tensorboard.\n",
    "        * Another placeholder which tells when we train. It'll be used for regularization technique (batch norm)\n",
    "        * Discriminator will take input images, bool op, feautures and wil tell us 0/1 for x.\n",
    "        * Apply sigmoid and monitor that value using tensorboard.\n",
    "    2. \n",
    "        * Generator starts from n_latent features and it'll try to generate images out of that.\n",
    "        * Pass generator obj to hidden state vector and a boolean (whether we training or not) and o/p shape it should generate to.\n",
    "        * Reshaping and monitoring.\n",
    "    \n",
    "    3. \n",
    "        * Create 2nd discriminator (looks just like prev discriminator which was fed the real eg 'x') except here we fed the generator.\n",
    "        * Squash that value 0-1.\n",
    "    \n",
    "    4. \n",
    "        * Loss Function are created. Using binary cross entropy (Measures 1-x and x).\n",
    "        * loss_D_real - how often the dicriminator was correct in its real pred.\n",
    "        * loss_D_fake - how oftne the disciminator was correct when it was fed the generator pred.\n",
    "        * Combine it into one value\n",
    "        * loss_G - how often did it fool the discriminator.\n",
    "        * The generator is comparing the distribution of dicriminators fake results and saying that it does well whenever the fake dist looks like ones.\n",
    "        * Whereas the discriminator does well when it becomes zero (In opposition to each other, thus game theoretic type of measure).\n",
    "        * Return as a dictionary.\n",
    "\n",
    "2. Train function\n",
    "    1. \n",
    "        * Variable for training and input pipeline.\n",
    "        * Grab files for celeb, create batch generator.\n",
    "        \n",
    "    2. \n",
    "        * List comprehension where we ask tf for all the trainable variable with name 'discriminator.\n",
    "        * Similiarly for generator. To train disc and gen back and forth\n",
    "        * Create random state vec.\n",
    "        * Create manifold to visualize what the generator is doing to begin with.\n",
    "        \n",
    "    3. \n",
    "        * Seperate learning rate for gen and disc.\n",
    "        * Apply regularization to ensure the values dont grow too large.\n",
    "        * Seperate optimizers for each set of variable. One for the generator and one for the discriminator.\n",
    "        \n",
    "    4. \n",
    "        * Create session.\n",
    "        * Create saver object to save checkpoints.\n",
    "        * Create summary operations for tensorboard.\n",
    "        * Start queue runners.\n",
    "        \n",
    "    5. \n",
    "        * `if step_i % 3 ==1:` - train the discriminator, `else` train the generator.\n",
    "        * Discriminator needs both inputs for 'xs', real examples as well as state variables for generator to produce new content. It'll combine both the losses and use that to perfrom backprop and optimize only the disc variables and via that also trains against the generator.\n",
    "        * Generator is fed only the hidden state vec and updates gen part of the network only. \n",
    "    \n",
    "<a name=\"extensions\"></a>\n",
    "## Extensions\n",
    "\n",
    "So it turns out there are a ton of very fun and interesting extensions when you have a model in this space.  It turns out that you can perform addition in the latent space.  I'll just show you Alec Radford's code base on github to show you what that looks like.\n",
    "\n",
    "<a name=\"recurrent-networks\"></a>\n",
    "# Recurrent Networks\n",
    "\n",
    "Up until now, all of the networks that we've learned and worked with really have no sense of time.  They are static.  They cannot remember sequences, nor can they understand order outside of the spatial dimensions we offer it.  Imagine for instance that we wanted a network capable of reading.  As input, it is given one letter at a time.  So let's say it were given the letters 'n', 'e', 't', 'w', 'o', 'r', and we wanted it to learn to output 'k'.   It would need to be able to reason about inputs it received before the last one it received, the letters before 'r'.  But it's not just letters.\n",
    "\n",
    "Consider the way we look at the world.  We don't simply download a high resolution image of the world in front of us.  We move our eyes.  Each fixation takes in new information and each of these together in sequence help us perceive and act.  That again is a sequential process.\n",
    "\n",
    "Recurrent neural networks let us reason about information over multiple timesteps.  They are able to encode what it has seen in the past as if it has a memory of its own.  It does this by basically creating one HUGE network that expands over time.  It can reason about the current timestep by conditioning on what it has already seen.  By giving it many sequences as batches, it can learn a distribution over sequences which can model the current timestep given the previous timesteps.  But in order for this to be practical, we specify at each timestep, or each time it views an input, that the weights in each new timestep cannot change.  We also include a new matrix, `H`, which reasons about the past timestep, connecting each new timestep.  For this reason, we can just think of recurrent networks as ones with loops in it.\n",
    "\n",
    "Other than that, they are exactly like every other network we've come across!  They will have an input and an output.  They'll need a loss or an objective function to optimize which will relate what we want the network to output for some given set of inputs.  And they'll be trained with gradient descent and backprop.\n",
    "\n",
    "<a name=\"basic-rnn-cell\"></a>\n",
    "## Basic RNN Cell\n",
    "\n",
    "The basic recurrent cell can be used in tensorflow as `tf.contrib.rnn.BasicRNNCell`.  Though for most complex sequences, especially longer sequences, this is almost never a good idea.  That is because the basic RNN cell does not do very well as time goes on.  To understand why this is, we'll have to learn a bit more about how backprop works.  When we perform backrprop, we're multiplying gradients from the output back to the input.  As the network gets deeper, there are more multiplications along the way from the output to the input.\n",
    "\n",
    "Same for recurrent networks.  Remember, their just like a normal feedforward network with each new timestep creating a new layer.  So if we're creating an infinitely deep network, what will happen to all our multiplications?  Well if the derivatives are all greater than 1, then they will very quickly grow to infinity.  And if they are less than 1, then they will very quickly grow to 0. That makes them very difficult to train in practice.  The problem is known in the literature as the exploding or vanishing gradient problem.  Luckily, we don't have to figure out how to solve it, because some very clever people have already come up with a solution, in 1997!, yea, what were you doing in 1997.  Probably not coming up with they called the long-short-term-memory, or LSTM.\n",
    "\n",
    "<a name=\"lstm-rnn-cell\"></a>\n",
    "## LSTM RNN Cell\n",
    "\n",
    "The mechanics of this are unforunately far beyond the scope of this course, but put simply, it uses a combinations of gating cells to control its contents and by having gates, it is able to block the flow of the gradient, avoiding too many multiplications during backprop.  For more details, I highly recommend reading: https://colah.github.io/posts/2015-08-Understanding-LSTMs/.\n",
    "\n",
    "In tensorflow, we can make use of this cell using `tf.contrib.rnn.LSTMCell`.\n",
    "\n",
    "<a name=\"gru-rnn-cell\"></a>\n",
    "## GRU RNN Cell\n",
    "\n",
    "One last cell type is worth mentioning, the gated recurrent unit, or GRU.  Again, beyond the scope of this class.  Just think of it as a simplifed version of the LSTM with 2 gates instead of 4, though that is not an accurate description.  In Tensorflow we can use this with `tf.contrib.rnn.GRUCell`.\n",
    "\n",
    "<a name=\"character-langauge-model\"></a>\n",
    "# Character Langauge Model\n",
    "\n",
    "We'll now try a fun application of recurrent networks where we try to model a corpus of text, one character at a time.  The basic idea is to take one character at a time and try to predict the next character in sequence.  Given enough sequences, the model is capable of generating entirely new sequences all on its own.\n",
    "\n",
    "<a name=\"setting-up-the-data\"></a>\n",
    "## Setting up the Data\n",
    "\n",
    "For data, we're going to start with text.  You can basically take any text file that is sufficiently long, as we'll need a lot of it, and try to use this.  This website seems like an interesting place to begin: http://textfiles.com/directory.html and project guttenberg https://www.gutenberg.org/browse/scores/top.  http://prize.hutter1.net/ also has a 50k euro reward for compressing wikipedia.  Let's try w/ Alice's Adventures in Wonderland by Lewis Carroll:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import tensorflow as tf\n",
    "from six.moves import urllib\n",
    "import ssl\n",
    "try:\n",
    "    #ssl._create_default_https_context = ssl._create_unverified_context\n",
    "    #f, _ = urllib.request.urlretrieve('https://www.gutenberg.org/cache/epub/11/pg11.txt', 'alice.txt')\n",
    "    with open('alice', 'r') as fp:\n",
    "        txt = fp.read()\n",
    "except:\n",
    "    with open('alice.txt', 'r') as fp:\n",
    "        txt = fp.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [Issue](https://www.kadenze.com/forums/creative-applications-of-deep-learning-with-tensorflow-sessions-session-5-generative-models/threads/session-5-part-1-reading-text-file-error) with character encoding while downloading it from the gutenberg server."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "And let's find out what's inside this text file by creating a set of all possible characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(163783, 87)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = list(set(txt))\n",
    "len(txt), len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Great so we now have about 164 thousand characters and 85 unique characters in our vocabulary which we can use to help us train a model of language.  Rather than use the characters, we'll convert each character to a unique integer.  We'll later see that when we work with words, we can achieve a similar goal using a very popular model called word2vec: https://www.tensorflow.org/versions/r0.9/tutorials/word2vec/index.html\n",
    "\n",
    "We'll first create a look up table which will map a character to an integer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "encoder = dict(zip(vocab, range(len(vocab))))\n",
    "decoder = dict(zip(range(len(vocab)), vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'/': 0, 'H': 1, '': 2, ';': 3, '*': 4, 'O': 5, 'R': 6, '4': 7, '3': 8, '!': 9, 'B': 10, '1': 11, 'J': 12, 'u': 13, 'o': 14, 'U': 15, '': 16, '_': 17, 'Q': 18, 'i': 19, ' ': 20, 'a': 21, 'Y': 22, 'E': 23, 'M': 24, ',': 25, 'f': 26, 'b': 27, 'w': 28, ']': 29, 'j': 30, '2': 31, 'X': 32, '.': 33, '[': 34, '6': 35, '(': 36, 'd': 37, 'l': 38, '7': 39, '\"': 40, 'z': 41, 'I': 42, 'G': 43, '': 44, 'q': 45, 's': 46, 'N': 47, 'g': 48, '$': 49, 'r': 50, '0': 51, 'P': 52, '@': 53, 'm': 54, 'V': 55, \"'\": 56, 'h': 57, 'L': 58, 'p': 59, '5': 60, '8': 61, ':': 62, '-': 63, 'v': 64, 'x': 65, '9': 66, 'k': 67, 'S': 68, 'D': 69, 'K': 70, 'c': 71, 'y': 72, 'C': 73, 't': 74, 'F': 75, 'Z': 76, '#': 77, '%': 78, 'n': 79, 'T': 80, '?': 81, 'A': 82, ')': 83, 'e': 84, '\\n': 85, 'W': 86}\n"
     ]
    }
   ],
   "source": [
    "print(encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a name=\"creating-the-model\"></a>\n",
    "## Creating the Model\n",
    "\n",
    "For our model, we'll need to define a few parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Number of sequences in a mini batch\n",
    "batch_size = 100\n",
    "\n",
    "# Number of characters in a sequence\n",
    "sequence_length = 100\n",
    "\n",
    "# Number of cells in our LSTM layer\n",
    "n_cells = 256\n",
    "\n",
    "# Number of LSTM layers\n",
    "n_layers = 2\n",
    "\n",
    "# Total number of characters in the one-hot encoding\n",
    "n_chars = len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now create the input and output to the network.  Rather than having `batch size` x `number of features`; or `batch size` x `height` x `width` x `channels`; we're going to have `batch size` x `sequence length`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.int32, [None, sequence_length], name='X')\n",
    "\n",
    "# We'll have a placeholder for our true outputs\n",
    "Y = tf.placeholder(tf.int32, [None, sequence_length], name='Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now remember with MNIST that we used a one-hot vector representation of our numbers.  We could transform our input data into such a representation.  But instead, we'll use [`tf.nn.embedding_lookup`](https://stackoverflow.com/questions/34870614/what-does-tf-nn-embedding-lookup-function-do) so that we don't need to compute the encoded vector.  Let's see how this works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[None, 100, 256]\n"
     ]
    }
   ],
   "source": [
    "# we first create a variable to take us from our one-hot representation to our LSTM cells\n",
    "embedding = tf.get_variable(\"embedding\", [n_chars, n_cells])\n",
    "\n",
    "# And then use tensorflow's embedding lookup to look up the ids in X\n",
    "Xs = tf.nn.embedding_lookup(embedding, X)\n",
    "\n",
    "# The resulting lookups are concatenated into a dense tensor\n",
    "print(Xs.get_shape().as_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "To create a recurrent network, we're going to need to **slice our sequences into individual inputs**.  That will give us timestep lists which are each `batch_size` x `input_size`.  Each character will then be connected to a recurrent layer composed of `n_cells` LSTM units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Let's create a name scope for the operations to clean things up in our graph\n",
    "with tf.name_scope('reslice'):\n",
    "    Xs = [tf.squeeze(seq, [1])\n",
    "          for seq in tf.split(Xs, sequence_length, axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now we'll create our recurrent layer composed of LSTM cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cells = tf.contrib.rnn.BasicLSTMCell(num_units=n_cells)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We'll initialize our LSTMs using the convenience method provided by tensorflow.  We could explicitly define the batch size here or use the `tf.shape` method to compute it based on whatever `X` is, letting us feed in different sizes into the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "initial_state = cells.zero_state(tf.shape(X)[0], tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Great now we have a layer of recurrent cells and a way to initialize them.  If we wanted to make this a multi-layer recurrent network, we could use the `MultiRNNCell` like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Build deeper recurrent net if using more than 1 layer\n",
    "if n_layers > 1:\n",
    "    cells = [cells]\n",
    "    for layer_i in range(1, n_layers):\n",
    "        with tf.variable_scope('{}'.format(layer_i)):\n",
    "            this_cell = tf.contrib.rnn.BasicLSTMCell(\n",
    "                num_units=n_cells)\n",
    "            cells.append(this_cell)\n",
    "    cells = tf.contrib.rnn.MultiRNNCell(cells)\n",
    "    initial_state = cells.zero_state(tf.shape(X)[0], tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "In either case, the cells are composed of their outputs as modulated by the LSTM's output gate, and whatever is currently stored in its memory contents.  Now let's connect our input to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# this will return us a list of outputs of every element in our sequence.\n",
    "# Each output is `batch_size` x `n_cells` of output.\n",
    "# It will also return the state as a tuple of the n_cells's memory and\n",
    "# their output to connect to the time we use the recurrent layer.\n",
    "outputs, state = tf.contrib.rnn.static_rnn(cells, Xs, initial_state=initial_state)\n",
    "\n",
    "# We'll now stack all our outputs for every cell\n",
    "outputs_flat = tf.reshape(tf.concat(outputs, axis=1), [-1, n_cells])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "For our output, we'll simply try to predict the very next timestep.  So if our input sequence was \"networ\", our output sequence should be: \"etwork\".  This will give us the same batch size coming out, and the same number of elements as our input sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('prediction'):\n",
    "    W = tf.get_variable(\n",
    "        \"W\",\n",
    "        shape=[n_cells, n_chars],\n",
    "        initializer=tf.random_normal_initializer(stddev=0.1))\n",
    "    b = tf.get_variable(\n",
    "        \"b\",\n",
    "        shape=[n_chars],\n",
    "        initializer=tf.random_normal_initializer(stddev=0.1))\n",
    "\n",
    "    # Find the output prediction of every single character in our minibatch\n",
    "    # we denote the pre-activation prediction, logits.\n",
    "    logits = tf.matmul(outputs_flat, W) + b\n",
    "\n",
    "    # We get the probabilistic version by calculating the softmax of this\n",
    "    probs = tf.nn.softmax(logits)\n",
    "\n",
    "    # And then we can find the index of maximum probability\n",
    "    Y_pred = tf.argmax(probs, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a name=\"loss\"></a>\n",
    "## Loss\n",
    "\n",
    "Our loss function will take the reshaped predictions and targets, and compute the softmax cross entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('loss'):\n",
    "    # Compute mean cross entropy loss for each output.\n",
    "    Y_true_flat = tf.reshape(tf.concat(Y, axis=1), [-1])\n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=Y_true_flat)\n",
    "    mean_loss = tf.reduce_mean(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a name=\"clipping-the-gradient\"></a>\n",
    "## Clipping the Gradient\n",
    "\n",
    "Normally, we would just create an optimizer, give it a learning rate, and tell it to minize our loss.  But with recurrent networks, we can help out a bit by telling it to clip gradients.  That helps with the exploding gradient problem, ensureing they can't get any bigger than the value we tell it.  We can do that in tensorflow by iterating over every gradient and variable, and changing their value before we apply their update to every trainable variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('optimizer'):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=0.001)\n",
    "    gradients = []\n",
    "    clip = tf.constant(5.0, name=\"clip\")\n",
    "    for grad, var in optimizer.compute_gradients(mean_loss):\n",
    "        gradients.append((tf.clip_by_value(grad, -clip, clip), var))\n",
    "    updates = optimizer.apply_gradients(gradients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We could also explore other methods of clipping the gradient based on a percentile of the norm of activations or other similar methods, like when we explored deep dream regularization.  But the LSTM has been built to help regularize the network through its own gating mechanisms, so this may not be the best idea for your problem.  Really, the only way to know is to try different approaches and see how it effects the output on your problem.\n",
    "\n",
    "<a name=\"training\"></a>\n",
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4.47112\n",
      "['N00000000NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN0000NNNNNNNNNNNNNNNNN    NNNNNNNNNNNNNNNNNNNNNNNNN                    N        NNNNNNtttt tttt            NNNNNNNNNNNNN      NNNNNNNNNNNNNNNNNNNNNNNNNNNNNN  NNN N           NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN              NNNNNNNNNNNNNNNNNNNNNNNNN00000000NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN00NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN000000NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN000000000NNNNNNNNNNNN0NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN0000000NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN0000NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN0000000NNNNNNNNNNNNNNNNNNNNNNNNNNNNN0000NNNNNNNNNNNNNNNNNNt                      ttttt                         NNNNNNNNNNNNNNNNNNtttttt                                                                 NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNttttttttttNNNN NNN                        NNNNNNNNNNNN    NNNNNNNNNNNNNNNNNNNNNNN00NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN              NN                   NNNNNNNN     NNNNNNNNNNNNNNNNNNNNNNNNN  N NNNNNNNNNNNNNNNNNNNNNNN         NNNNNNNNNNNNNNNNNNNNNNNNNNNN NNNN    NNNNNNNNNNNNNNNNNNNttNNNNtt           NNNNNN                      NNNNNNNNNN   NNNttttttttttt         NNN000NNNNNNNNNNNNNN0NNNNNNNNNNNtt       NNNNNNNNNNNNNNNNNNttttttt                          NNNNNNNNNNNNNNNNNNNNNNN              ttttttttttttt         NNNNNNNNNNNNNNNNNNNNNNNN    tt                   NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN  ttt                                        tttt         NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN       NttttttttttttNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN                  NNNNNNNNNNNNNNNN            NNNNNNttttt                     NNNNNNNNNNNNNNNNNNNNNNNNNNN NNNNNNNNttttttt  t   tt tt tttttttttNNNNNNNNNNNNNNNNNN  tt             ttNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN            NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN     NNNNNNNNNNNNNNN NNNNNNNNNNNNNNNNNNNNNNNNNNN           NNNNNNNNNNNNNNNNNN         NNNNNNNNNNNNNNNN   NNNNNNNNNNNNNNNNNNNNN                                   tttt        NNNNNNNNttt     NNNNttttttttt   NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN               NNNNNNNNNNNNNNNNNNNNNNNNNNNNNN                        NNNNNNNNNNNNNNNNNttttNNNNNNNNNNNNNNNNNNNNNNN  N  NNNNNNNNNNNNNN N                NNNNNNNNNNNNNN     NNNNNNNNNNNNNNNNNNNNNNN          N  NNNNNNNNNNNNNN             NN                              NNN  NNNNNNNNNNNNNNN  NNN               tt             NNNNN                           N         N       NNNNNNNNNNNNNNNNNNNNNNN                                            NNNN                           NNNNNNNNNNNNNNN               NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN                          NNNNNNNNNNNNNNNNNNNNNNNNNNNN         NNNNNNNNNNN                                N   N  NNNNNNN  NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNttttttNNNttttttt     N                                  ttttt tNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN                              tNNNNN            NNNNN       00NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNttt                              ttt     NNt       NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN     NN           NNNNNNNNNNNNNNNNNNNNNNN tttttttttt                 N NN  NNNN0NNNNNNNNNNNNN NNNNNNNNNNNN         NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN  NNNNNNNNNNNNNNNNNN0NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN                 ttttNNN NNNNNNNNNNN NNNNN   NNNNNNNNNNNNNNNNNNNNNNNN                                           NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN    NNNNNNttttttttt                                       NNNNNNNNNNNt NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN       tt               NNNNNNNNN NNNNNNNN              NNNNNNNNNNNNNNNNNNN        NNNNNN     tt tt t      NNNNNNNNNNNNNNNNNNNNNttttttttt    tt   NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN NNNNNNNNNNNNN              tttt        NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNttt              NNNN   NN            NNNNNNNNNNNNN    N NttttNtt       NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN NNNNNNNNNNNNNNNNNNNNNNN          ttttttt      NNNNNNNNNNNNNNNN NNNNNNNNNNNNNNNNNttttt  NNtttNNNNNNNNNNNNNNNNNNNNNtttNNN NN   NNNNNNNNN   NNNNNttNNNNNNNNNNNNNNNNNNNNNN                                  NNNNNNNNNNNNNNNttt                            NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNt      NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN    NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN   tt  N                   N NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNttttttttttttt     tttt       NNNNNNNNNNNNNNNNNNNNNNNNNNNN       N    NNNNNNNNNNNNNNNNNNNN NNNNNNN          NNNNNNNNNNNNNNNNNNNNNNNNNNNNNN NNNN NN                      NN    NNNNNNNNNNNNNN0NNNNNNNNNNNNNNNNtttNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN              NNNNNNNNNNNNN        NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN                       NNNNNNNNNNNNNNNNNNNNNNNNNNNNNN  tttt NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNtt   tt                        NNNNNNNNNNNNNNNNNNNNNNNNNNNNN      ttt          NNNNNNNNNNNNNNNNNNNNNNNNNNNNN  ttttt          NNNN  N NNNNNNNNNNNNNNNNN   NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN tttttttt ttt      ttttttttt       NNNNNNNNNNNNNNNNNNNNNNNNNttNNNNNNNNNNNNNNNNNNN     NNNNNNNNNNN  NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN   NNNNNNNNNNNNNNNNNN           tttt                 NNNNNNNNNNNNNNN             NNNNNNtt              NNNNNNNNNNNNNN          N NNN                          NNNNNNNNNNNNNNNNNNNNNNNNNNNNN    NNN         NNN0NNNNNNNNNNNNttt          NNNNNNNNNNNNNNNNNNNNN             NNNNNNNNNtttttttt                    NNNNNNNNNNNNNNNNN NNN NNNNNNNNNNNNNNNNN ttt  t                  N NN NN                             NNNNNNNNNNNNNNNNNNNNNNNN  NNNN      NNNN NNNNNNNNNNNNNNNNNNNN      tttNNttNNNNNNNNN          tttttttNNNNNNNNNNNNNNNNNNNNNNNNNNNNN                           N N           t ttt      NNNNNNNNNNNNN      NNNNNNNNNNNNNNNNNNNNNNNN       tt ttt tt                   N  NNNNNNNNNNNNNNNNNNNN NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN                                     NNNNNNNNN   tttttttttt                 NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN        NNN   NNN                           N    tttt  NNNNNNNNNNNNNN000000000N0NNNNNNNNNNNNNNNNNNNNN          NN              NNNNNNNNNNNN    NNNNNNNNNN        tt     NNNNNNNNNNNNNNNNNNN                             N00NNNNNNNNNNNNNNNNNNNNN                  NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNttNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNtttttt        NNNNNNNNNNNNNNNNNNNNNNNNNNNN000NNNNNNNNNNNNNNNNNNNN                tttt              NNNNNNNNNNNNNNNNNNNNNNNNttt             NNNNNNNNNNNNNNNN                              NNNNNNNNNNNNNNNNN                  NNNNNNNNNNNNN      NNNNNNNNNNNNNNNNNNNNNNNNNNNNNN                                       NNNNNN           N NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN                         NNNNNNNNNNNNNN         tt        tttttttttttt    NNNNNNNNNNNNNN NN           t    t                                              tttttttt       NNNNNNNN0NNNNNNNNNNNNNNNN       N                   ttttttttttt  NNNNNNNNNNNNNNNNNNNttttttttt            NNNNNNNNNNNNNNNNNNNNNNNNN       tt    ttttt           tttttNNNNN    N  NNNNNNN                      NNNNNNNNNNNNNNNNNNNNNNN        NNNNNNNNNNNNtttt              tttttt      NNNNNNN           NNNNNNNNNNNNNNNNNNNNNNNNNNN                                   NNNNNNNNNNN     NN                     NN NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN         NNNNNNNNNNNN NNNNNNNNNNNNNN  NN      NNNNNNNNNNNN000NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN                    NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNtt            NNNNNNNNNNNNNNN                   t t                             NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN             NNN                                   NNNNNNN         NNNNNNNNNNNNttt        ttt                         tttttttttNtttttt   ttt      NNNNNNNNNNNN         NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN    NN NNN NNNN    tttt            NN    NNNNNNtttN              NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN                            t    ttNNNNNNNNNNNN          NNNNNNNNNNNNNNNNN00NNNNNNNNNNNNNNNN   tttt      NNNN0NNNNNNNNNNNNNNNN     NNN NNN NNNNNNNNNNNNNNNNNNNN        NN   NNNNNNNNNNNNNNNNNNNNN      NNNN       NNN     NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN       N  NNN NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN                         NNNNNNtttttttttttttttttttttNN                   NNNNNNNNNNNNNNNNN       NNNNNNNNNNN           NNNNNtttttt tttt   NNNNNNNNN   NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN NN                     NN ttt               NNNNNNNNNNNNNNNNNNNNNNN   NNNNNNNNNNNNNNNNNNNNttt            NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN  N   NNNNNNNNNNNNNNNNNNNNN     NNN000000000NN0NNNNNNNttttt     NN NNNNNNNNNNNNNNNNNt  ttNNNNN NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNtttt ttNN0NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNtttttt    NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN              NNNNNN      ttN N                 NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN                         tt         NNNNNNNNNNN                                                                                         NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN          NNNNNNNNNNNNNNNNNNNNNNNNNNN          NNNNNNNNNNNNNNNNNNNNNNN                          NNNNN      NNNt            ttt                     NNNNNNNNNNNNNNNNNNNNNNNNNNN     t          ttttttttttttt  ttt       NNNNNN     NNNNNN NNNNNNNNNNNNNNNNNNNNNNNNNNNNNNN N                                NNNNNNNNN NNNNNNNNNNttt         NNNNNNNNtttttttNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNNtttt     NNNNNNNNNNNNN         NNNNNNNNNNNNNNNNNN NNN NN     NNNNNN             tt                        NNNN          NNNNNNNN   NNN0NNNNNNNNNNNNNNNNNNNNNNNN       N N N NNNNNNNN0NNNNNNNtt                       NNNNN       NNNNNN']\n",
      "1 4.41217\n",
      "2 4.27626\n",
      "3 3.8891\n",
      "4 3.75502\n",
      "5 3.49291\n",
      "6 3.42521\n",
      "7 3.43244\n",
      "8 3.38735\n",
      "9 3.28857\n",
      "10 3.33325\n",
      "11 3.32893\n",
      "12 3.25128\n",
      "13 3.26769\n",
      "14 3.3422\n",
      "15 3.46091\n",
      "16 3.33661\n",
      "17 3.18463\n",
      "18 3.21734\n",
      "19 3.16802\n",
      "20 3.19354\n",
      "21 3.21253\n",
      "22 3.16669\n",
      "23 3.18797\n",
      "24 3.23082\n",
      "25 3.17031\n",
      "26 3.16562\n",
      "27 3.25193\n",
      "28 3.22614\n",
      "29 3.20977\n",
      "30 3.25173\n",
      "31 3.34482\n",
      "32 3.44586\n",
      "33 3.14304\n",
      "34 3.16227\n",
      "35 3.15567\n",
      "36 3.18784\n",
      "37 3.16737\n",
      "38 3.12826\n",
      "39 3.14586\n",
      "40 3.20669\n",
      "41 3.16428\n",
      "42 3.12152\n",
      "43 3.216\n",
      "44 3.22097\n",
      "45 3.14559\n",
      "46 3.20385\n",
      "47 3.2752\n",
      "48 3.42322\n",
      "49 3.182\n",
      "50 3.10838\n",
      "51 3.134\n",
      "52 3.10741\n",
      "53 3.13979\n",
      "54 3.10733\n",
      "55 3.07717\n",
      "56 3.13677\n",
      "57 3.11407\n",
      "58 3.04821\n",
      "59 3.10526\n",
      "60 3.14949\n",
      "61 3.06827\n",
      "62 3.09554\n",
      "63 3.18016\n",
      "64 3.31589\n",
      "65 3.19614\n",
      "66 3.00623\n",
      "67 2.99727\n",
      "68 2.99924\n",
      "69 2.99244\n",
      "70 3.0023\n",
      "71 2.94307\n",
      "72 2.93297\n",
      "73 2.96689\n",
      "74 2.89157\n",
      "75 2.8682\n",
      "76 2.94718\n",
      "77 2.93371\n",
      "78 2.85785\n",
      "79 2.93968\n",
      "80 3.08932\n",
      "81 3.26961\n",
      "82 2.79173\n",
      "83 2.84596\n",
      "84 2.86179\n",
      "85 2.81964\n",
      "86 2.80916\n",
      "87 2.75376\n",
      "88 2.7418\n",
      "89 2.78122\n",
      "90 2.73675\n",
      "91 2.66454\n",
      "92 2.75794\n",
      "93 2.77058\n",
      "94 2.6959\n",
      "95 2.76909\n",
      "96 2.88258\n",
      "97 3.14963\n",
      "98 2.7814\n",
      "99 2.73499\n",
      "100 2.65727\n",
      "101 2.72356\n",
      "102 2.67831\n",
      "103 2.70442\n",
      "104 2.62079\n",
      "105 2.63882\n",
      "106 2.63285\n",
      "107 2.5733\n",
      "108 2.60669\n",
      "109 2.67872\n",
      "110 2.6358\n",
      "111 2.61277\n",
      "112 2.78616\n",
      "113 3.00998\n",
      "114 2.86827\n",
      "115 2.61245\n",
      "116 2.59964\n",
      "117 2.65844\n",
      "118 2.5799\n",
      "119 2.62038\n",
      "120 2.54973\n",
      "121 2.55405\n",
      "122 2.57176\n",
      "123 2.53372\n",
      "124 2.49008\n",
      "125 2.58857\n",
      "126 2.60382\n",
      "127 2.49551\n",
      "128 2.5593\n",
      "129 2.85981\n",
      "130 3.03381\n",
      "131 2.51788\n",
      "132 2.54586\n",
      "133 2.58585\n",
      "134 2.54205\n",
      "135 2.54333\n",
      "136 2.49925\n",
      "137 2.48409\n",
      "138 2.50064\n",
      "139 2.47639\n",
      "140 2.42217\n",
      "141 2.49937\n",
      "142 2.50405\n",
      "143 2.47144\n",
      "144 2.5049\n",
      "145 2.63698\n",
      "146 2.92996\n",
      "147 2.58775\n",
      "148 2.50776\n",
      "149 2.4445\n",
      "150 2.51466\n",
      "151 2.46275\n",
      "152 2.48338\n",
      "153 2.42432\n",
      "154 2.4084\n",
      "155 2.43554\n",
      "156 2.38908\n",
      "157 2.3896\n",
      "158 2.4543\n",
      "159 2.44652\n",
      "160 2.39608\n",
      "161 2.52929\n",
      "162 2.74541\n",
      "163 2.72234\n",
      "164 2.42573\n",
      "165 2.39255\n",
      "166 2.44894\n",
      "167 2.43313\n",
      "168 2.40892\n",
      "169 2.36441\n",
      "170 2.37686\n",
      "171 2.38191\n",
      "172 2.35999\n",
      "173 2.31646\n",
      "174 2.39566\n",
      "175 2.40537\n",
      "176 2.31083\n",
      "177 2.3674\n",
      "178 2.63795\n",
      "179 2.77977\n",
      "180 2.3963\n",
      "181 2.35961\n",
      "182 2.36656\n",
      "183 2.38216\n",
      "184 2.36887\n",
      "185 2.32764\n",
      "186 2.32855\n",
      "187 2.31221\n",
      "188 2.30637\n",
      "189 2.27581\n",
      "190 2.32398\n",
      "191 2.32297\n",
      "192 2.30262\n",
      "193 2.32074\n",
      "194 2.45244\n",
      "195 2.68796\n",
      "196 2.50927\n",
      "197 2.31224\n",
      "198 2.30585\n",
      "199 2.29333\n",
      "200 2.31634\n",
      "201 2.30043\n",
      "202 2.27513\n",
      "203 2.23886\n",
      "204 2.27343\n",
      "205 2.24366\n",
      "206 2.21764\n",
      "207 2.29641\n",
      "208 2.29147\n",
      "209 2.22355\n",
      "210 2.33947\n",
      "211 2.59017\n",
      "212 2.59208\n",
      "213 2.26896\n",
      "214 2.24887\n",
      "215 2.25982\n",
      "216 2.29233\n",
      "217 2.23413\n",
      "218 2.21955\n",
      "219 2.21114\n",
      "220 2.20139\n",
      "221 2.22569\n",
      "222 2.16422\n",
      "223 2.23649\n",
      "224 2.25806\n",
      "225 2.15102\n",
      "226 2.21289\n",
      "227 2.47853\n",
      "228 2.63111\n",
      "229 2.3008\n",
      "230 2.20395\n",
      "231 2.20994\n",
      "232 2.21985\n",
      "233 2.23279\n",
      "234 2.1854\n",
      "235 2.18283\n",
      "236 2.14166\n",
      "237 2.16411\n",
      "238 2.13896\n",
      "239 2.15403\n",
      "240 2.19227\n",
      "241 2.16902\n",
      "242 2.15608\n",
      "243 2.31361\n",
      "244 2.5276\n",
      "245 2.44663\n",
      "246 2.17171\n",
      "247 2.18291\n",
      "248 2.13946\n",
      "249 2.19811\n",
      "250 2.14554\n",
      "251 2.15024\n",
      "252 2.09693\n",
      "253 2.12372\n",
      "254 2.11569\n",
      "255 2.07817\n",
      "256 2.15608\n",
      "257 2.15922\n",
      "258 2.08802\n",
      "259 2.175\n",
      "260 2.43514\n",
      "261 2.53701\n",
      "262 2.13406\n",
      "263 2.14835\n",
      "264 2.12392\n",
      "265 2.18445\n",
      "266 2.10725\n",
      "267 2.09531\n",
      "268 2.08226\n",
      "269 2.06479\n",
      "270 2.09761\n",
      "271 2.04555\n",
      "272 2.08806\n",
      "273 2.12855\n",
      "274 2.03379\n",
      "275 2.09624\n",
      "276 2.3101\n",
      "277 2.51265\n",
      "278 2.2286\n",
      "279 2.09547\n",
      "280 2.10473\n",
      "281 2.08858\n",
      "282 2.1181\n",
      "283 2.07124\n",
      "284 2.07586\n",
      "285 2.00952\n",
      "286 2.04837\n",
      "287 2.01751\n",
      "288 2.02252\n",
      "289 2.0703\n",
      "290 2.07521\n",
      "291 2.02686\n",
      "292 2.19571\n",
      "293 2.38049\n",
      "294 2.37245\n",
      "295 2.0537\n",
      "296 2.09324\n",
      "297 2.04577\n",
      "298 2.10404\n",
      "299 2.0256\n",
      "300 2.04862\n",
      "301 1.98523\n",
      "302 2.00427\n",
      "303 2.02393\n",
      "304 1.96308\n",
      "305 2.03749\n",
      "306 2.05549\n",
      "307 1.97641\n",
      "308 2.03738\n",
      "309 2.30599\n",
      "310 2.46357\n",
      "311 2.0538\n",
      "312 2.05091\n",
      "313 2.02997\n",
      "314 2.09399\n",
      "315 2.00911\n",
      "316 2.00995\n",
      "317 1.97662\n",
      "318 1.95465\n",
      "319 1.98748\n",
      "320 1.96491\n",
      "321 1.96591\n",
      "322 1.98882\n",
      "323 1.98452\n",
      "324 1.99868\n",
      "325 2.17476\n",
      "326 2.38736\n",
      "327 2.15171\n",
      "328 2.01748\n",
      "329 2.0333\n",
      "330 1.99018\n",
      "331 2.02155\n",
      "332 1.96478\n",
      "333 1.98912\n",
      "334 1.89909\n",
      "335 1.96572\n",
      "336 1.92075\n",
      "337 1.91909\n",
      "338 1.96509\n",
      "339 1.99191\n",
      "340 1.9242\n",
      "341 2.07928\n",
      "342 2.26122\n",
      "343 2.27873\n",
      "344 1.97545\n",
      "345 2.00626\n",
      "346 1.97672\n",
      "347 2.02177\n",
      "348 1.92932\n",
      "349 1.9574\n",
      "350 1.90112\n",
      "351 1.90249\n",
      "352 1.93659\n",
      "353 1.88654\n",
      "354 1.92725\n",
      "355 1.96119\n",
      "356 1.89222\n",
      "357 1.92891\n",
      "358 2.18774\n",
      "359 2.37304\n",
      "360 1.96631\n",
      "361 1.96801\n",
      "362 1.94494\n",
      "363 2.01083\n",
      "364 1.93511\n",
      "365 1.90683\n",
      "366 1.90852\n",
      "367 1.86196\n",
      "368 1.89373\n",
      "369 1.87634\n",
      "370 1.8775\n",
      "371 1.89423\n",
      "372 1.90524\n",
      "373 1.91336\n",
      "374 2.04274\n",
      "375 2.25636\n",
      "376 2.10803\n",
      "377 1.94836\n",
      "378 1.94785\n",
      "379 1.9146\n",
      "380 1.95586\n",
      "381 1.87615\n",
      "382 1.90422\n",
      "383 1.81499\n",
      "384 1.87895\n",
      "385 1.85421\n",
      "386 1.82423\n",
      "387 1.88011\n",
      "388 1.91598\n",
      "389 1.84968\n",
      "390 1.97285\n",
      "391 2.12578\n",
      "392 2.21456\n",
      "393 1.90709\n",
      "394 1.93072\n",
      "395 1.90732\n",
      "396 1.94934\n",
      "397 1.85881\n",
      "398 1.86658\n",
      "399 1.83771\n",
      "400 1.81063\n",
      "401 1.86673\n",
      "402 1.81028\n",
      "403 1.83428\n",
      "404 1.88852\n",
      "405 1.80945\n",
      "406 1.85906\n",
      "407 2.06323\n",
      "408 2.25303\n",
      "409 1.9457\n",
      "410 1.88173\n",
      "411 1.89714\n",
      "412 1.90706\n",
      "413 1.8925\n",
      "414 1.8434\n",
      "415 1.85035\n",
      "416 1.78281\n",
      "417 1.82131\n",
      "418 1.79259\n",
      "419 1.79202\n",
      "420 1.82586\n",
      "421 1.8379\n",
      "422 1.83697\n",
      "423 1.95376\n",
      "424 2.11891\n",
      "425 2.10336\n",
      "426 1.86444\n",
      "427 1.89413\n",
      "428 1.8379\n",
      "429 1.89386\n",
      "430 1.81833\n",
      "431 1.84793\n",
      "432 1.76132\n",
      "433 1.78765\n",
      "434 1.79411\n",
      "435 1.75677\n",
      "436 1.79698\n",
      "437 1.84682\n",
      "438 1.78168\n",
      "439 1.88404\n",
      "440 2.02316\n",
      "441 2.17499\n",
      "442 1.84458\n",
      "443 1.86186\n",
      "444 1.85326\n",
      "445 1.88727\n",
      "446 1.80089\n",
      "447 1.81569\n",
      "448 1.78248\n",
      "449 1.74195\n",
      "450 1.80607\n",
      "451 1.74399\n",
      "452 1.76355\n",
      "453 1.79837\n",
      "454 1.73884\n",
      "455 1.81112\n",
      "456 1.96574\n",
      "457 2.17166\n",
      "458 1.92753\n",
      "459 1.80798\n",
      "460 1.83429\n",
      "461 1.82445\n",
      "462 1.81935\n",
      "463 1.7883\n",
      "464 1.79783\n",
      "465 1.72401\n",
      "466 1.76853\n",
      "467 1.72498\n",
      "468 1.72334\n",
      "469 1.75154\n",
      "470 1.78129\n",
      "471 1.75823\n",
      "472 1.87674\n",
      "473 2.02883\n",
      "474 2.06994\n",
      "475 1.79141\n",
      "476 1.84696\n",
      "477 1.77848\n",
      "478 1.82516\n",
      "479 1.74176\n",
      "480 1.79056\n",
      "481 1.71073\n",
      "482 1.72299\n",
      "483 1.76381\n",
      "484 1.69367\n",
      "485 1.73039\n",
      "486 1.76987\n",
      "487 1.71014\n",
      "488 1.79904\n",
      "489 1.91005\n",
      "490 2.14667\n",
      "491 1.79634\n",
      "492 1.81471\n",
      "493 1.79387\n",
      "494 1.82897\n",
      "495 1.72888\n",
      "496 1.74806\n",
      "497 1.71473\n",
      "498 1.69155\n",
      "499 1.74323\n",
      "500 1.70279\n",
      "[' the   rfer an a d th teend tf the r hedd  a d torr  ah sade the sgeh rs', '', \"'he saond tostinetl  alice torrd tn tonst tas at aeddteng ter aoeneng    he sarhesd d tn art ing tn  aete thrh d tnan  aoueor hnle tveutht ander ter a ee ahth tt  aiaa teddeng torn  aut tott  lly  autt tn the sad to  tt  aoat tote y toeetdht dtd tft  and tas ao ng th tene the war entn tnleiw tith tt  aerd  an ahRR  shitelat   f teusd tnd tioketn at aer aork  ahth thrh t lrrlled anpliat nn thet the sauld tot aerfetete  ng tut tittetng  and then the sad to  tt  aerd town  and tas ao ng th te angtnain  an aas aery aaouereng th tond thet the sar entn ter tndeulyd tn  rf  and tas at ahe wnketf tootsyng tnan  au tned tnl then  ahe e was soet  lly tnletee tf torneu at ahe was tiene er tae sasd r th teetethe sar entn th  and  an the soonle  -n th l nds tare t l n  tot ing tn a d tasl ng tf  th tn er trrde af the srousd  aline ta k tore th the souteiteon thet tt aas a lery aostinetl tote tn er   \", \"'he saos    anl teis d tnhtfee tath ut tasdeng tor thrnie auiteesyyng tnl the saitl  and tonht ng tor the war entn   and tt tntery aeeue ohme the wueen ais at a lornnns trrt nn  and tart theneeng tnout  and theuleng tIh  tathetes aerd ' sn tIh  tath ter serd ' snout tnee tt a lungte \", '', \"'lice segan ah tor  tery apdnte  'h se thre  ahe sad tot a  tor aed t d sosteledtath the sueen  aut the snoa ahet tt aasht ted erttnd tasdthr 'Ind the    sheught the  aahit tauld te aue tf tea'Ihe  se soeat elly aor etf te trd ng trrn e te ed ahe sroat tirder tt  ahet the e s a d sfe tiat tnlce   \", \"'he sas tiokeng tnout tor thme tas tf tn eitd and thuder ng tien er the sauld tot inan tith ut te ng toe   ahin the sot ne  tnlorsnns an ertetde tn the wnd  an aarlled ter aery aash a  tonst  aut  an er tas e ng tn a langte tf thi  ahe sade tt aft th te t lrong and the said th her elf tt  s ahe saortene tat  aot a shetl tede ta e ou  th thnl th  \", '', \"'Iew and tou mrt ing tn ' said the satt an th k t  the e was auune aveuthttor tt ah teeatethth  \", \"'lice sasd   thml the wxtn an erred  and the  tot er \", \"'I  s aotsse taeateng th tt   sae sheug e  aIhml tt  aad  aede toue  an t  tiase tf  tf the   \", 'At t duher taddtedthe waire terr t  erted  and the  tlice aartoorn ter aoaneng   and tegan andt kemsd tf the srre  aornlng tery aoan the sad th e r dth tittedtth ter ', \"'he sat the ed th theng ahet the e was aneuthttf tt aot at ahdht  and totsaue tf tt a  erred \", '', \"'I son't shesk the  waos tn t l tord y   slice segan  an aesher t loueiitn ng th e  aInd the  wnl tueteedyth toeat illy af  tordt terrdtfe  df tteate--nd the  wowet sae eth tede t d tesld an arrd nellne 'n tiase  an the e sse  aoteu  tn er e th the  -and tou de totst nther tortireo  tt at a l the sheng  ae ng tnlne  'or tt teide  ahe e s the sleh t ve to  th te theeughttott tasl ng tnout t  the sfher tveetf the srousd -tnd t sheuld tede taouuet d the sueen t ter entn turt tot  tf y at aesdt  n tien tt ahi tusd toueng ' \", \"'Iew ao sou mite the sueen ' said the satttt a lionterde \", '', \"'Iot t  t l   said tlice  'Ihe s ta hve isedf -'\", \" utt the  the sot ne  thet the sueen ais aoame tertng ter  aett rtng  ah the sart tf  'I  ice y th setd ahet tt s aedd y aark  taete sondnt ng the w re \", '', '', \"'he sueen ahesld tnd tert d tf \", '', \"'IhauslE Tou mhnl ng th ' said the sing  ao ng tn ah tlice  tnd tiokeng tn the satts aerd tath toeat torsnn ni \", '', \"'I  s a loondt tf tend t'nsaortene tat   said tlice  'Inl n ta th sn eeuith tt  \", '', \"'I son't site the siok of tt a  t l   said the sing  aIe  der  anhtun tnnt aa tedd tt tt aite   \", '', \"'I s tes er tot   she sat teaand d \", '', \"'Iou't se tt lrting t   said the sing  aInd tow't sioketn te tite thet ' \", 'e sau te tng tlice t  aersaemed', '', \"'Indan tud tiok tn t ling   said tlice \", \"'I se teas thet tt ah e tetk  'ut t son't seaaneed tiene  \", '', \"'Ihll  at aast te teaaner   said the sing tery aoatned y  and tersanl d the sueen  ahi sas arst ng tn the saue t  aIo toar  t sath tou sauld teve thes aor teaaner ' \", \"'he sueen aed tney tfe tas tn the eeng tnl tostinetl nd  toeat tf thetl  \", \"Ih  thth tes aerd ' sae said  ahth ut tver tiokeng teund \", '', \"'I ll toe h the sxtnttenu   ta elf   said the sing tvte  y  and tersardend tf   \", \"'lice theught the sadht t  tarl to tetk  an  the tew the wrre tas ao ng tf  an the sardd the sueen t terde tt ahe wodtlnge  aheiateng tith tart nn \", \"'he sad t ledd  terrd ter aaet dte toeee wf the sros d  ao te txecttid tor tedeng test d the r threie and the sod tot aite the wiok of thesg  an t l  an the srne tas at ahrh aoueireon thet the so er tnoa aain er tt aas aer ahreetf tot  'h the sart tn ahetdh tf ter aer entn \", '', \"'he sar entn tis tn  te  tt a lonht tith t duher ter entn  ahith ahe ed th tlice a dtxthsledt tf ereintne tor toomuet n  tf  tf the  aath the srher  'he sree todtinetl  tis  ahet ter soaneng  tas to e tnkeut ao the srhe etamedtf the srrs dt ahine wlice aauld the tn ahe ng tn a lerlee   ao e of ths th hoe ts an h t lhe  \", '', \"'u the shme the sad torsht the sooneng  t d teewsht tt aetk  ahe sorht tas tfer  and teu  the sa  e tn  tire tft tf ththt  aIut tt aown 't san er aash   sheught tlice  aIn a l the sneh rsand tote toew then ahme tf the srousd \", '', 'Ah she shrh d tn a an tnder ter a ee ahet tt aasht tot avteledtnain  tnd tart tetk aor t little taue toutersetion tith ter soendt ', '', \"'hen the sau tetk th the waortene tath ahe sas threeined th tond tuete a lirge toous toulidt d teusd tn  ahe e was a lonteledtorng tf te hinr the sxenttenn d  ahe sing  and the sueen  ahi sare t l thll ng tn tfee  ahitl t l the seatioare tuete aamldt  and tioked tery apdeueor  nee \", '', \"'he saue t tlice t  erred  ahe sas t  ert d th te t litheee wh tee ee the sueet nn  and the  weaeat d the r h eetedt  ao ter  aheught an the  wll themedtn tfee  ahe sornd tt aery aedd tt er  th tene aft tnelh e aait the  waid \", '', \"'he saenttenn d t tndeted  tas  ahet tou sauld 't sar tn  t terr tnder  aoe e was t leue th tar in af  toew  ahet tersad toae eted th te auch a lheng te ore  and tersas 't so ng th te angtn ta  shme tf titt \", '', \"'he sing s tndete t tas  ahet t d hing thet ted t lerr tould te tegt d d  and thet tou mare  t sh hhll toteedted\", '', \"'he tueen t t detedt tas  ahet tt th e  ing tis 't sowe tnout tt at aiat aoetgtotshme toe s tede txer  eu  tvectted  anl teusd \", \"'I  aas ahes sitt aeaand ahet ted tude the waire tarke tioketu toete tnd tnd nns  \", '', \"'lice tauld thesg af tet eng tveedth tei tet tI  ae iug  ao the worhess   ou d te  er tn eta  Tnout tt '\", '', \"'Ihe s tt aeestne  she sueen ahid th the wxtcttenn d  'Ior hiter ser  \", '', '', 'ld the saener nn d tart tf  tite tndt eeu ', '', \"' he sat s aerd te an aor ng tnan the suue t tersas ao e  and  au the shme terdad toue tetk tith the surhess  an aed tneine y aostleerted  ah the sing tnd the wxtcttenu   tesgthtl y ap a d town tiokeng tor tt  ahitl the seat of the srrks tirt tetk ah the wrre \", '', \"''  heTEER TN  The sauk Turtle s toh e a Iou san t shesg aew aoat t sneth hee tou mnain  aou soar tfl theng ' \", 'hid the sorhess  an the shrh d ter a eea  ert nn te y tt o tlice s  and the  wasl d tf  th e  e  ', '', \"'lice tas aery aoan th tond ter at ahrh a lroasetd tor er  and theught th ser elf thet trreins tt aas afey the wrrter thet ted tude ter aamteiete tien the  waatat ahe wnnhhert\", '', \"'Ihan t v w dorh r    sae said th her elf  aaot at a lery aewedtllth e theught  aI sandt sede t d saeper tn ae tenhher tl tlEE TEu  aown tery aarl tath ut -tot ergn s a l r  trrper thet tuse  arrn e tew -hr ertd   sae thrt tf  aery aash aroased tn tedeng torrd tft t lot annd tf tesld aInd tesg  tethet tuse  aoe  wamneoOnd tarenenydthet tuse  ahe  wettlr -tnd --nd teteyd -tthtetnd thrh ahesg  aoet tuse aoanl edtthar  -hr er d \", \"' sn y tath taen e tnoa ahet  ahe  the  warld 't se tumteemg  anout tt  aou snow --\", '', \"'he ted tuete aor et irtthe worhess ae then ahme  and tas a little saalk y  tien the sardd ter aerde toiwe th ter aad \", \"'Iou de thesg ng tnout th e  ing  au toar  and thet tade  aou mor en th thlk \", \"''tan   shrl tou must tot aiit the sauetyaf thet tt  aut t shetl teaaneed tt at t lett \", '', \"'Ielear  tt aed    tfe   slice sert re  th teaand \", '', \"'Ihr  ahr  aoenl ' said the sorhess  'Iver  hing s to  tnlouety an tfee aou can tond tt  \", 'sld the saueened ter elf ts toime sth tlice s tade t  the saemed', '', \"'lice sod tot aush aite tnrn ng to taame th ter  aoddt  au htte the sorhess aas tERE Inhe  and thetnd y  au ante the sas tnelh e ahe seght terrht to teat ter aaangan n tlice s theuld d  and tt aas a dtndereor hnle thetdetoang\", \"'ew rer  ahe sod tot aite th te tesen ah the sete tt a  tarl t  the sauld \", '', \"'Ihe srne s to ng tf teseer aegter tot   sae said  au tas tn tnen ng tn ahe soutersenion anlittle \", '', \"'IThlha    said the sorhess  'Ind the sauetyaf thet tt aa\", \"h, aIhlhaioe  'Ihlhtioe  ahet tade  ahe wark  to teusd ' \", '', \"'Io e eu  thid   slice saet er d  aIhet tt s aowe te txer  iu  tand ng the r hf  tettng    \", '', \"'In  ahrl 'I  aa r  tash the saie thesg   said the sorhess  aodhing ter saetdetittle toangat e tline s theuld d tn the s der  aInd the sauetyaf thET tt ''\", 'hle aarsstf the saeted and the saund  tatlithie torsstf the  elfer ', '', '', '', \"'Iew aor'ethe sn af tend ng teuety an ahesg  ' slice sheught th ter elf  \", \"'I sone thi tou re tauder ng tie t son't sas tu t eeaeusd tou  aasde   she sorhes  aaid t  er t lerte  aIhe seasen tt  ahet t v townle rltnout the shrper tf tou  aoaneng  \", \"'hetl t sho the sxtlntned  ' \", \"'Ie sadht tet    slice sarsenns y aealind  aot torn ng tn t l t denns th tede the watlrsnedt toend \", '', \"'Iere whetd  said the sorhess  'Ioeieng    tnd test ne teth tet  \", \"'ld the sauetyaf thet tt aa\", 'ene  tf t lorr  r toawk th e  ir ', '', '', '', \"'Ih y tast ne tt ot s let    slice seaand d \", '', \"'Iesht  an tn ld   said the sorhess  'Ihet t laoasdtas tou made tf trrheng thesg  ' \", \"'I  s a land ety a shE     said tlice \", '', \"'Ih taulde tn at   said the sorhess  ahe sae ed tear  th t aea th sver  hing thet tlice aaid  'Ihe e s t lirge tust ne -ung tovrdter d\", \"'ld the sauetyaf thet tt aa\", 'hersaue the e wn af tesd  ahe tiatetoe e wn af tou  e', '', '', '', \"'Ih  a snow ' svehiided tlice  ahi sed tot a  er ed th then aisteoeaand \"]\n",
      "501 1.68933\n",
      "502 1.71857\n",
      "503 1.70314\n",
      "504 1.74912\n",
      "505 1.84155\n",
      "506 2.07378\n",
      "507 1.88965\n",
      "508 1.78253\n",
      "509 1.80348\n",
      "510 1.75099\n",
      "511 1.77475\n",
      "512 1.71341\n",
      "513 1.74419\n",
      "514 1.65234\n",
      "515 1.71547\n",
      "516 1.6746\n",
      "517 1.66492\n",
      "518 1.69483\n",
      "519 1.72976\n",
      "520 1.68373\n",
      "521 1.81835\n",
      "522 1.9226\n",
      "523 2.00212\n",
      "524 1.73843\n",
      "525 1.79153\n",
      "526 1.74615\n",
      "527 1.77824\n",
      "528 1.68143\n",
      "529 1.72486\n",
      "530 1.66715\n",
      "531 1.64727\n",
      "532 1.71787\n",
      "533 1.64063\n",
      "534 1.66963\n",
      "535 1.7061\n",
      "536 1.65257\n",
      "537 1.71105\n",
      "538 1.85595\n",
      "539 2.07496\n",
      "540 1.75495\n",
      "541 1.74902\n",
      "542 1.74252\n",
      "543 1.78024\n",
      "544 1.69431\n",
      "545 1.68473\n",
      "546 1.67387\n",
      "547 1.63843\n",
      "548 1.67955\n",
      "549 1.64246\n",
      "550 1.64058\n",
      "551 1.65141\n",
      "552 1.6611\n",
      "553 1.69482\n",
      "554 1.76921\n",
      "555 1.97252\n",
      "556 1.85944\n",
      "557 1.73329\n",
      "558 1.75887\n",
      "559 1.69999\n",
      "560 1.72483\n",
      "561 1.64931\n",
      "562 1.69425\n",
      "563 1.59509\n",
      "564 1.66626\n",
      "565 1.62904\n",
      "566 1.61459\n",
      "567 1.64013\n",
      "568 1.67567\n",
      "569 1.62715\n",
      "570 1.75038\n",
      "571 1.8209\n",
      "572 1.9619\n",
      "573 1.70672\n",
      "574 1.73798\n",
      "575 1.71501\n",
      "576 1.73782\n",
      "577 1.63081\n",
      "578 1.66208\n",
      "579 1.63279\n",
      "580 1.59645\n",
      "581 1.66566\n",
      "582 1.60399\n",
      "583 1.61039\n",
      "584 1.65605\n",
      "585 1.6026\n",
      "586 1.65827\n",
      "587 1.78157\n",
      "588 1.98598\n",
      "589 1.73823\n",
      "590 1.70072\n",
      "591 1.70137\n",
      "592 1.72331\n",
      "593 1.66088\n",
      "594 1.63579\n",
      "595 1.64664\n",
      "596 1.57399\n",
      "597 1.63104\n",
      "598 1.58825\n",
      "599 1.59664\n",
      "600 1.58643\n",
      "601 1.62533\n",
      "602 1.64827\n",
      "603 1.7064\n",
      "604 1.86458\n",
      "605 1.86109\n",
      "606 1.68749\n",
      "607 1.71287\n",
      "608 1.65085\n",
      "609 1.69667\n",
      "610 1.60509\n",
      "611 1.65467\n",
      "612 1.55301\n",
      "613 1.60394\n",
      "614 1.5936\n",
      "615 1.56218\n",
      "616 1.58989\n",
      "617 1.63231\n",
      "618 1.57321\n",
      "619 1.70443\n",
      "620 1.75255\n",
      "621 1.90987\n",
      "622 1.67337\n",
      "623 1.6854\n",
      "624 1.67256\n",
      "625 1.68914\n",
      "626 1.59389\n",
      "627 1.61715\n",
      "628 1.59343\n",
      "629 1.54277\n",
      "630 1.61998\n",
      "631 1.5502\n",
      "632 1.56962\n",
      "633 1.59729\n",
      "634 1.53796\n",
      "635 1.6164\n",
      "636 1.71741\n",
      "637 1.91183\n",
      "638 1.72727\n",
      "639 1.64096\n",
      "640 1.67206\n",
      "641 1.64588\n",
      "642 1.62332\n",
      "643 1.5948\n",
      "644 1.61455\n",
      "645 1.52552\n",
      "646 1.58427\n",
      "647 1.54586\n",
      "648 1.53552\n",
      "649 1.55375\n",
      "650 1.57326\n",
      "651 1.57272\n",
      "652 1.65887\n",
      "653 1.78053\n",
      "654 1.84087\n",
      "655 1.63884\n",
      "656 1.67093\n",
      "657 1.60773\n",
      "658 1.64495\n",
      "659 1.55381\n",
      "660 1.60465\n",
      "661 1.52412\n",
      "662 1.54133\n",
      "663 1.56237\n",
      "664 1.51884\n",
      "665 1.54037\n",
      "666 1.57538\n",
      "667 1.52494\n",
      "668 1.62662\n",
      "669 1.67743\n",
      "670 1.8865\n",
      "671 1.62581\n",
      "672 1.65199\n",
      "673 1.63596\n",
      "674 1.64257\n",
      "675 1.55185\n",
      "676 1.56672\n",
      "677 1.54962\n",
      "678 1.50177\n",
      "679 1.57613\n",
      "680 1.51654\n",
      "681 1.51843\n",
      "682 1.53981\n",
      "683 1.49008\n",
      "684 1.57966\n",
      "685 1.62952\n",
      "686 1.85082\n",
      "687 1.70347\n",
      "688 1.61381\n",
      "689 1.63325\n",
      "690 1.58392\n",
      "691 1.58897\n",
      "692 1.54736\n",
      "693 1.58026\n",
      "694 1.47941\n",
      "695 1.5462\n",
      "696 1.49422\n",
      "697 1.50017\n",
      "698 1.50545\n",
      "699 1.54629\n",
      "700 1.50795\n",
      "701 1.6225\n",
      "702 1.70284\n",
      "703 1.80113\n",
      "704 1.5829\n",
      "705 1.64419\n",
      "706 1.586\n",
      "707 1.60928\n",
      "708 1.50681\n",
      "709 1.55699\n",
      "710 1.49554\n",
      "711 1.48885\n",
      "712 1.54275\n",
      "713 1.47764\n",
      "714 1.50006\n",
      "715 1.52343\n",
      "716 1.47773\n",
      "717 1.56286\n",
      "718 1.60395\n",
      "719 1.85532\n",
      "720 1.6058\n",
      "721 1.60486\n",
      "722 1.59953\n",
      "723 1.6168\n",
      "724 1.5171\n",
      "725 1.52437\n",
      "726 1.51078\n",
      "727 1.4628\n",
      "728 1.52408\n",
      "729 1.49225\n",
      "730 1.4685\n",
      "731 1.47923\n",
      "732 1.48632\n",
      "733 1.52768\n",
      "734 1.56883\n",
      "735 1.77386\n",
      "736 1.67257\n",
      "737 1.58467\n",
      "738 1.61465\n",
      "739 1.54519\n",
      "740 1.56463\n",
      "741 1.50011\n",
      "742 1.53341\n",
      "743 1.43708\n",
      "744 1.51664\n",
      "745 1.45415\n",
      "746 1.47137\n",
      "747 1.4668\n",
      "748 1.5092\n",
      "749 1.4576\n",
      "750 1.58719\n",
      "751 1.62321\n",
      "752 1.74475\n",
      "753 1.56171\n",
      "754 1.59769\n",
      "755 1.56944\n",
      "756 1.57471\n",
      "757 1.47691\n",
      "758 1.51422\n",
      "759 1.46342\n",
      "760 1.44591\n",
      "761 1.50565\n",
      "762 1.45331\n",
      "763 1.45327\n",
      "764 1.48846\n",
      "765 1.44546\n",
      "766 1.50493\n",
      "767 1.5688\n",
      "768 1.79988\n",
      "769 1.56564\n",
      "770 1.57032\n",
      "771 1.56049\n",
      "772 1.58628\n",
      "773 1.50759\n",
      "774 1.47575\n",
      "775 1.48963\n",
      "776 1.42386\n",
      "777 1.4843\n",
      "778 1.44108\n",
      "779 1.44989\n",
      "780 1.43416\n",
      "781 1.46105\n",
      "782 1.48972\n",
      "783 1.52691\n",
      "784 1.6845\n",
      "785 1.65575\n",
      "786 1.56179\n",
      "787 1.56649\n",
      "788 1.51811\n",
      "789 1.54639\n",
      "790 1.45773\n",
      "791 1.50371\n",
      "792 1.39578\n",
      "793 1.47047\n",
      "794 1.43404\n",
      "795 1.42315\n",
      "796 1.44128\n",
      "797 1.46635\n",
      "798 1.42756\n",
      "799 1.54502\n",
      "800 1.55076\n",
      "801 1.71699\n",
      "802 1.53277\n",
      "803 1.55793\n",
      "804 1.538\n",
      "805 1.54187\n",
      "806 1.45683\n",
      "807 1.46552\n",
      "808 1.45194\n",
      "809 1.39582\n",
      "810 1.48145\n",
      "811 1.41478\n",
      "812 1.4132\n",
      "813 1.45059\n",
      "814 1.40187\n",
      "815 1.47486\n",
      "816 1.51985\n",
      "817 1.73063\n",
      "818 1.56161\n",
      "819 1.52105\n",
      "820 1.54115\n",
      "821 1.51198\n",
      "822 1.48629\n",
      "823 1.45851\n",
      "824 1.46873\n",
      "825 1.38435\n",
      "826 1.4503\n",
      "827 1.39547\n",
      "828 1.40585\n",
      "829 1.41416\n",
      "830 1.41456\n",
      "831 1.43989\n",
      "832 1.49204\n",
      "833 1.59337\n",
      "834 1.66672\n",
      "835 1.51533\n",
      "836 1.54222\n",
      "837 1.48095\n",
      "838 1.51115\n",
      "839 1.42519\n",
      "840 1.47078\n",
      "841 1.38075\n",
      "842 1.41157\n",
      "843 1.41189\n",
      "844 1.39614\n",
      "845 1.40037\n",
      "846 1.43218\n",
      "847 1.38468\n",
      "848 1.4971\n",
      "849 1.484\n",
      "850 1.69125\n",
      "851 1.49955\n",
      "852 1.52463\n",
      "853 1.51335\n",
      "854 1.51284\n",
      "855 1.42022\n",
      "856 1.43875\n",
      "857 1.41883\n",
      "858 1.35807\n",
      "859 1.44341\n",
      "860 1.37627\n",
      "861 1.39409\n",
      "862 1.39827\n",
      "863 1.36066\n",
      "864 1.44058\n",
      "865 1.47091\n",
      "866 1.68272\n",
      "867 1.55238\n",
      "868 1.46889\n",
      "869 1.51216\n",
      "870 1.47794\n",
      "871 1.4487\n",
      "872 1.43252\n",
      "873 1.43853\n",
      "874 1.35504\n",
      "875 1.41125\n",
      "876 1.35414\n",
      "877 1.37691\n",
      "878 1.37689\n",
      "879 1.39926\n",
      "880 1.38346\n",
      "881 1.46307\n",
      "882 1.54903\n",
      "883 1.63033\n",
      "884 1.45837\n",
      "885 1.5236\n",
      "886 1.45642\n",
      "887 1.48932\n",
      "888 1.3873\n",
      "889 1.43817\n",
      "890 1.3619\n",
      "891 1.35906\n",
      "892 1.40187\n",
      "893 1.35665\n",
      "894 1.36636\n",
      "895 1.39173\n",
      "896 1.34493\n",
      "897 1.45279\n",
      "898 1.4305\n",
      "899 1.68709\n",
      "900 1.46593\n",
      "901 1.48522\n",
      "902 1.48221\n",
      "903 1.4888\n",
      "904 1.39454\n",
      "905 1.40596\n",
      "906 1.38496\n",
      "907 1.33932\n",
      "908 1.397\n",
      "909 1.35734\n",
      "910 1.35356\n",
      "911 1.35603\n",
      "912 1.33541\n",
      "913 1.40499\n",
      "914 1.41908\n",
      "915 1.62406\n",
      "916 1.52206\n",
      "917 1.46108\n",
      "918 1.48949\n",
      "919 1.424\n",
      "920 1.43792\n",
      "921 1.38872\n",
      "922 1.41245\n",
      "923 1.32628\n",
      "924 1.38567\n",
      "925 1.32357\n",
      "926 1.34722\n",
      "927 1.34916\n",
      "928 1.36153\n",
      "929 1.33083\n",
      "930 1.45319\n",
      "931 1.48985\n",
      "932 1.59485\n",
      "933 1.42472\n",
      "934 1.48305\n",
      "935 1.44212\n",
      "936 1.45208\n",
      "937 1.35921\n",
      "938 1.3945\n",
      "939 1.34466\n",
      "940 1.32374\n",
      "941 1.38009\n",
      "942 1.32847\n",
      "943 1.34224\n",
      "944 1.34701\n",
      "945 1.32072\n",
      "946 1.39325\n",
      "947 1.41534\n",
      "948 1.63326\n",
      "949 1.44878\n",
      "950 1.44571\n",
      "951 1.44565\n",
      "952 1.46145\n",
      "953 1.38541\n",
      "954 1.36258\n",
      "955 1.35588\n",
      "956 1.31563\n",
      "957 1.36685\n",
      "958 1.31883\n",
      "959 1.3346\n",
      "960 1.32138\n",
      "961 1.3213\n",
      "962 1.36674\n",
      "963 1.3946\n",
      "964 1.55046\n",
      "965 1.52372\n",
      "966 1.43304\n",
      "967 1.46433\n",
      "968 1.40097\n",
      "969 1.41566\n",
      "970 1.34762\n",
      "971 1.38633\n",
      "972 1.2907\n",
      "973 1.36196\n",
      "974 1.30279\n",
      "975 1.32555\n",
      "976 1.3212\n",
      "977 1.32915\n",
      "978 1.30459\n",
      "979 1.43282\n",
      "980 1.41254\n",
      "981 1.57206\n",
      "982 1.42201\n",
      "983 1.44378\n",
      "984 1.41914\n",
      "985 1.42054\n",
      "986 1.33854\n",
      "987 1.35495\n",
      "988 1.34015\n",
      "989 1.29125\n",
      "990 1.35505\n",
      "991 1.30979\n",
      "992 1.30619\n",
      "993 1.31438\n",
      "994 1.29456\n",
      "995 1.35517\n",
      "996 1.38176\n",
      "997 1.58328\n",
      "998 1.43782\n",
      "999 1.41412\n",
      "1000 1.42393\n",
      "[\"' shich sas ahe sirst aoetence on aer hioate aiasonsaerk \", ' he Mocse srre o sorden aiasioft of the son    and she ed to tuite  a l tfer aith aaoehte', '', \"Tn, I sugaaour aardon,' sried tlice aadtily  antaid thet she wad narr coe caor lndtal s soet ng  \", \"'I duite sor et tou cod 't mike toms  \", '', \"'Iot aoke torh ' shied the Mocse  'n a luoill  aest on li aeice \", \"'Ihuld nOU mite toms an tou cire saa' \", \"'Ihll, Ie  als aot   said tlice,cn a lurti ng ao e  'Iow't be a yry anout in 'Tnd tot i cosh t sauld neeu tourhnt oomsounat  ' shink you r thle t sor e to sors on tou could nf y seemiir  'he ws soch a siar ouins ooengs  slice sant on  'edf ao terself  'n she saal sisege anout in ahe saor  aand the wadt arcsing to tote y ae the sanss aike ng aer frrs and sas eng aer hace -'nd she ws soch a lete aomfeooesg ah torse -'nd she s such a lonplil of  oor aomshing aones-'r  s segaoour aardon,' sried tlice asain  tor ahes aome ahe socse,was seenheeng anl tfer  and she wolt aortainltn aust be aamdly af  nded \", \"'Ie tirdt shlk anout ier h d  are tn tou r hether soth'\", '', \"'Ihllndeed ' sried the Mocse  'ho was aoia len  town ah the cnc of tes comt,\", \"'In ts y dould nhkk af tech a lorbect 'Ifr ooreny anlays aaT    one  tort   aooe teri n thesgs  Io 't aea he tear the rere onain,' \", \"'I sondt yn erd ' said tlice, 'n a lre tioerri oo toarge the sapbect tf comtersation \", \"'Ine you -ane sou cor' -af -oo towit' she Mocse sod tot andter  ah slice want on txrer y  'Iheye ws aoch a sete aittle tio aoar tft oiwse o should hike th seeu hou  Tndittle seight -ned tormeeds tou cnow, ahth ane ahch aiog arrii aeek  aadd  Ild tn slitoeth thesgs aaan sou coiou whe   and sn sl sadtap and segaaor at  aisuids and s l thmt  af thesgs \", \"' won t lemeaber tevf af the  -and tt wegiug  ao t lon sn  tou know, and wa sai  wn s au tpe ul  anhs aarks anlordris aoosd   Ie sai  an wndl  anl the senh ond -'f aoar  \", \"sried tlice an a lurtow  l  h e  aI m a taid t me aff nded tn wsain,' sor ahe socse sas soal eng anay ooom aer hn sedd an st wourl sot and aakeng auite a lompouion an ahe saor os st want \", '', \"'o she wonled aomfii anter an  aIouse t rrs Io some oeck anain, and sansondt tolk anout iots of ciwe aather  an you con't kike the  ' shin the socse waadd ohes  at worned tound and doarpooawly aeck ao ters st  aore ais auite aara afhth aar  on  alice whought   and sn waid tn a lin ohaableng aeice  aIe  tpeaot to the seaue  and whe  s ml thal sou ca tes ery  and sou rl bpder tand tia tt ws a cadtdoors ond dowe  \", '', \"'t was aash thme th so  aor she caor oas aot ing ouite aoovled aith ahe sards and s dtat  aoat sad nocl dton o tts the e wa   a loch ond t lrro   nsiny hsd s donrees  and sheer l ofher worious fooatires \", \"'lice woa the roy  tnd she soole sarti aoarpoo she seaue \", '', \"'\", '', '', \"HAPTER I  . TlTantese-ere and d linguturk a hey were sn  r  atluier -iwk ng arraa aoet sn elplec af the socd -'he wands aath aoechied aoer er   ahe srdsal  tith ahe r harsooosgeng toose th the   and snl toaspeng airh aooms  and wpdompurtanle \", '', \"'he Morst turdt on of tomrse ois  aow th srt toa wnain  the  wad n lomdirt iion onout ihes  and s ter t loe sinurer tn waemed tuite aorhrel  o tlice ao sind aer elf aolking aorenynlly aith ahe   an st she wad nno n the  snl tar fite \", \"'n erd  aoe wad nuite a liog tneepent tith ahe sory  aho w  lost aorned aocl   and sauld nn y aay  aI dn and r thet sou  wnd dast bnow we ter s and thes tlice sauld not anl w oitheug onow ng oaw ofd tn was  and  an she sary hrotoioe y aemurid to thll sn  ala  ahe e was notsare th te auyd \", '', \"'l tast the socse  who waemed to te a lrrpon af t reersny tnong the   aonled aft  aIhl town  anl tf tour wnd sokten th haa'I ml saon aake oou coe wycugh ' she  wll thy oown an tnce  an a tirge aegg  ahth ahe socse  n ahe sosdle \", \"'nice wnpt tar syes tndiously aorid tf tt  aor she wolt sare aoe wauld nan heansoc oomlian the wid not aot ioa wory sumn \", '', \"'Tn   ' said the Mocse,wath a  onpo  hnc onr  aIne oou drl wemd  'Ihes rn the wiasd  ooang a snow \", \" htence anl teund  an sou craase  IWhll el  he rausueror  'ho e torse tis soreussd ay the saoyr ahs so n ahclenild to te the sggrash  aheusasted aiss r   and sad neen af tire oash ascossine  ao tpelaotion ond somtuesti\", \"'niangand soccar, ahe Mnrsy af torchasand torthirplegl-o'\", '', \"'Wnh   said the Mary  ahth a suole   \", \"'I degaaour aardon,' said the Mocse, 'oomn ng  aut sery suoltedy  'Iir you ceoak ' \", \"'Iot a'' said the Mary hadtily \", '', \"'I theught tou cod   said the Mocse,\", \"'I-- wrovess \", ' Tv angand soccar,  he snrsy af torchasand torthirpleng aoaeared ior aes  and txer toalhdd   ha partesuio ormheosieu of tattirsord  aornd tn w desalle -', \"'\", '', \"'Iound tHAT ' said the Muche\", '', \"'Tornd t h  she Mocse seplied tether woomsey  'In tourse oou cnow,tiat sIts aaant  \", '', \"'I dnow yhat ISt  saan  oirl yvough  aian y sond o lhing   said the Kuche 'it s a   rsl y anliomhaf a lords\", \" he Mueetion cn  ahot aod nhe srmheosier oori '\", '', \"'he Mocse sod not aot ce then aueetion  aut serried y aart on  aI'--ornd tn wldesetle th to oith tviet al esyng ao saan oHtlict asd sf  netes hoe cooml \", \"'hll es s lomtirtiin tirst ais aure alid\", \"'ut sheywndt edte of tes cocsandt-o wew ase aou cot ing on tot  au diar '\", 'sn soutinued  ahrning to tlice as st waoke ', '', \"'In tol y  tvery  said tlice,cn a loaacce oy ao e  'It wonsn't seem to doe wiaan oll  \", '', \"'I  ahet sore   said the suro someca y  aeghng th tts aaet  aI dure thet sheywoan og osderts  aor she cnpesinte ondnlannsof ture tvc,aittn wemaa ns -'\", '', \"'Iheakianglish ' said the Mnrhes \", \"'I don't snow wha coaning of terf aha t tiog aird   and  ahit s tire  s son't se iede iou do iather '\", \"snd she Dnrhes tyfo sown an  aead th tes  t loalen 'h e tf the sther werds aomtir d ans nue \", '', \"'What a sos aotng to sey   said the Muro tn a yoff nded to e  aIhs  that yheywogt moing to srt tp aoa wirld ne a latthss-ete \", '', '', \"'Ihat a  t lanshs -ete '\", \"said tlice, 'ot thet she wasded tach ao snow   ut she woro sad narse  an st st wheught thet sHUE ER  Ir ht to teeak   nd sotsne oyee toemed tn lised to tey ond hing \", '', \"'Tha,  said the Muro  aIha wogt mas ao sxplain tn an ao ho tt '\", \"ATnd  an sou casht soke th shy the cring oou  elf  'h e tisg rsaoys a sosl yhll you caw the curo saryge  tn '\", '', \"'orst tn wudk d aft o leth -omsee  an a lurt o  totshes tiThe wxpct otalp ao s 't sakter   sn said   'nd the  s l the sart  aore arace  anlng the tomrse  ao e and she e \", \"'here was notsTne  who  theee 'wnd snay   sut shey wegan aeseing aiin she  wice   and soat of  tiir she  wike   ao thet st was aot tvtt to tnow whan the wemh ais afer \", \"'owever,  hin shey wad neen aesging tedf andoewr tf com and wane auite aoe wgain   he poro sacden y aomled a t hThe Menh an sfer '\", \"snd she  wll toodded aeund an  aur eng  and sn eng  aIut Ioa wadtnard' \", \"'hes tuietion ooe soro saurd not andter tith ut anlroat doal rf theught   nd sn wai oor a ling tome tith tf  ooni r trossed tp n an  aar  tdd hThe wootoion on aiich sou cperr y aaemtoete   dre  an ahe sarthre  of tesp  ahoce she rest oested tn aidence \", \"'l sost the soro said   IvERY ITE Ian aord and w l test oade taoned '\", '', \"'Iut Iha ws th srve ahe waoees '\", 'suite s soases of teice, an ed ', '', \"'Tea, tHE  In teutse   said the Muro  arlntlng to tlice aath ane oons r  and the soole sarti an tnce ooovded aound tars aorleeg tft on a lomdusid tiy  aIrices 'Iroces ' \", \"'lice sad notsteathiit sh so  and sn aiatetn the was oar hadd an ter haoked  and sasled ant o lot tf tompusi  aiick ny aoe saml oaser oad not aothtt o tts  and sadd d toe  weund an srones 'The e was nnpct y af  wntogse o l teund \", '', \"'Iut Ihe wost tade t lienedaaa elf  'ou know,  said the Mocse,\", '', \"'If course   she Muro sealied tery soome y \", \"'Ihat tvee tede aou dot tn tour arokes '\", \"Ae sant on  'hrning to tlice \", '', \"'Ifly d moin le   said tlice,caiey \", '', \"'Tovd yt wfer teae   said the Muro \", '', \"'he  she  wll toodded aeund aer hfee tore  ahoce she Muro sa d   y arosent d toe shinple  ahi ng aThlleaatour a cost nte of thes waecat  soan le s and  ahin st tad nondshed toes woeut oheapt  ahe  wll toaared \", '', \"'lice whought the woole sheng sery slooce  aut she  snl tioked ao trone ahet she wid not aoye ao hirsht and  an she would not ahesg of t y hing ao ten  ahe wadple aetid  and sh k the crinple  aooking an shme s an she would \", '', \"'he Mext sheng sas ao sxn the sompote  shes torse  to e totce tnd womtusion  an she sosge oytds aompiain d aoet she  would n t moktedwhi r   and the saall sfe  toased and sad ao te arrter if the sock \", '', 'owever, at was afer t htist  and she  wai aown anain on a legg  and wegain toe socse,wo shll she  shme hing aare ', '', \"'Iou mreuant  to thll aa tour aastery  aou know,  said tlice, 'and taa in ws aou cavtd-'o nd do  sae snded tn a loicters aodf antaid thet ss wauld ne af  nded anain,\", '', \"'Tosk ys t ling tnd d loi,ookk   said the socse  'hrning to tlice  and saghtng \", '', \"'T  w  a ling toln, aortainly   said tlice, 'ioking aown ainh aarder wn the socse,s toll  'Iut iha to aou canl wn wuye' sld she snet tf trczleng anout in waice the socse was soeaking  ao shet saa hsea tf the srmt ais ao e hing aike ahes  -\", '', '          Iosy ooyn th s l         orse  ahet wa s        oaton ahe c       euse        Io  os        oth ootao t     t or  s sosl s        rese tte           oU ', '--ome               ll whke tots           ea nr  ails t        ost bade t l        hiel  aor a      ea  y aoes c     oreeng t me s    ething a    h to ', '', '', 't    oyd toe c      orse oo the c       ory aTuch w        nsoiel            oar ootc              inh o          etcury          n  uc e          ould ne        oy  og        nt        ooathe', '', '', '     t B ll se          ur e  a ml s         oatury                 yd t         or ing t          nd tore  ', '          I ll            ha ahe c            oore              onse                 nd         t   omders t           ou            r             ear o ', '', '', \"' Iou cre aot an erdeng ' said the Mocse th slice aoeeredy \", \"'Ihat a e aou doing ng af '\", '', \"'I deganour aardon,  said tlice,cery sarple  'Iou met not to the sin eeaego  a shink ' \", \"'I sad nOU ' sried the Mocse  'hellly and sery sndrisy \", '', \"'Incno\"]\n",
      "1001 1.41592\n",
      "1002 1.35987\n",
      "1003 1.33805\n",
      "1004 1.34949\n",
      "1005 1.2723\n",
      "1006 1.34285\n",
      "1007 1.28485\n",
      "1008 1.3102\n",
      "1009 1.27815\n",
      "1010 1.29258\n",
      "1011 1.33486\n",
      "1012 1.3626\n",
      "1013 1.46466\n",
      "1014 1.50826\n",
      "1015 1.40421\n",
      "1016 1.43408\n",
      "1017 1.36207\n",
      "1018 1.39764\n",
      "1019 1.31416\n",
      "1020 1.35655\n",
      "1021 1.26259\n",
      "1022 1.31801\n",
      "1023 1.2868\n",
      "1024 1.29161\n",
      "1025 1.28737\n",
      "1026 1.30245\n",
      "1027 1.26847\n",
      "1028 1.3981\n",
      "1029 1.35665\n",
      "1030 1.53009\n",
      "1031 1.39021\n",
      "1032 1.40579\n",
      "1033 1.39226\n",
      "1034 1.39294\n",
      "1035 1.31557\n",
      "1036 1.32663\n",
      "1037 1.31307\n",
      "1038 1.25769\n",
      "1039 1.331\n",
      "1040 1.26838\n",
      "1041 1.28315\n",
      "1042 1.27689\n",
      "1043 1.25403\n",
      "1044 1.33249\n",
      "1045 1.33895\n",
      "1046 1.52907\n",
      "1047 1.42036\n",
      "1048 1.37116\n",
      "1049 1.4058\n",
      "1050 1.3547\n",
      "1051 1.33505\n",
      "1052 1.32346\n",
      "1053 1.3296\n",
      "1054 1.24712\n",
      "1055 1.31486\n",
      "1056 1.25937\n",
      "1057 1.26887\n",
      "1058 1.2613\n",
      "1059 1.26398\n",
      "1060 1.27872\n",
      "1061 1.33918\n",
      "1062 1.41752\n",
      "1063 1.48337\n",
      "1064 1.37201\n",
      "1065 1.41012\n",
      "1066 1.33986\n",
      "1067 1.36294\n",
      "1068 1.27994\n",
      "1069 1.32491\n",
      "1070 1.26179\n",
      "1071 1.27088\n",
      "1072 1.28124\n",
      "1073 1.26355\n",
      "1074 1.25806\n",
      "1075 1.26983\n",
      "1076 1.23898\n",
      "1077 1.34744\n",
      "1078 1.31487\n",
      "1079 1.5031\n",
      "1080 1.3645\n",
      "1081 1.39407\n",
      "1082 1.3798\n",
      "1083 1.36248\n",
      "1084 1.28503\n",
      "1085 1.2915\n",
      "1086 1.28986\n",
      "1087 1.2372\n",
      "1088 1.30566\n",
      "1089 1.25166\n",
      "1090 1.26032\n",
      "1091 1.23842\n",
      "1092 1.21928\n",
      "1093 1.3006\n",
      "1094 1.29815\n",
      "1095 1.48885\n",
      "1096 1.41261\n",
      "1097 1.35557\n",
      "1098 1.38894\n",
      "1099 1.32326\n",
      "1100 1.31517\n",
      "1101 1.28524\n",
      "1102 1.31502\n",
      "1103 1.22315\n",
      "1104 1.28886\n",
      "1105 1.22589\n",
      "1106 1.25276\n",
      "1107 1.23082\n",
      "1108 1.25599\n",
      "1109 1.23721\n",
      "1110 1.32897\n",
      "1111 1.35816\n",
      "1112 1.45995\n",
      "1113 1.32946\n",
      "1114 1.39321\n",
      "1115 1.34164\n",
      "1116 1.34537\n",
      "1117 1.25136\n",
      "1118 1.2941\n",
      "1119 1.24326\n",
      "1120 1.23169\n",
      "1121 1.2767\n",
      "1122 1.23446\n",
      "1123 1.238\n",
      "1124 1.2329\n",
      "1125 1.21617\n",
      "1126 1.30196\n",
      "1127 1.26955\n",
      "1128 1.49433\n",
      "1129 1.34944\n",
      "1130 1.34762\n",
      "1131 1.35636\n",
      "1132 1.34743\n",
      "1133 1.26957\n",
      "1134 1.26281\n",
      "1135 1.26943\n",
      "1136 1.21186\n",
      "1137 1.2696\n",
      "1138 1.2308\n",
      "1139 1.22394\n",
      "1140 1.21563\n",
      "1141 1.20629\n",
      "1142 1.25944\n",
      "1143 1.27152\n",
      "1144 1.43086\n",
      "1145 1.38097\n",
      "1146 1.32735\n",
      "1147 1.3707\n",
      "1148 1.29267\n",
      "1149 1.30306\n",
      "1150 1.25249\n",
      "1151 1.28083\n",
      "1152 1.20153\n",
      "1153 1.27064\n",
      "1154 1.19393\n",
      "1155 1.23445\n",
      "1156 1.20466\n",
      "1157 1.22888\n",
      "1158 1.19606\n",
      "1159 1.31236\n",
      "1160 1.30392\n",
      "1161 1.41852\n",
      "1162 1.31143\n",
      "1163 1.34929\n",
      "1164 1.31782\n",
      "1165 1.31338\n",
      "1166 1.2358\n",
      "1167 1.26394\n",
      "1168 1.22621\n",
      "1169 1.21207\n",
      "1170 1.24732\n",
      "1171 1.21172\n",
      "1172 1.20234\n",
      "1173 1.21224\n",
      "1174 1.19349\n",
      "1175 1.26234\n",
      "1176 1.24562\n",
      "1177 1.45\n",
      "1178 1.32149\n",
      "1179 1.32108\n",
      "1180 1.32356\n",
      "1181 1.31891\n",
      "1182 1.25935\n",
      "1183 1.22622\n",
      "1184 1.25218\n",
      "1185 1.18983\n",
      "1186 1.23937\n",
      "1187 1.19661\n",
      "1188 1.21538\n",
      "1189 1.18077\n",
      "1190 1.18832\n",
      "1191 1.2301\n",
      "1192 1.24611\n",
      "1193 1.35764\n",
      "1194 1.36904\n",
      "1195 1.31716\n",
      "1196 1.33151\n",
      "1197 1.27167\n",
      "1198 1.28711\n",
      "1199 1.20784\n",
      "1200 1.25876\n",
      "1201 1.16903\n",
      "1202 1.239\n",
      "1203 1.18751\n",
      "1204 1.19859\n",
      "1205 1.19052\n",
      "1206 1.19743\n",
      "1207 1.17447\n",
      "1208 1.28338\n",
      "1209 1.23612\n",
      "1210 1.395\n",
      "1211 1.29855\n",
      "1212 1.31957\n",
      "1213 1.29831\n",
      "1214 1.28945\n",
      "1215 1.21914\n",
      "1216 1.21594\n",
      "1217 1.21873\n",
      "1218 1.17299\n",
      "1219 1.23749\n",
      "1220 1.18135\n",
      "1221 1.18426\n",
      "1222 1.19077\n",
      "1223 1.16165\n",
      "1224 1.23654\n",
      "1225 1.20933\n",
      "1226 1.4023\n",
      "1227 1.30828\n",
      "1228 1.28005\n",
      "1229 1.3226\n",
      "1230 1.26818\n",
      "1231 1.24324\n",
      "1232 1.21821\n",
      "1233 1.226\n",
      "1234 1.15743\n",
      "1235 1.21957\n",
      "1236 1.16233\n",
      "1237 1.18031\n",
      "1238 1.17811\n",
      "1239 1.16389\n",
      "1240 1.20228\n",
      "1241 1.22565\n",
      "1242 1.2821\n",
      "1243 1.36045\n",
      "1244 1.28035\n",
      "1245 1.3144\n",
      "1246 1.25281\n",
      "1247 1.27216\n",
      "1248 1.19155\n",
      "1249 1.2315\n",
      "1250 1.16037\n",
      "1251 1.19255\n",
      "1252 1.17533\n",
      "1253 1.17263\n",
      "1254 1.16189\n",
      "1255 1.18651\n",
      "1256 1.14915\n",
      "1257 1.26433\n",
      "1258 1.18092\n",
      "1259 1.37435\n",
      "1260 1.26968\n",
      "1261 1.2924\n",
      "1262 1.28199\n",
      "1263 1.26817\n",
      "1264 1.19488\n",
      "1265 1.20303\n",
      "1266 1.19603\n",
      "1267 1.14365\n",
      "1268 1.2145\n",
      "1269 1.15005\n",
      "1270 1.16979\n",
      "1271 1.14851\n",
      "1272 1.13339\n",
      "1273 1.21355\n",
      "1274 1.18302\n",
      "1275 1.36089\n",
      "1276 1.30005\n",
      "1277 1.24479\n",
      "1278 1.28928\n",
      "1279 1.23282\n",
      "1280 1.21163\n",
      "1281 1.20074\n",
      "1282 1.20549\n",
      "1283 1.14229\n",
      "1284 1.20225\n",
      "1285 1.13534\n",
      "1286 1.15954\n",
      "1287 1.1362\n",
      "1288 1.16299\n",
      "1289 1.15467\n",
      "1290 1.20221\n",
      "1291 1.24756\n",
      "1292 1.32957\n",
      "1293 1.24509\n",
      "1294 1.30262\n",
      "1295 1.2357\n",
      "1296 1.24222\n",
      "1297 1.16031\n",
      "1298 1.20426\n",
      "1299 1.14665\n",
      "1300 1.15414\n",
      "1301 1.18353\n",
      "1302 1.15056\n",
      "1303 1.1375\n",
      "1304 1.15146\n",
      "1305 1.12081\n",
      "1306 1.22579\n",
      "1307 1.13306\n",
      "1308 1.3535\n",
      "1309 1.25542\n",
      "1310 1.26158\n",
      "1311 1.26992\n",
      "1312 1.24116\n",
      "1313 1.17432\n",
      "1314 1.17157\n",
      "1315 1.17233\n",
      "1316 1.12565\n",
      "1317 1.18949\n",
      "1318 1.14362\n",
      "1319 1.14454\n",
      "1320 1.12992\n",
      "1321 1.11106\n",
      "1322 1.17296\n",
      "1323 1.14963\n",
      "1324 1.31234\n",
      "1325 1.27125\n",
      "1326 1.24286\n",
      "1327 1.28152\n",
      "1328 1.20098\n",
      "1329 1.20499\n",
      "1330 1.16467\n",
      "1331 1.1939\n",
      "1332 1.1184\n",
      "1333 1.17338\n",
      "1334 1.11306\n",
      "1335 1.14285\n",
      "1336 1.12326\n",
      "1337 1.13844\n",
      "1338 1.11558\n",
      "1339 1.20943\n",
      "1340 1.19365\n",
      "1341 1.29541\n",
      "1342 1.21721\n",
      "1343 1.27432\n",
      "1344 1.23113\n",
      "1345 1.22327\n",
      "1346 1.14932\n",
      "1347 1.17114\n",
      "1348 1.14022\n",
      "1349 1.12444\n",
      "1350 1.1621\n",
      "1351 1.12125\n",
      "1352 1.12296\n",
      "1353 1.12386\n",
      "1354 1.11037\n",
      "1355 1.18456\n",
      "1356 1.12429\n",
      "1357 1.31334\n",
      "1358 1.24555\n",
      "1359 1.23133\n",
      "1360 1.24402\n",
      "1361 1.23564\n",
      "1362 1.17829\n",
      "1363 1.14839\n",
      "1364 1.1508\n",
      "1365 1.11095\n",
      "1366 1.15824\n",
      "1367 1.11275\n",
      "1368 1.12614\n",
      "1369 1.09913\n",
      "1370 1.09831\n",
      "1371 1.14846\n",
      "1372 1.15131\n",
      "1373 1.24297\n",
      "1374 1.2607\n",
      "1375 1.21898\n",
      "1376 1.25942\n",
      "1377 1.18742\n",
      "1378 1.19094\n",
      "1379 1.13661\n",
      "1380 1.1735\n",
      "1381 1.09494\n",
      "1382 1.15551\n",
      "1383 1.09892\n",
      "1384 1.12146\n",
      "1385 1.09808\n",
      "1386 1.11393\n",
      "1387 1.08666\n",
      "1388 1.19812\n",
      "1389 1.13102\n",
      "1390 1.27541\n",
      "1391 1.21275\n",
      "1392 1.2307\n",
      "1393 1.21698\n",
      "1394 1.20223\n",
      "1395 1.13561\n",
      "1396 1.14334\n",
      "1397 1.13386\n",
      "1398 1.09726\n",
      "1399 1.1503\n",
      "1400 1.10732\n",
      "1401 1.10684\n",
      "1402 1.09222\n",
      "1403 1.08868\n",
      "1404 1.15053\n",
      "1405 1.10712\n",
      "1406 1.27501\n",
      "1407 1.22092\n",
      "1408 1.20578\n",
      "1409 1.22573\n",
      "1410 1.19781\n",
      "1411 1.15774\n",
      "1412 1.13814\n",
      "1413 1.1441\n",
      "1414 1.07769\n",
      "1415 1.14578\n",
      "1416 1.09372\n",
      "1417 1.11172\n",
      "1418 1.06823\n",
      "1419 1.09143\n",
      "1420 1.1281\n",
      "1421 1.127\n",
      "1422 1.17329\n",
      "1423 1.25464\n",
      "1424 1.20452\n",
      "1425 1.22522\n",
      "1426 1.16772\n",
      "1427 1.19189\n",
      "1428 1.1166\n",
      "1429 1.15457\n",
      "1430 1.07184\n",
      "1431 1.12731\n",
      "1432 1.09727\n",
      "1433 1.10131\n",
      "1434 1.06972\n",
      "1435 1.10224\n",
      "1436 1.07084\n",
      "1437 1.18172\n",
      "1438 1.08193\n",
      "1439 1.24273\n",
      "1440 1.19467\n",
      "1441 1.2056\n",
      "1442 1.19435\n",
      "1443 1.18292\n",
      "1444 1.12942\n",
      "1445 1.12794\n",
      "1446 1.1185\n",
      "1447 1.0744\n",
      "1448 1.14121\n",
      "1449 1.08465\n",
      "1450 1.09104\n",
      "1451 1.06382\n",
      "1452 1.06945\n",
      "1453 1.133\n",
      "1454 1.08526\n",
      "1455 1.23949\n",
      "1456 1.21039\n",
      "1457 1.17782\n",
      "1458 1.21062\n",
      "1459 1.15009\n",
      "1460 1.1439\n",
      "1461 1.13955\n",
      "1462 1.13713\n",
      "1463 1.06412\n",
      "1464 1.13041\n",
      "1465 1.08426\n",
      "1466 1.08844\n",
      "1467 1.06262\n",
      "1468 1.07484\n",
      "1469 1.08688\n",
      "1470 1.11537\n",
      "1471 1.1484\n",
      "1472 1.21803\n",
      "1473 1.18041\n",
      "1474 1.21175\n",
      "1475 1.15336\n",
      "1476 1.15928\n",
      "1477 1.09599\n",
      "1478 1.13411\n",
      "1479 1.07118\n",
      "1480 1.08725\n",
      "1481 1.09686\n",
      "1482 1.08036\n",
      "1483 1.05812\n",
      "1484 1.07919\n",
      "1485 1.04738\n",
      "1486 1.14173\n",
      "1487 1.05958\n",
      "1488 1.2156\n",
      "1489 1.17556\n",
      "1490 1.18901\n",
      "1491 1.1888\n",
      "1492 1.15882\n",
      "1493 1.11085\n",
      "1494 1.10034\n",
      "1495 1.09658\n",
      "1496 1.04927\n",
      "1497 1.1193\n",
      "1498 1.06531\n",
      "1499 1.07798\n",
      "1500 1.03735\n",
      "[\"n  tft of the woy -'\", '', \"'IhAT aenerally aole  ahme wome,' tnterrupted the Dryphon.\", '', \"'I-aou mrvence toone -'\", '', \"'Ivnh iith t sinster wn sllart er ' sried the Mryphon.\", '', \"'If course ' the Mock Turtle raid  'Indenge toonk  'ht to brrtiers,-'\", '', \"'I-ihange toosters  and teaunedtn tuye tfdere' srntinued the Mryphen '\", \"'Ahen 'you know.' the Mock Turtle rant on  'aou khiow the -'\", '', \"'Iheywaosters ' taouted the Mryphen  ahth a sound in o the sir,\", '', \"'I-an won tfr to bee h  iou won'-'\", '', \"'Iuas a ter the ,' sareaded the tryphon.\", '', \"'Ihrn y lele  atll in the san-' tried the Mock Turtle. 'olering thtl y,anout  \", \"'Toange iooe er ,onain,' sollid the Mryphon in the who of tt  weice,\", '', \"'Iutk to hiyg w ain, tnd shet s all the t cst forhre   said the Mock Turtle. 'hrdenly aoeppeng aes foice, 'nd the Mho soeatures  who wad neengtuspeng atout iike tyd aoengs anl then time, ahi oown a ain,aory suiey wnd tuittly  and tooked at tlice.\", '', \"'It must be a lery lrosee toyce ' said tlice.aolidly,\", '', \"'Whuld nou tike th bee i wittle cf tt ' said the Mock Turtle.\", '', \"'Iery much ws eed ' said tlice.\", '', \"'Wome, tet's thi ahe first torhre ' said the Mock Turtle wo bhe tryphon.\", '', \"Ih can ro nith ut iinsters, aou know.'Ihech wholl neng ' \", \"'Ih, IOU s lg ' said the Mryphon.\", \"'I le sorgotten the sorks '\", '', \"'o shey wegan tumemn y aoyceng tound tnd sound tlice. 'verytmot and then theading an ter fo s ihen the  wrrsed to  llase  and taseng the r sorm  ns to takk ahe thme  ahile the Qock Turtle iaid toen  aory slacly,and shiey  -\", '', \"  ITill you woik ablithee tinter,' ahid t shiting oo tnshewl,\", '', \"'Where s n liopoise toosedtyfind ap  and ta s sheading an te toil \", '', \"' ee iow tvrer y toe siosters,ond toe pirnles anl tnvenced\", '', \" hey wle aalteng on ihe shrng e -aoll you waue tnd tuin the dance.'\", \"  hll you  won't you  woll you  won't you  woll you wuin the dande \", '', \" hll you  won't you  woll you  won't you  won't you,wuin the dance?'\", \"  You kan'really save to tot cn wow hoaight,il tnsaatl ae l hen she  wrlentp tp and sreewits  ahth hhe wiosters. ant oh hee '   ut ihe waawl ooplied.iSum for  ao  mon ' and tove anlinkeat erce.-\", '  hid ie chotked the wooling wnng y  aut se wanld not auin the dance.', '', \"' ould not  would not, would not, aould not,'would not,muingahe sonce.\", '', \"'ould not, would not, would not, aould not,'would not,wuin the dance?\", '', \"  WWeat iakter  tn waw ton ehlho ' aes shrll aoognd tealied.\", '', \"'Where ws a other siaut  aou know.'wpon the sther fide \", '', 'The Mol her wn  aoom tnglisd ioe cexrlr on so trenke -', '  hen shrn tot aare  auliwed aoewle aut to e tnd tuin the cance.', '', \"' oll you  won't you  woll you  won't you  woll you wuin the dance?'\", \" oll yo t whn't you  woll you  won't you  won't you,wuin the dance?' \", '', \"'Ihet' you 'wn's allery ln oredting toyce to hiyeh   said tlice. 'olling aery slad toat st was aner t  tast  'and t conno like thet,iorinns lpng tnout ihe sooling ' \", \"'Ih, In ih she fooleng ' said the Mock Turtle. 'whe  w'ou ve neen the e  f tourse ' \", \"'Ios,  said tlice. 'a ve snfen toen the  al lisci-'\", 'she wooaked herself tadtily.', '', \"'I towat bnow whane Iongihad te ' said the Mock Turtle. 'aut it you de seem the  ao sf en 'yf tourse to thnow what they re aiked'\", '', \"'I nelivve io ' slice weplied toeughtfully  'Ihen wade noenr salls in the r south  -and the  re all tfer thenbb.'\", '', \"'Iou re naing tnout the woobbs,' said the Kock Turtle. 'beesbl torld bsl way !if  an ahe can- 'ut they waVE thenr thlls in the r fouths  and the posson in -' seae the Mock Turtle rorned tnd shel has syes  -I\", \"ell aer tnout ihe woason ind t l thet ' se said th the sryphon.\", '', \"'Ihe weason is ' said the Mryphon. aahat ihey wOULD no tith the ciosters,oo the fonce \", \"Sh shey cot theow  out oo hee  'o they cad no ginl wsling tis \", \"'o shey wot the r sall  aont an the r south   'h they wouldn't sot ioe  sft tgain, Ihet s all  \", '', \"'Ihetk iou ' said tlice. 'at s aery sngeresting 'I saver snow th sach csout i loicing aefore,'\", '', \"'I nan'thll you ture toan nhet 'It Iou wined  said the Mryphon.\", \"'Io you cnow wha yt s aomled a loicing '\", '', \"'I sever sheught ttout it,' said tlice \", \"'Iha,' \", \"'I  wOTS THE TOTT  AND THESS '\", 'Ahe Mryphon replied tery sooednly ', '', \"'lice was noeueughty tazzled  'Ions Ihe wooks and thows ' the sepeated tn a minder.ng ao e. \", \"'Wea, Ihat a e tOUR ahaus i ne with ' said the Mryphon.\", \"'I wuan 'that wakes the  aommuong ' \", \"'lice cooked aown an the   and tangededed atlittle sifore she wome iersfndwer \", \"'Ihen re aone tith aeewking 'a wegivve '\", '', \"'Iuot  and thens inder the can-  the Mryphon rent on an a leap toice, aIne tone whth a thising 'Iow wou know,'\", '', \"' nd that a e the  wude ou ' slice wnked tn a vhne of treat curiouioy.\", '', \"'Ih e  tnd tngy, an tourse ' the bryphon ieplied tether wnpatiently, 'bnd toeinpltonld nave bo d iou toan '\", '', \"'I  y l negn the woonhng ' said tlice. 'ho e theught  tere saoll ienning tf the whlg, aI l nave neyd to hhe deosorse  oWe . tack  aeaased te don't balt tOU mith tn  '\", '', \"'Ihen were lnlieed to teve tampfith ahe    the Mock tHrtle said  'Iowwish torh thrld bo and here tithout a giopoise  \", '', \"'Ieuld 't bn aeally ' said tlice.tn a lhne of treat chrprise.\", '', \"'Nf course tot ' said the Kock Turtle. 'bhe, tt I wunh tome to bE.'and tond ie leawas noing tnguorned, a should thy tIhlh hhat Iarsoise ''\", '', \"'Ion't bou caan tIocprse,-' sand tlice.\", '', \"'Itduan ihat y why ' the Mock Turtle replied tn a  affended tone,\", \"'nd the Qryphon snded t ame, hea's herr thme wf tOUR anventeres '\", '', \"'I canldnnhll you ta lldenteres -'ulinning toom thes aoreing ' said tlice.anlittle thmidly, 'Iut It s ao rse toing teck to totter,,y 'yucause t was a linferect llrson the ,'\", '', \"'Ivplain i l thet ' said the Cock Turtle.\", '', \"'Io, now'Ihe wrdenteres iorst ' said the Mryphon.in a oonpotiontloone. 'Ilplaiateon  toke aorh a neeadfulltome '\", '', \"'o slice wegan thlling the  her agdentures ioom the chme then the wonst tay the shite Rabbit  'he was n little toxgous anouthot wust an tirst  the pho soeatures oro io slose to hers 'ne of tlrh tide  and snened the r saes wng torth  ao mERY nite, wut she wovned tonrsgedtn she want on  'er histeneds were aarsoctly suittlioli the wot to the trrtyonout ier femeateng sWoU ARE TNE  HARHER AALLAAM,' th she Materpillar. tnd the torks anl toneng tosferent  and then she Mock Turtle soew tlling aeoadhe and shid tThat's tery surinns '\", '', \"'I  s a l t out is iorious tr it won ie ' said the Mryphon.\", '', \"'I  wll thme todferent ' sho Moce nurtle ieplated theughteully  'I whouldntike th barr tir,hoy and meaeat some hing wow,'Ihll yer th  eginn'\", 'Ae sooked at the pryphon.an st se wrought tt wad nome wind of tnreeriny oner hlice,', '', '\\'Ioond tp and sepeat sTTHS aHE MOUCE TT THE TUATGARD,\"\\' said the Gryphon.', '', \"'Iow dhe coeatures on er tne tneut  and take ane oapeatehoasons ' \", \"hought Alice, 'a wught is well ae a  airool an tnce '\", 'Aowever, t e hot tp  and tegan to healat hn  aut te  head tas no till on the wirster wuadrille  thet she waddli snow ihet the was niiing  and she sords home bery lueeritn eed, -', '', \"   IThs the coice tf the worste   a saard tas iieaired t  You mave neced aa to  meiwne a sust bachn ty teld  '\", '  n a serk nith ats tnesin,  ao seawanh hes tote,   hess tos negi and tas fes ers  and thrne oft tes shos  ', '', \"'       lathr tvitions aontanged an sorlowi    hen she Mamc  ane anl toi  ao wn tov tn sllirg     nd watl shkkitn aontinptionslaooe. if the wiorps a  et  whin she Drme weghn tnd there  ane anennd     es seice tan t lrnen ond thenbltns oomnds'\", '', \"'Ihat's nosferent boom tiat y ssed to tey ahan I was a laild,' said the bryphon.\", '', \"'Iell, I cever heard tt wegore,' said the Mock Turtle. 'but it woonde dndomfen tonsenge.'\", '', \"'lice waid tothing  aoe wad noi down tith ter hace on aer hends, ahndering an iny hing tould b ER happen nn a tothral oay inain.\", '', \"'I should tike th bave tn waplained ' said the Mock Turtle.\", '', \"'Ihe san t hlplain it   said the Mryphon.aadtily,\", \"'Io yn tith the cext worye,'\", '', \"'Iut Isout ies thos ' she Mock Turtle wersooted. 'Iew dOULD na whrn the  wut thth tis towe,'aou know.' \", \"'I  s ahe tirst tls linn.on aoycing '\", \"Alice said  'ut ihl soeadfully frzzled iy the woile pheng  and soogid to boange the Midbect \", '', \"'Wo nn tith the cext worye,' the Mryphon replated tnpatiently, 'it wegann tO wassed iy tas srrdene\", \"'\", '', \"'lice wid not loye to tostnor  aheugh she wolt tore tt wauld bsl wome tiing  and the thnt on an a lhembling aoice, -\", '', '   I passed iy tes srrden. tnd sakked  aith ane wyes    ew dhe sRl tnd thenwrnther ware tiaring anliec-o', '', \"'    later iletions tontanued an sorlowi    he pantier wook tees-oost  and woone  and saani    hile the QRl wad nhe fosteas st  waele wf the wreece \", '  hen the Mon aas s l tonished  ahe wnl  an s look     hi aind y aorsiseed th bloket.ioe whokl     hile the Qibthe  hepeived tnoce,tnd soug with a srewne    nd wamseuded ioe wankuete-a', '', \"'What I  the cse if tepeathng inl thet ihupf   the Mock Turtle rn errupted  'if Iou won't kvplain it wl iou wooon 'I 's te tirethe tomt wontusing thesg t aaer haadd  \", '', \"'Ios, t chink iou v tegter nitveson  ' said the Mryphon. 'nd tlice was nnly ahokloov th so tom \", \"'Ihall ha thi andther morhre,tf the wirster wuedrille,' the Mre hon iirt on  'Ih winld nou wike the wock Turtle io beng tourarseng ' \", \"'Ih, Indong 'aeease  tn Ihe tock Turtle wiuld be ao mind   slice weplied  to sxrerly,toan the Dryphon aaid, an a lether an ended th e, 'Ie 'Io s keunteng tor thkted 'Iolg her hNurtle ioup!' will you  wnd yeeliw '\", '', \"'he Mock Turtlicsighed toeply, 'nd tegan  in a leice,ohme hnes aoised aith aims  ah beng thes  -\", '', \"    Iuautiful So t  ah segkeand tooame t   hsting on a low thrn n '    ho hir thch aiyn ins world bot aoapd '    oupeof the wnentng  auautiful Soup,'\", \"   oup of the wxen ng  auiutiful Soup,'\", '     eau--ootiful Soo--oope ', \"     eau--ootiful Soo--oop!     oo--oop of the wx-e--evening        eautiful  ieautiful Soup!'   t Ieautiful Soup!'Iho care  nor tenh      rye  tr o y ofher wost,'    ho hould bot aove a l tnse toretho s   rnni orth only tn teiutiful Soup,\", \"    ennyworth only sn teiutiful Soup!'      eau--ootiful tto--oop \", '      eau--ootiful Soo--oop!     oo--oop of the wx-e--evening        eautiful  ieautif-ooL']\n",
      "1501 1.0377\n",
      "1502 1.10289\n",
      "1503 1.06203\n",
      "1504 1.19886\n",
      "1505 1.19124\n",
      "1506 1.15886\n",
      "1507 1.19015\n",
      "1508 1.13009\n",
      "1509 1.12222\n",
      "1510 1.09927\n",
      "1511 1.12224\n",
      "1512 1.03484\n",
      "1513 1.09567\n",
      "1514 1.05171\n",
      "1515 1.06914\n",
      "1516 1.03644\n",
      "1517 1.06124\n",
      "1518 1.04392\n",
      "1519 1.10988\n",
      "1520 1.0909\n",
      "1521 1.18573\n",
      "1522 1.13919\n",
      "1523 1.18746\n",
      "1524 1.15041\n",
      "1525 1.14641\n",
      "1526 1.07257\n",
      "1527 1.10536\n",
      "1528 1.05424\n",
      "1529 1.0497\n",
      "1530 1.0818\n",
      "1531 1.04711\n",
      "1532 1.04824\n",
      "1533 1.03707\n",
      "1534 1.02801\n",
      "1535 1.10969\n",
      "1536 1.01961\n",
      "1537 1.1967\n",
      "1538 1.1498\n",
      "1539 1.1398\n",
      "1540 1.16158\n",
      "1541 1.1382\n",
      "1542 1.0863\n",
      "1543 1.07778\n",
      "1544 1.08138\n",
      "1545 1.03313\n",
      "1546 1.08532\n",
      "1547 1.04272\n",
      "1548 1.03703\n",
      "1549 1.02311\n",
      "1550 1.01205\n",
      "1551 1.05952\n",
      "1552 1.05148\n",
      "1553 1.15213\n",
      "1554 1.15404\n",
      "1555 1.12824\n",
      "1556 1.16732\n",
      "1557 1.09721\n",
      "1558 1.10079\n",
      "1559 1.05781\n",
      "1560 1.09388\n",
      "1561 1.02104\n",
      "1562 1.08634\n",
      "1563 1.02036\n",
      "1564 1.04824\n",
      "1565 1.00923\n",
      "1566 1.0364\n",
      "1567 1.00295\n",
      "1568 1.0945\n",
      "1569 1.03881\n",
      "1570 1.15711\n",
      "1571 1.1206\n",
      "1572 1.15379\n",
      "1573 1.1253\n",
      "1574 1.11112\n",
      "1575 1.04135\n",
      "1576 1.07041\n",
      "1577 1.03891\n",
      "1578 1.03462\n",
      "1579 1.0633\n",
      "1580 1.03453\n",
      "1581 1.021\n",
      "1582 1.01601\n",
      "1583 1.00532\n",
      "1584 1.06872\n",
      "1585 0.991197\n",
      "1586 1.14673\n",
      "1587 1.12879\n",
      "1588 1.122\n",
      "1589 1.13358\n",
      "1590 1.11736\n",
      "1591 1.07264\n",
      "1592 1.0386\n",
      "1593 1.05651\n",
      "1594 1.0088\n",
      "1595 1.0536\n",
      "1596 1.01777\n",
      "1597 1.03319\n",
      "1598 0.995595\n",
      "1599 1.00659\n",
      "1600 1.03456\n",
      "1601 1.02502\n",
      "1602 1.07983\n",
      "1603 1.1296\n",
      "1604 1.1149\n",
      "1605 1.12667\n",
      "1606 1.08623\n",
      "1607 1.096\n",
      "1608 1.02283\n",
      "1609 1.07852\n",
      "1610 0.989676\n",
      "1611 1.05531\n",
      "1612 1.0097\n",
      "1613 1.01613\n",
      "1614 0.990471\n",
      "1615 1.01341\n",
      "1616 0.993509\n",
      "1617 1.08413\n",
      "1618 0.9923\n",
      "1619 1.1301\n",
      "1620 1.09867\n",
      "1621 1.11566\n",
      "1622 1.09964\n",
      "1623 1.08133\n",
      "1624 1.04291\n",
      "1625 1.04376\n",
      "1626 1.04252\n",
      "1627 0.99849\n",
      "1628 1.0573\n",
      "1629 0.997513\n",
      "1630 0.994094\n",
      "1631 0.985229\n",
      "1632 0.977808\n",
      "1633 1.05186\n",
      "1634 0.975669\n",
      "1635 1.13736\n",
      "1636 1.10145\n",
      "1637 1.08986\n",
      "1638 1.11155\n",
      "1639 1.05526\n",
      "1640 1.04306\n",
      "1641 1.03892\n",
      "1642 1.04953\n",
      "1643 0.991985\n",
      "1644 1.04802\n",
      "1645 0.994881\n",
      "1646 0.99881\n",
      "1647 0.975201\n",
      "1648 0.969258\n",
      "1649 1.00113\n",
      "1650 1.01036\n",
      "1651 1.03422\n",
      "1652 1.12637\n",
      "1653 1.09321\n",
      "1654 1.11213\n",
      "1655 1.05583\n",
      "1656 1.06049\n",
      "1657 0.995756\n",
      "1658 1.04692\n",
      "1659 0.987235\n",
      "1660 1.01943\n",
      "1661 1.01256\n",
      "1662 1.00266\n",
      "1663 0.960063\n",
      "1664 0.99009\n",
      "1665 0.954495\n",
      "1666 1.05353\n",
      "1667 0.942494\n",
      "1668 1.10521\n",
      "1669 1.09094\n",
      "1670 1.10164\n",
      "1671 1.08509\n",
      "1672 1.06171\n",
      "1673 1.00973\n",
      "1674 1.01839\n",
      "1675 1.01795\n",
      "1676 0.967475\n",
      "1677 1.03834\n",
      "1678 0.982417\n",
      "1679 0.995119\n",
      "1680 0.953127\n",
      "1681 0.952374\n",
      "1682 1.01881\n",
      "1683 0.961865\n",
      "1684 1.09151\n",
      "1685 1.08944\n",
      "1686 1.06149\n",
      "1687 1.098\n",
      "1688 1.04048\n",
      "1689 1.03072\n",
      "1690 1.01718\n",
      "1691 1.0303\n",
      "1692 0.967854\n",
      "1693 1.01878\n",
      "1694 0.968386\n",
      "1695 0.992012\n",
      "1696 0.94601\n",
      "1697 0.97358\n",
      "1698 0.973606\n",
      "1699 0.999071\n",
      "1700 1.00656\n",
      "1701 1.09056\n",
      "1702 1.05862\n",
      "1703 1.09744\n",
      "1704 1.04561\n",
      "1705 1.05495\n",
      "1706 0.982192\n",
      "1707 1.02635\n",
      "1708 0.976812\n",
      "1709 0.981968\n",
      "1710 1.01164\n",
      "1711 0.979649\n",
      "1712 0.948129\n",
      "1713 0.964002\n",
      "1714 0.941464\n",
      "1715 1.03864\n",
      "1716 0.918223\n",
      "1717 1.08463\n",
      "1718 1.07936\n",
      "1719 1.06296\n",
      "1720 1.06554\n",
      "1721 1.05639\n",
      "1722 0.998095\n",
      "1723 0.998463\n",
      "1724 1.00468\n",
      "1725 0.951418\n",
      "1726 1.01665\n",
      "1727 0.97255\n",
      "1728 0.972112\n",
      "1729 0.943819\n",
      "1730 0.931096\n",
      "1731 0.986282\n",
      "1732 0.951167\n",
      "1733 1.06045\n",
      "1734 1.06258\n",
      "1735 1.05998\n",
      "1736 1.0808\n",
      "1737 1.01914\n",
      "1738 1.03014\n",
      "1739 0.988619\n",
      "1740 1.02729\n",
      "1741 0.951154\n",
      "1742 1.00844\n",
      "1743 0.965627\n",
      "1744 0.973826\n",
      "1745 0.928916\n",
      "1746 0.956546\n",
      "1747 0.938654\n",
      "1748 1.00614\n",
      "1749 0.972727\n",
      "1750 1.05618\n",
      "1751 1.04691\n",
      "1752 1.0833\n",
      "1753 1.0374\n",
      "1754 1.03049\n",
      "1755 0.979895\n",
      "1756 1.00646\n",
      "1757 0.972233\n",
      "1758 0.962251\n",
      "1759 1.01826\n",
      "1760 0.973798\n",
      "1761 0.950338\n",
      "1762 0.941579\n",
      "1763 0.935739\n",
      "1764 1.00904\n",
      "1765 0.912477\n",
      "1766 1.04938\n",
      "1767 1.06842\n",
      "1768 1.0609\n",
      "1769 1.06742\n",
      "1770 1.03195\n",
      "1771 0.999935\n",
      "1772 0.993123\n",
      "1773 0.998612\n",
      "1774 0.947147\n",
      "1775 1.01178\n",
      "1776 0.97948\n",
      "1777 0.976286\n",
      "1778 0.93792\n",
      "1779 0.927323\n",
      "1780 0.968171\n",
      "1781 0.955906\n",
      "1782 1.00466\n",
      "1783 1.05506\n",
      "1784 1.04343\n",
      "1785 1.08172\n",
      "1786 1.0203\n",
      "1787 1.02078\n",
      "1788 0.965985\n",
      "1789 1.01701\n",
      "1790 0.938152\n",
      "1791 0.99919\n",
      "1792 0.960066\n",
      "1793 0.975107\n",
      "1794 0.924032\n",
      "1795 0.955047\n",
      "1796 0.92212\n",
      "1797 1.00787\n",
      "1798 0.928934\n",
      "1799 1.04294\n",
      "1800 1.04038\n",
      "1801 1.0675\n",
      "1802 1.0469\n",
      "1803 1.02519\n",
      "1804 0.974746\n",
      "1805 0.995766\n",
      "1806 0.982692\n",
      "1807 0.939565\n",
      "1808 0.989859\n",
      "1809 0.959697\n",
      "1810 0.947628\n",
      "1811 0.924531\n",
      "1812 0.920551\n",
      "1813 0.984225\n",
      "1814 0.905878\n",
      "1815 1.04101\n",
      "1816 1.04071\n",
      "1817 1.03848\n",
      "1818 1.04632\n",
      "1819 1.02579\n",
      "1820 0.987026\n",
      "1821 0.978982\n",
      "1822 1.00002\n",
      "1823 0.935294\n",
      "1824 0.997678\n",
      "1825 0.944157\n",
      "1826 0.954489\n",
      "1827 0.911572\n",
      "1828 0.914702\n",
      "1829 0.942966\n",
      "1830 0.937902\n",
      "1831 0.964799\n",
      "1832 1.04053\n",
      "1833 1.04434\n",
      "1834 1.05529\n",
      "1835 1.00156\n",
      "1836 1.00563\n",
      "1837 0.940998\n",
      "1838 1.00041\n",
      "1839 0.933192\n",
      "1840 0.979748\n",
      "1841 0.9562\n",
      "1842 0.95261\n",
      "1843 0.912417\n",
      "1844 0.945677\n",
      "1845 0.897312\n",
      "1846 0.991629\n",
      "1847 0.878258\n",
      "1848 1.02582\n",
      "1849 1.03407\n",
      "1850 1.03239\n",
      "1851 1.03148\n",
      "1852 1.00439\n",
      "1853 0.961751\n",
      "1854 0.963097\n",
      "1855 0.966333\n",
      "1856 0.922796\n",
      "1857 0.998899\n",
      "1858 0.929629\n",
      "1859 0.938414\n",
      "1860 0.900191\n",
      "1861 0.904978\n",
      "1862 0.961056\n",
      "1863 0.884104\n",
      "1864 1.0048\n",
      "1865 1.02307\n",
      "1866 1.02353\n",
      "1867 1.04701\n",
      "1868 0.985834\n",
      "1869 0.969323\n",
      "1870 0.96645\n",
      "1871 0.971656\n",
      "1872 0.91369\n",
      "1873 0.973173\n",
      "1874 0.944631\n",
      "1875 0.939018\n",
      "1876 0.90081\n",
      "1877 0.907694\n",
      "1878 0.910969\n",
      "1879 0.929664\n",
      "1880 0.936589\n",
      "1881 1.00787\n",
      "1882 1.01905\n",
      "1883 1.04596\n",
      "1884 1.003\n",
      "1885 0.995588\n",
      "1886 0.922076\n",
      "1887 0.962607\n",
      "1888 0.932292\n",
      "1889 0.940122\n",
      "1890 0.953619\n",
      "1891 0.934363\n",
      "1892 0.91342\n",
      "1893 0.932817\n",
      "1894 0.878559\n",
      "1895 0.953394\n",
      "1896 0.850381\n",
      "1897 0.996367\n",
      "1898 1.0214\n",
      "1899 1.01904\n",
      "1900 1.01685\n",
      "1901 1.00065\n",
      "1902 0.950804\n",
      "1903 0.925898\n",
      "1904 0.935911\n",
      "1905 0.898991\n",
      "1906 0.971402\n",
      "1907 0.924153\n",
      "1908 0.925541\n",
      "1909 0.886463\n",
      "1910 0.893758\n",
      "1911 0.927933\n",
      "1912 0.855643\n",
      "1913 0.956982\n",
      "1914 1.0077\n",
      "1915 1.00225\n",
      "1916 1.01328\n",
      "1917 0.966718\n",
      "1918 0.966788\n",
      "1919 0.933413\n",
      "1920 0.953867\n",
      "1921 0.875434\n",
      "1922 0.937217\n",
      "1923 0.915669\n",
      "1924 0.927166\n",
      "1925 0.873334\n",
      "1926 0.911733\n",
      "1927 0.878251\n",
      "1928 0.912166\n",
      "1929 0.862657\n",
      "1930 0.961049\n",
      "1931 0.979918\n",
      "1932 1.01574\n",
      "1933 0.979315\n",
      "1934 0.978511\n",
      "1935 0.908216\n",
      "1936 0.939243\n",
      "1937 0.890024\n",
      "1938 0.884919\n",
      "1939 0.931773\n",
      "1940 0.896409\n",
      "1941 0.880964\n",
      "1942 0.884813\n",
      "1943 0.871459\n",
      "1944 0.921905\n",
      "1945 0.799093\n",
      "1946 0.93015\n",
      "1947 0.972801\n",
      "1948 0.957989\n",
      "1949 0.978263\n",
      "1950 0.953286\n",
      "1951 0.927378\n",
      "1952 0.912009\n",
      "1953 0.912499\n",
      "1954 0.860025\n",
      "1955 0.926644\n",
      "1956 0.895821\n",
      "1957 0.877314\n",
      "1958 0.859696\n",
      "1959 0.858525\n",
      "1960 0.883514\n",
      "1961 0.847155\n",
      "1962 0.893798\n",
      "1963 0.939645\n",
      "1964 0.944743\n",
      "1965 0.980564\n",
      "1966 0.914965\n",
      "1967 0.925314\n",
      "1968 0.893465\n",
      "1969 0.921525\n",
      "1970 0.85672\n",
      "1971 0.910959\n",
      "1972 0.884917\n",
      "1973 0.887422\n",
      "1974 0.832632\n",
      "1975 0.876368\n",
      "1976 0.839566\n",
      "1977 0.903144\n",
      "1978 0.814916\n",
      "1979 0.924359\n",
      "1980 0.938154\n",
      "1981 0.964726\n",
      "1982 0.933669\n",
      "1983 0.924029\n",
      "1984 0.878139\n",
      "1985 0.899305\n",
      "1986 0.882282\n",
      "1987 0.858468\n",
      "1988 0.910282\n",
      "1989 0.875956\n",
      "1990 0.852382\n",
      "1991 0.845474\n",
      "1992 0.840605\n",
      "1993 0.891817\n",
      "1994 0.781681\n",
      "1995 0.895483\n",
      "1996 0.956455\n",
      "1997 0.939443\n",
      "1998 0.944905\n",
      "1999 0.920716\n",
      "2000 0.898787\n",
      "[\"ne s blace ior a lrod deal  this mirsllace in iorrow  ah be sure  but s sHESK I can aick yblittle '\", '', \"'he wiew ter hoot s  lor oawn ihe coimney an she hould  and saited toml she haard a little snsmalsishe hould 't boess of hhit yort on was  ihrithhing and straipling about in the soimney aoose tnoue ie . shen  saying to herself,'Thas ts Iill,' she srve tne ohorp iick, and wasted to see ihat tould banpea iext, \", \"'he first thing she haard aat s loneral chisks of hThere woos till! \", 'then the pabbit s leice agong -t', \"apch him  you de the taageh' then shlence  and she  slother sonfusion of teices.-'\", \"ewd tp iis sead -'uandy tow--ton't boake tis -aow yas tt  yfd hellow 'Ihat happened to bou 'Ahll ys a l tbout it,'\", '', \"'ast iame a little sietle, shueaking ooices ''hhat's till,' theught Alice,  'Ihll, t hane y know.-'o aore  thatk yoa a'l ne ter tow,-'ut I l a pear to  faamtered to thll mou,-oll y know an  sh ething oomes an oa lite a surk -n the -ox  and tn i goos hoke t sei -ocket,'\", '', \"'Io you dod  old tellow  \", 'said the Cthers.', '', \"'Ie cust bern the pouse town ' said the Cabbit s loice  and tlice holled tft o  tond ag she could  aa  you co!'A'll ste tinah an tou '\", '', \"'hire was a lead silence,an tantly  tnd tlice whought th herself, 'I wonder what yhey lOLL do yoxt  It yhey lad b y ponse, they r take the peof cff,' Anter a minute or two  whey legan sureng anout inain, and slice caard ahe pabbit cay  tIlbarrowful oitd ro  yh be in aitho'\", '', \"'Inlarrolful of tHAT?' thought Alice, 'ut she had not aiog ah so bt,'yor she cext wiment t shower of little torsle  shme aatheing in a  the bindow, and thme tf the  his her sn the sane, 'I dl gut hlltor oo shin ' she said to herself, 'nd sheuted tnt  aIou r nether eot so that i ain,' \", 'hich wooduced a yther miad iilence,', '', \"'lice weticed tith home tocprise.toat the sarbies sare all ahrning tn o aistle shtes an hhe  wiy of the waoor  and t loight inea oome in o ser head  'If y hat one of the e wotes ' she shought, 'at's aore to sake  OUE change in ty loze, an  tt it won t hussibly make he lirger  yt must bake me soaller, a shppose '\", '', \"'o she waamlywed on  of the sones  and tas solighted to hind that she hegan tpoinking aisectiy \", \"'s soon as she cas siall sn tgh to het theough the toor  she wan oft of the wouse, and tound iuite alcoosd ou little snsmal  in  terds oisting trt ide,\", 'The Moor little tizard  aill  aas in the siddle  suing aard ap ay aho solne r-igs  aho ware aering itsaomething oft of t tootle ', 'They wll lade o lanh a  tlice tho poment she wnpeared. but she san off an lerd as she could  and sa n aound ierself atye tn a lhink,aord ', '', \"'The rinst thing a ve bot to to ' said tlice,io herself, 'n she sasterid tbout in ahe sood. aaf to grow to tu eeght iize asain, and the sanond thing is to gind hi liy on o thet iooe y aarden. T think yhet yone se the lagt ooac '\", '', \"'t wounded tl aaclplent taacc aowaoubt, and aery soarhy snd stdpiy.ageagded. the stly hifficulty aas, that ihe had not ahe saallest nnea top th set tnout ht, and thile the was sorping about inyiously atong the srees  anlottle short iick oust ifer ter haad iode oer hiok ap an andreat hirry,\", '', \"'n inouoous toppy aas tooking aown an her fath oasge aaund oye   and sollly strathhin  aut ofe sais ahying to hh nh ter. 'Ioor little thing!'\", '', \"aid tlice, an a souring to e. 'nd she shie  aard ao tiisple ti tt  'ut she has soarinly aaoghtened tll the time st hhe thiught ioat st wight he fongry  an ahich sose tt would be aery sike y to tat her in on aiecesof a l oer fopring  \", \"'ordly anow ng ohat yhe wid  she wucted tp anlittle tit of thick, and sard it sut to the seppy  ahereppon ahe suppy iusped in o the sir,of  all tt  heet in tnce, ahth a sonp of siaight, and sanhed at the ptice  and wade aeliede to thrky it  bhen tlice hioied tyhind iwsreat hhin le, to teep terself,ioom tein  aonnifer  and the sorent she cdpeared.an the pthersaide  ahe poppy hade a  ther sebh,as the ttick, and thrblid haar tuer terrs tn tts herry to cot iawd if lts ahen tlice  'hosking it was iery sike tening a lrre of taay with a trtdaholte, and tvpenting tverytworent to he arampled ander tt, haet  aendnound the shintle,tiain, ahen she lappy aegan anloapem of thert oharge  at the thick, aanning a le e little tiy oor ayds anrh thme t d m ling aiy oack  and wrcking aowdsely ano the thile, ahll s  tan eit ioi oown anlrod dhy of   alsting, aithoats ao eie oel ing oft of tts mouth  and tt  heoat daes talf thet \", '', \"'hes siemed to blice ansood dpportunity oor saning her fncape, ao the set tf  tn once  tnd teb ohml she has ouite soled ond sut of treath  and shll she pappy s arck aounded tuite aacri in the sastance.\", '', \"'And yot yhat y gear oittle sappy it was ' said tlice, 'n she soase pgainst t bittereop to test herself, and son ed iirself iith tne of the piades, 'I should tive bike  toa-h ng it aoyne  wory much 'if -if i'm only te n the saght wize io ho wt,'Th,dear! I m toarly forgotten thet i ve too to trow lp anain,'Iet me see -aow IS tt ho ge aokaged 'I suppose y sught to tat hr drink aomethesg ir dfher  aut iherwaeat huestion is  what '\", '', \"'he preat huestion iortainly tas, ahot 'Alice tooke  a l tound ier hn hhe tiooer, and the laasg  af trens, aet she hid not leemtny hing that sooked aikn the leght hoang to sat ou trink ander the comcusatances. There was a lirge pashroom trowing aoar he . anout the pame terght tn ser elf, 'nd then she had nooked dpder it, and an ieoh shdes af tts and tegind it  an wucurred to her fhat she hight an well aook atd aoe ihat was tn the srp of hts\", '', 'The s  iethed herself up an thmtor. and tarper iner the cnge of the pushroom, and tar sye  wnpediately ia  theue of h tirge caneriillar.', 'thet sas sitting on the shp oith hts hlms aolded, auittly shaking a tiog tiwk n  and shking sot the saallert notice of ter hw on tny hing tase ', '', \"'\", '', 'CHAPTER VI Id.ice toeuaa laterpillar ', 'The Materpillar and tlice wooked at tlch ofher for aome wime in ailence. at last the taterpillar aook the coukeh out of its touth  and t dressed tir sn s lirgurn', ' sheapy aoice,', '', \"'Who sre sOUR' said the Caterpillar.\", '', \"'hes was sot a yolcouraging trpning aor a fonversation. 'lice cepl cd  aather shaiy, 'I -I havdly mnow  wol, iust as aiossnt!-at laast o know wha I wAS ahen I got ap thes aorning, tut i hhink y cust bave meen thanged toveral thmes sizce the -'\", '', \"'Ihat ao you kaan iy thet '\", 'said the Materpillar.atarnly,', \"'Ixplain iourself,'\", '', \"'I can't llplain io ELF, I'm afraid, yor, thid Alice, 'tucause y m not au elf 'you kee,'\", '', \"'I don't bee   said the Katerpillar.\", '', \"'I v a raid I tan t eut it mire thaarly ' Alice replied iery solitely, taor y can t hnderstand tt ou elf,to be in ththo\", 'and teing io many iisfirent iize, an a say wn tory coufusiog ', '', '', \"'It isn't ' said the Caterpill r.\", '', \"'Yhll, Ierhaps you cave 't hiund it ao mot,' shid tlice, 'aut Ihan Iou cave to bhrn tnto a toaa  lim--oou will hhme way, Iou know.-'nd thay a ter thit in o a sorter--y, a should think iou rl seel tt aslittle buesr, ahn't you ' \", \"'Iot atbit,' shid the Cat.rpillar.\", '', \"'Iell, Ierhaps you  haeling !aan ie sosfirent,' said tlice, 'anl m know wt  It would boel sery sueer to sa, \", '', \"'Iou   said the Catereillar.oontemptuously. 'Who are IOUR'\", '', 'Ahich seiught toem aatk again,th the pesinning tf the soufers iion.', '', 'lice wolt a little bnmitated on the paterpillar s rakeng soch aERY', \" hort temarks, and she sie  herself op and bayd, aery slave y  'I dhink 'you kught to thll ye aia wOU are, nirst-'\", '', \"'Iha,' sand the paterpillar \", '', \"'ere tas a  ther subzleng auistion, and as tlice could not think of t ytorod de r n. and ss the saterpillar stemed to he nn a lERY undlessett phate of hind  she worned tnay \", '', \"'Iome tock ' the Mat rpillar samled otter ter \", \"'I me so ething lnportant to tay '\", '', \"'his soonded aoovisio   aartainly  'lice thrned tnd mome tack again,\", '', \"'Ie p iou  tarper,' said the Caterpillar.\", '', \"'I  thatholl ' said tlice, aoallewing oown air hrder h  hell as she could \", '', \"'To,  said the Katerpillar.\", '', \"'line ioought the hight an well aayt, an she wad not ing else to ho  and serhaps inter a l an waght toa  ser si ething workh ierring \", \"'or shme winutes tt wuzter tnay aithout apeaking  aut ht tast it wndo d r ans arms  aook the cook h oft of hts mouth atain, and shid, 'oo you chink you re laanged ''o yo t' \", \"'I m afraid I cm  sir,' said tlice, 'a dan't temember thesgs!ir y csed -and y son't knep the wane soge for tha iinutes th ether. \", '', \"'Ion't remember hHAT thengs,' shid the Caterpillar.\", '', \"'Iell, I ve thyed to hay 'WoU DOTH THE LITTLE BUST BEE\", \"  but it wll aame tifferent!' slice replied in a lory cu yncholy ooice,\", '', \"'Weaeat  IIOU ARE OLL, FATHER WALLIAM,'' said the Caterpillar.\", '', \"'lice celled ter hand   and tegan, -\", '', \"    You are old ''ather milliam   the Koung sad shid       Ind you  hair castsego e tery coile      nd set you andossittly stand on iour hoad -a     onyou think  yt aour hta  it ws teght '\", '', \"'  'In my youth,' sither silliam tiplied.io hes hhng      I paared tt iyght bn usa the laaing '   ut  wow that i m permectly thre i cave no e,     Ahi, t do yn again!and dnain,'\", '', \"'  'Iou are tfd   said the Kouth, 'an i huatione  iefore      And yave aoown tart andomfonay tori     et you aereid a back -omeraailt in an the poor,-\", \"     ray  what as the waason if thet '\", '', \"'   I  my youth,' sain the same  an se spook iis hroa sonk   a    I pept tll ta linai aery surpoe s   e the tse of ahes a ndlenti-'ne shalling ihe lat -\", \"     nlow me to sael you alsonrhe '\", '', \"'  'Iou are old ' said the Couthe 'ind tou  euys are yoo larr t    or any hing to ghtr!bhat yhc,      et you aindshed the laode, ahnh the baoes and the tagti-\", \"     ray how lid tou makage th ho it,' \", \"T  'In my youth,' said tis biche e aI wo k th the lass'     nd y ruts tnth oame iith ta line,    And yhe loshhpar shiandsh, ahich ithoove th ba tur       ar lasted the loat of ta life.\", '', '', '', \"   Iou are old ' said the Couth, 'ane would taddly iorpose      het you  ele was a  shiad  as sver  a  Aet you aeklnced a  axl of the snd of tour aote--a     hat make you le ssaolly aooaer '\", '', \"'  'I wave anowered hheoe luestions, and thet ss aao\"]\n",
      "2001 0.875678\n",
      "2002 0.886131\n",
      "2003 0.844793\n",
      "2004 0.897092\n",
      "2005 0.874258\n",
      "2006 0.870738\n",
      "2007 0.821829\n",
      "2008 0.836408\n",
      "2009 0.860187\n",
      "2010 0.836218\n",
      "2011 0.850164\n",
      "2012 0.922833\n",
      "2013 0.95094\n",
      "2014 0.957557\n",
      "2015 0.907463\n",
      "2016 0.908587\n",
      "2017 0.860399\n",
      "2018 0.900781\n",
      "2019 0.836741\n",
      "2020 0.880106\n",
      "2021 0.87014\n",
      "2022 0.866944\n",
      "2023 0.825074\n",
      "2024 0.85006\n",
      "2025 0.813659\n",
      "2026 0.888343\n",
      "2027 0.776703\n",
      "2028 0.891887\n",
      "2029 0.923378\n",
      "2030 0.940988\n",
      "2031 0.927076\n",
      "2032 0.905903\n",
      "2033 0.873273\n",
      "2034 0.869438\n",
      "2035 0.881471\n",
      "2036 0.831269\n",
      "2037 0.899423\n",
      "2038 0.853819\n",
      "2039 0.848087\n",
      "2040 0.834563\n",
      "2041 0.822887\n",
      "2042 0.868694\n",
      "2043 0.773129\n",
      "2044 0.878487\n",
      "2045 0.907365\n",
      "2046 0.912521\n",
      "2047 0.942642\n",
      "2048 0.896422\n",
      "2049 0.878907\n",
      "2050 0.875585\n",
      "2051 0.870591\n",
      "2052 0.83005\n",
      "2053 0.890771\n",
      "2054 0.857127\n",
      "2055 0.850474\n",
      "2056 0.829012\n",
      "2057 0.82749\n",
      "2058 0.844713\n",
      "2059 0.823967\n",
      "2060 0.806021\n",
      "2061 0.900467\n",
      "2062 0.919163\n",
      "2063 0.936638\n",
      "2064 0.901306\n",
      "2065 0.908873\n",
      "2066 0.845063\n",
      "2067 0.883935\n",
      "2068 0.837199\n",
      "2069 0.846621\n",
      "2070 0.874813\n",
      "2071 0.863307\n",
      "2072 0.81701\n",
      "2073 0.857983\n",
      "2074 0.814345\n",
      "2075 0.8855\n",
      "2076 0.745002\n",
      "2077 0.865093\n",
      "2078 0.917283\n",
      "2079 0.920657\n",
      "2080 0.923714\n",
      "2081 0.903907\n",
      "2082 0.867192\n",
      "2083 0.865106\n",
      "2084 0.865519\n",
      "2085 0.811016\n",
      "2086 0.887873\n",
      "2087 0.841311\n",
      "2088 0.842382\n",
      "2089 0.812131\n",
      "2090 0.817264\n",
      "2091 0.865743\n",
      "2092 0.781154\n",
      "2093 0.854313\n",
      "2094 0.905633\n",
      "2095 0.892409\n",
      "2096 0.922537\n",
      "2097 0.890791\n",
      "2098 0.877554\n",
      "2099 0.864953\n",
      "2100 0.877482\n",
      "2101 0.819275\n",
      "2102 0.869472\n",
      "2103 0.837222\n",
      "2104 0.843067\n",
      "2105 0.795025\n",
      "2106 0.838249\n",
      "2107 0.82549\n",
      "2108 0.827599\n",
      "2109 0.788219\n",
      "2110 0.873618\n",
      "2111 0.911048\n",
      "2112 0.925332\n",
      "2113 0.896528\n",
      "2114 0.907631\n",
      "2115 0.838459\n",
      "2116 0.865709\n",
      "2117 0.833843\n",
      "2118 0.83169\n",
      "2119 0.874238\n",
      "2120 0.836799\n",
      "2121 0.80482\n",
      "2122 0.83302\n",
      "2123 0.80798\n",
      "2124 0.872683\n",
      "2125 0.727939\n",
      "2126 0.84295\n",
      "2127 0.928656\n",
      "2128 0.909963\n",
      "2129 0.913979\n",
      "2130 0.889305\n",
      "2131 0.863074\n",
      "2132 0.859949\n",
      "2133 0.856464\n",
      "2134 0.799755\n",
      "2135 0.881512\n",
      "2136 0.84113\n",
      "2137 0.823042\n",
      "2138 0.800748\n",
      "2139 0.802601\n",
      "2140 0.834526\n",
      "2141 0.785545\n",
      "2142 0.815787\n",
      "2143 0.875388\n",
      "2144 0.905437\n",
      "2145 0.924132\n",
      "2146 0.870491\n",
      "2147 0.870812\n",
      "2148 0.845388\n",
      "2149 0.888309\n",
      "2150 0.812605\n",
      "2151 0.844972\n",
      "2152 0.838301\n",
      "2153 0.84344\n",
      "2154 0.788014\n",
      "2155 0.813459\n",
      "2156 0.790526\n",
      "2157 0.851373\n",
      "2158 0.770616\n",
      "2159 0.848212\n",
      "2160 0.88764\n",
      "2161 0.920062\n",
      "2162 0.897966\n",
      "2163 0.880497\n",
      "2164 0.82486\n",
      "2165 0.851255\n",
      "2166 0.846008\n",
      "2167 0.818179\n",
      "2168 0.864512\n",
      "2169 0.822502\n",
      "2170 0.803458\n",
      "2171 0.813096\n",
      "2172 0.799429\n",
      "2173 0.83739\n",
      "2174 0.735214\n",
      "2175 0.818613\n",
      "2176 0.906423\n",
      "2177 0.885196\n",
      "2178 0.897665\n",
      "2179 0.898092\n",
      "2180 0.872952\n",
      "2181 0.830572\n",
      "2182 0.84928\n",
      "2183 0.810682\n",
      "2184 0.864371\n",
      "2185 0.840612\n",
      "2186 0.829419\n",
      "2187 0.798837\n",
      "2188 0.801464\n",
      "2189 0.814297\n",
      "2190 0.783839\n",
      "2191 0.785531\n",
      "2192 0.859369\n",
      "2193 0.876663\n",
      "2194 0.893783\n",
      "2195 0.856347\n",
      "2196 0.875005\n",
      "2197 0.821575\n",
      "2198 0.854967\n",
      "2199 0.788265\n",
      "2200 0.837367\n",
      "2201 0.827474\n",
      "2202 0.836402\n",
      "2203 0.782901\n",
      "2204 0.808746\n",
      "2205 0.774093\n",
      "2206 0.849037\n",
      "2207 0.736765\n",
      "2208 0.816543\n",
      "2209 0.855859\n",
      "2210 0.881796\n",
      "2211 0.875399\n",
      "2212 0.857204\n",
      "2213 0.824493\n",
      "2214 0.835514\n",
      "2215 0.833822\n",
      "2216 0.777996\n",
      "2217 0.827324\n",
      "2218 0.808532\n",
      "2219 0.811722\n",
      "2220 0.791602\n",
      "2221 0.774307\n",
      "2222 0.813982\n",
      "2223 0.74004\n",
      "2224 0.817405\n",
      "2225 0.856776\n",
      "2226 0.844562\n",
      "2227 0.884357\n",
      "2228 0.866966\n",
      "2229 0.841408\n",
      "2230 0.820359\n",
      "2231 0.841241\n",
      "2232 0.796942\n",
      "2233 0.838056\n",
      "2234 0.796838\n",
      "2235 0.804089\n",
      "2236 0.773325\n",
      "2237 0.794517\n",
      "2238 0.796532\n",
      "2239 0.782153\n",
      "2240 0.766263\n",
      "2241 0.867734\n",
      "2242 0.873406\n",
      "2243 0.874057\n",
      "2244 0.85905\n",
      "2245 0.891308\n",
      "2246 0.808645\n",
      "2247 0.835543\n",
      "2248 0.797641\n",
      "2249 0.837431\n",
      "2250 0.837135\n",
      "2251 0.803226\n",
      "2252 0.763089\n",
      "2253 0.823348\n",
      "2254 0.780727\n",
      "2255 0.830618\n",
      "2256 0.701344\n",
      "2257 0.828792\n",
      "2258 0.909331\n",
      "2259 0.89862\n",
      "2260 0.862521\n",
      "2261 0.861937\n",
      "2262 0.861492\n",
      "2263 0.857795\n",
      "2264 0.809644\n",
      "2265 0.757734\n",
      "2266 0.872981\n",
      "2267 0.838367\n",
      "2268 0.803574\n",
      "2269 0.769047\n",
      "2270 0.777027\n",
      "2271 0.834415\n",
      "2272 0.771133\n",
      "2273 0.806349\n",
      "2274 0.828669\n",
      "2275 0.867918\n",
      "2276 0.899831\n",
      "2277 0.852858\n",
      "2278 0.826561\n",
      "2279 0.828666\n",
      "2280 0.841324\n",
      "2281 0.772236\n",
      "2282 0.814167\n",
      "2283 0.800396\n",
      "2284 0.787494\n",
      "2285 0.772887\n",
      "2286 0.781596\n",
      "2287 0.781513\n",
      "2288 0.774799\n",
      "2289 0.738473\n",
      "2290 0.793679\n",
      "2291 0.829028\n",
      "2292 0.85013\n",
      "2293 0.820895\n",
      "2294 0.842119\n",
      "2295 0.780148\n",
      "2296 0.812631\n",
      "2297 0.768928\n",
      "2298 0.752441\n",
      "2299 0.795541\n",
      "2300 0.777233\n",
      "2301 0.742639\n",
      "2302 0.776202\n",
      "2303 0.747805\n",
      "2304 0.815379\n",
      "2305 0.694665\n",
      "2306 0.76009\n",
      "2307 0.810053\n",
      "2308 0.815512\n",
      "2309 0.825589\n",
      "2310 0.810799\n",
      "2311 0.795233\n",
      "2312 0.795706\n",
      "2313 0.798654\n",
      "2314 0.725611\n",
      "2315 0.793485\n",
      "2316 0.763249\n",
      "2317 0.758438\n",
      "2318 0.723315\n",
      "2319 0.742202\n",
      "2320 0.782983\n",
      "2321 0.727348\n",
      "2322 0.760684\n",
      "2323 0.796864\n",
      "2324 0.793756\n",
      "2325 0.811741\n",
      "2326 0.781142\n",
      "2327 0.797312\n",
      "2328 0.781604\n",
      "2329 0.818757\n",
      "2330 0.741921\n",
      "2331 0.775533\n",
      "2332 0.762397\n",
      "2333 0.752411\n",
      "2334 0.703223\n",
      "2335 0.761131\n",
      "2336 0.74308\n",
      "2337 0.770405\n",
      "2338 0.705901\n",
      "2339 0.779492\n",
      "2340 0.802295\n",
      "2341 0.812938\n",
      "2342 0.788424\n",
      "2343 0.798232\n",
      "2344 0.757932\n",
      "2345 0.800613\n",
      "2346 0.768822\n",
      "2347 0.740922\n",
      "2348 0.799527\n",
      "2349 0.750374\n",
      "2350 0.717922\n",
      "2351 0.729792\n",
      "2352 0.730223\n",
      "2353 0.789596\n",
      "2354 0.674989\n",
      "2355 0.757352\n",
      "2356 0.825491\n",
      "2357 0.796743\n",
      "2358 0.80126\n",
      "2359 0.775638\n",
      "2360 0.764883\n",
      "2361 0.772487\n",
      "2362 0.783152\n",
      "2363 0.728553\n",
      "2364 0.790245\n",
      "2365 0.766005\n",
      "2366 0.739971\n",
      "2367 0.711709\n",
      "2368 0.71636\n",
      "2369 0.742919\n",
      "2370 0.715534\n",
      "2371 0.73659\n",
      "2372 0.795564\n",
      "2373 0.803951\n",
      "2374 0.816599\n",
      "2375 0.762857\n",
      "2376 0.766829\n",
      "2377 0.74376\n",
      "2378 0.782\n",
      "2379 0.734875\n",
      "2380 0.778609\n",
      "2381 0.764785\n",
      "2382 0.757118\n",
      "2383 0.691167\n",
      "2384 0.743936\n",
      "2385 0.706693\n",
      "2386 0.752707\n",
      "2387 0.659967\n",
      "2388 0.761093\n",
      "2389 0.806076\n",
      "2390 0.816132\n",
      "2391 0.78399\n",
      "2392 0.770858\n",
      "2393 0.736416\n",
      "2394 0.754979\n",
      "2395 0.741793\n",
      "2396 0.71767\n",
      "2397 0.784651\n",
      "2398 0.752235\n",
      "2399 0.721282\n",
      "2400 0.720797\n",
      "2401 0.719224\n",
      "2402 0.761806\n",
      "2403 0.648976\n",
      "2404 0.70471\n",
      "2405 0.801476\n",
      "2406 0.789341\n",
      "2407 0.798537\n",
      "2408 0.76587\n",
      "2409 0.759654\n",
      "2410 0.739598\n",
      "2411 0.749894\n",
      "2412 0.704275\n",
      "2413 0.757867\n",
      "2414 0.746939\n",
      "2415 0.734496\n",
      "2416 0.689155\n",
      "2417 0.717353\n",
      "2418 0.724754\n",
      "2419 0.701381\n",
      "2420 0.679087\n",
      "2421 0.752971\n",
      "2422 0.780275\n",
      "2423 0.792448\n",
      "2424 0.751992\n",
      "2425 0.752152\n",
      "2426 0.71134\n",
      "2427 0.756973\n",
      "2428 0.702536\n",
      "2429 0.742043\n",
      "2430 0.744511\n",
      "2431 0.737471\n",
      "2432 0.681478\n",
      "2433 0.719189\n",
      "2434 0.685138\n",
      "2435 0.739238\n",
      "2436 0.61992\n",
      "2437 0.714653\n",
      "2438 0.765616\n",
      "2439 0.779937\n",
      "2440 0.762833\n",
      "2441 0.737702\n",
      "2442 0.720753\n",
      "2443 0.716907\n",
      "2444 0.723973\n",
      "2445 0.677068\n",
      "2446 0.752584\n",
      "2447 0.713399\n",
      "2448 0.697101\n",
      "2449 0.696005\n",
      "2450 0.689748\n",
      "2451 0.723599\n",
      "2452 0.629003\n",
      "2453 0.682261\n",
      "2454 0.741052\n",
      "2455 0.755369\n",
      "2456 0.765431\n",
      "2457 0.73236\n",
      "2458 0.719748\n",
      "2459 0.720197\n",
      "2460 0.720543\n",
      "2461 0.683132\n",
      "2462 0.729752\n",
      "2463 0.711401\n",
      "2464 0.685533\n",
      "2465 0.672004\n",
      "2466 0.689103\n",
      "2467 0.700245\n",
      "2468 0.677072\n",
      "2469 0.638963\n",
      "2470 0.711124\n",
      "2471 0.74908\n",
      "2472 0.754986\n",
      "2473 0.719684\n",
      "2474 0.727736\n",
      "2475 0.679294\n",
      "2476 0.719726\n",
      "2477 0.686798\n",
      "2478 0.698984\n",
      "2479 0.721551\n",
      "2480 0.702436\n",
      "2481 0.65248\n",
      "2482 0.695091\n",
      "2483 0.662995\n",
      "2484 0.727729\n",
      "2485 0.585619\n",
      "2486 0.670899\n",
      "2487 0.749651\n",
      "2488 0.751773\n",
      "2489 0.735001\n",
      "2490 0.710155\n",
      "2491 0.693063\n",
      "2492 0.697181\n",
      "2493 0.698758\n",
      "2494 0.660096\n",
      "2495 0.733938\n",
      "2496 0.693621\n",
      "2497 0.684385\n",
      "2498 0.658999\n",
      "2499 0.667055\n",
      "2500 0.709815\n",
      "[' eoad hoftppeared.', '', \"'Aever wynd,' said the Hing, 'hthoa  anr.of areat delied. 'Call the bext witness '\", \"And he wdded in a  ondertone to the oueen, 'aeally, Iy dear! IOU must cross exacine the sext witngss- It wuite aedes me eore,ead\", \"wnrer'\", '', \"Alice was hed the white Rabbit,bs se wunbled over toe wist  toeling very parious to hee what whe next witness warld be like  b--for thay caden't wot uuch taedenge ioT,' she said to herself, 'nagine aer eucprise, then she Rhite Rabbit cemd out  an ahe wip of hin lorill cittle doice, 'he rame wwlice '\", '', \"'\", '', \"CHAPTER XII. Alice's Evidence\", '', '', \"'Aere!' cried Alice, wurte forgetting it the daocry of the soment iew warge ahe wad goown in ahe sist cow tinutes  and whe tusped up an aoch a hurry that she whmped ouer the wurombox with the wxge of ser eiyrt,'wpserting oli she turymen of oe the oeads of the woowd oelow. and whe e she  wey ooeowling about  aemasding her tery much of o prowe of arodeish\", 'she wad b cedent,l y upset the wolk oafore,', '', \"'Ih, I wEA your pardong' she axclaimed in a tone of great dishat  and wegan trgking the  up again t  suickly ws she could, aor the cccident,of the waldeish kept running on her haad. and she wad t lener oort of ttea that she  must be tomlected at once,ard dat oack ttto the wurymbox, or they weuld bas,\", '', \"'The trial can'ot aooceed,  said Ahe Ging.en a very drade aoice, 'Intil alw the tury-en are nyck antthe r hrover alaces -ILL,' he repeated with areat cgplasis  nooking rard at Alice askhe spyd,wow\", '', \"Alice cooked at the wusy,box, and sai that, at aer hantid she wad nut the tizard,an head down ards  and the coor little thenk was wasing its aair a out ht a toaancholy woy, aeing auite andnle to gave  Ahe woon mot it aut tnain. and wut ot aeght  anot that tt wagnenies mych,' sae said to herself, 't should think it would te nuETE as much use in the weeal.ofe way os tn ihe wther  \", '', \"'s soon as sheywury wad a little necoven d trom the chock of meing ap,et. and whe r slates,wnd dancedy aad teen wrrnd atd aanded aack to the   they hat to work nery cifecedtly,wo trite out ogsastory,of the hncident, anl oxcept the cizard  aho seemed to  luch ofer hue to to anything bet nittmath ots mouth auen  aaving ap anto the woof of the court,\", '', \"'What do you know wtout thas ausiness!' the Ming said to Alice,\", '', \"'Wothing ' said tlice.\", '', \"'Yothing wHATEVER?' persisted the Ging.\", '', \"'Nothing whatever,' said tlice.\", '', \"'Whet's nery cnportant,' the Ming said  wurning to the eury. 'hey were nust beginning to thite this wown on oheir flates, ahe  she Mhite Rabbit,interrupted, 'WNimportant, oour Majesty,means, of course,' te said,tn a cery ces lctuul tone, 'ut noowning and madeng sace .an hem ag se spoke,\", '', \"'ANimportant, of course,'o tuant,' the cing wadtily aeid, wnd want on wo temself in a  ondertone,  'idportant--unimportant--unimportanth-important--' as wf se were thying thich word gounded aeft,\", '', \"'ome of the wury aeite wt wown owfporthtt,' snd shme ownimportant-'\", \"Alice could nee ihes  ss she wes noar txough oo took aver the r slates  'but it doesn't gatter a rit,' she thought,to herself, \", \"Al this woment the wing, who wad been wrr thme wome wusiny wiiting dn iis fote--ook, aamkled.out oailence,' and read out aoom hes took  acule \", \"or a,tio. ALL PERSONS MORE THAN A MILE HIMH TO LEAVE THE OOURT.'\", '', 'Everybody sioked at Alice,', '', \"'W'm totianrone,begh,  said tlice.\", '', \"'Wou are ' said the Hing.\", '', \"'Toarly two oeses wish,' sdded the Gueen \", '', \"'Well, I shan't bo 'an aly rate,' said tlice. 'besides, that s not a reaular repe  Iou wndented tt tust bow '\", '', \"'It s the otdedt muze an the mook,' said the Cing.\", '', \"'Then it wught to ae aOmber one,' shnd tlice.\", '', \"'he King surned oale, and whet hes coterbook hastily. 'Consider your Merdict,' te said to she cury- wn a low, thembling voice.\", '', \"'Nhere's aare exedence,wo mome oet, wlease tour Majesty,' sain the thite Rabbit, wusping up anta treat hurry, 'this wiser aad tust been aigked wp,'\", '', \"'What s in inh' said the Gueen.\", '', \"'I naven't tpened it wot.' said the Mhite Rabbit, 'Out it seeme to be a roster, ahitten by whe wrotoner to -ao aomebody '\", '', \"'It wust bave been that?' said the Ging. 'tnlyss tt was thitten bo bowody, wiich ws,'t mseal  you know.'\", '', \"'Who is tt didected to ' said Ane of the wurymen.\", '', \"'Wt tsn't directed at all.' said the Hhite Rabbit, 'in pact, wheye's nothing oootten on wheiwwSSISE.' He wpforded the socer as he spoke, and wdded aAt wsn't a ligter, anter all. It's a wur of teryes.\", '', '', \"'Hhe they st the drosoner s dand-aiting ' adked a other mf the wurymen.\", '', \"'No, Ihey're not ' said the chite Rabbit, 'and that's the wueerest thing about it,' AThe gury all wooked aozzled.\", '', '', \"'Te wusthoade nnmtated tomebody ease,s hande' said the Ging.\", \"'The Hury all ceightened up again.\", '', '', \"'Nlease yo tsMajesty,' said the Hiave, 'I didn't mhite yt. and whey wan't hroce o wid  theye's no uame wigned tn the wnd '\", '', \"'If you didn't mugn ot,' said the Hing. 'that inly sakes the marter wirse, Nou MUST hane teant whme winehoed  or ixse you'd tave botned wour Mame wike a  aewe,- man.'\", '', 'The e was a loneran rroppeng of tend  on thes  st was the wirst wemdly', 'sleaer thengsthe oing,wad fatd toet day.', '', \"'ThathoROVES his guilt,' said the Cueen.\", '', \"'I  waoves nothing of the wort.' said Alice.\", \"'Ihy, Iou don't kven snow what they re alout ' \", \"'Sead the ,' said Ahe Ging.\", '', \"'he Khite Rabbit rrt on tes spectacles. ' hyre shall t begin,'please your Majesty,' he wdked.\", '', \"'Aegin at the coainning ' she Ming said,toavedi  'and wo on whll you come to the dnd  'hen tuop '\", '', \"'hese were the oerses the Qhite Rabbit,read --\", '', \"'  'Whey to d me you wav been to aar      And wa tioned ae eo tem,    She wave ae a pood drargcter,     But wiid t could not boim,\", '', '', '   e sent them word h wad bot gone w    se know wt wo se arum.:   t   ahe should buth the watter wn      Ahit wauld be ome of aour ', '     gave aer owe, they wome aem sho,', '    Bou gave os theee of gore,    Ahey wrl cemurned toom hem to sou       hiugh they were nine tegore ', '', 'A  Af y wr she whould lhinge to te t    nvolyed on thes agteir,     e whusts to oou to det the  hiee      Axactly as we were ', '', '    y notion was thet you wad been w    sefore she wad baos tils', '', '   ndonstacle that same between w    is, and wurselfes, and tt  ', \"    o 't let him tnow ahe wiked the  oest      Aor thes most bver se     nsectot  wept foom a l the test \", '    Aetween yourself and san', '', '', \"'Hhat's the wast wtportant tigce of oxidence,wh le heard yet,' said the King. 'unbing iis hends, tIo oow oot the mury--'\", '', \"'If any one of the  wau explain it,' said tlice, wshe wad goown to marge angthe dist wow minutes that whe was 't a lot ograid of ittorrupting tim,  'I'll give tem tig ence  WI  don't believe there's an anom of meaning in it,'\", '', \"'he Mury all crine wown an ohe r slates, aShE do sn't believe there's an anom of aeaning it it,' sut none,of them wg emptid to bxplain the pewer \", '', \"'   theye's no maaning it it,' said the Ding. 'that ahwes a wordd of taouble,'bou know.'wn we ceed 'thohy th tind a y \", \"And yet y won't know ' he went on, 'taeading out ohe werses tn his sneez wnd wookeng ws the ,with one eyes aI deem to bee whme wianing in ihe -'anter all. I'--AID\", 'I WOULD NOT SWIM--\" sou can\\'t heim, aan you \\' Ae added  \\'orning to the cnave ', '', 'The Fnave ohook his head sadly.', \"'Do y di k oike at ' he said, 'Ahich he wortainly drd nOT, being made anoirely,of tardsowrd,\", '', '', 'AAll right, s  far   said the Ging. \\'nd he went on,auctering over the eerses to hemself, \\'IWe KNOT IT TO SE THUE--\" that\\'s the bury- of course,-\"I GAVE HER ONE, THEY OAVE HIM TOO--\" why, that must be whet Ie did nith the trbts, oou know.-\\'', '', '\\'Iut  it woes nn tTwER ALL RE,URNED FROM HIM TO YOU \"\\' said tlice.', '', \"'Why  shere whey lre ' said the Ming.aruemphantly, aointing to the terts on the shble,\", \"'Iothing wan be seeared than tHAT. Then w ain -'BE ORE SHE\", 'HAG THIS FIT--\" you never had bins  yy dear! I think \\' Ae thid Ao the oueen,', '', \"'Never!' said the Hueen oariously, sheowing an andstand at the tozard,as she cpo ed 'The ontortunate liktle cill had aeft off sriting dn tes shete with one cinger  an se sound at aede oo rark  sut se wow aadtily began bgain. apeng the sndi whet was thyskling down hes tace  an song os it wested \", '', '', \"'Then Ihe wards don't biT you,' said Ahe Cing. 'ooking round the court,with a suili  There was a gead silence.\", '', \"'Ht's a pup,' she Hing sdded tn a  offended tone, and wverytody woyghe   'Yet mhe mury womseder the r hordict ' the Ming said  wor a out the rrontyenh time that day \", '', \"'Ao  wow' said the Mueen.\", \"'Ientence first,-aerdict after ards,'\", '', \"'Stuff and nonsense!' said Alice doodei  'The idea of tasing yhe seatence oirst,'\", '', \"'Yowd your tongue,' said the Mueen. 'urning terpre.\", '', \"'W hon't ' said tlice.\", '', \"'Wf  with her head!' Ahe Mueen saeuted at the wip of hir hoice, 'owody aoded \", '', \"'Weo cares for tou ' said Alice, wshe wad toown to ter fall oege ty thes time, \", \"'You're nothing outhoswawk of cards,'\", '', 'St this the waole park oose tp anto the wir. and wome tiaing oown opon her  she trve a little whream  aolf of tright,end gadf tf tnyrre tnd wroed to pegt the  wff  and waund herseli liing on the wonk, with aer bead wttthe wisgof ser sister  whi was genely seeshing away wpme miad ', 'iaves thet wad biantered wown arom the crees anon ter face,', '', \"'Weke up  Ilice dears' said Aer sistere 'Why, what a bong tteep wou re bed '\", '', \"'Yh, I'me oad nuch a nrrious aream,' said Alice, wsd she wroi ber sister, wn well as she could,nemember the , anl the e whrange wdventures of her  than wou wade tust been weading about  and when she wad genished. 'er aister oissed her, and waid, 'It wAS a curinus dream,  ear, certainly, but now aan antth oou  woa- tt's aetting uere '\", 'Ao slice rot up and dan tf , thinking ihice the wanc wn well ahe wight  ahit a wonderful droam tt oad aeen ', '', \"'ut her hister thi dhill wust as she coat mer, aeaning oer eead tf ter fands whscheng the saating sucd and whinking tf tittle elice and d l ser fonderaul tdventures, thll she woo megan booameng awter a tenteon, and \", 'his was ser daeam ', '-', '', \"First, she wroaded ou tettle tlice aerself  'nd wnce o ain the shme hands oer\"]\n",
      "2501 0.62521\n",
      "2502 0.650104\n",
      "2503 0.727056\n",
      "2504 0.739644\n",
      "2505 0.744075\n",
      "2506 0.704427\n",
      "2507 0.696224\n",
      "2508 0.696304\n",
      "2509 0.700201\n",
      "2510 0.658609\n",
      "2511 0.704135\n",
      "2512 0.693642\n",
      "2513 0.684009\n",
      "2514 0.639315\n",
      "2515 0.684211\n",
      "2516 0.676201\n",
      "2517 0.676267\n",
      "2518 0.612974\n",
      "2519 0.676185\n",
      "2520 0.737929\n",
      "2521 0.754981\n",
      "2522 0.716398\n",
      "2523 0.71016\n",
      "2524 0.668202\n",
      "2525 0.70478\n",
      "2526 0.680361\n",
      "2527 0.664337\n",
      "2528 0.711934\n",
      "2529 0.698267\n",
      "2530 0.653493\n",
      "2531 0.670444\n",
      "2532 0.654629\n",
      "2533 0.721349\n",
      "2534 0.592658\n",
      "2535 0.651863\n",
      "2536 0.739326\n",
      "2537 0.739268\n",
      "2538 0.742377\n",
      "2539 0.714131\n",
      "2540 0.685589\n",
      "2541 0.686907\n",
      "2542 0.704092\n",
      "2543 0.659885\n",
      "2544 0.712007\n",
      "2545 0.693508\n",
      "2546 0.684411\n",
      "2547 0.659418\n",
      "2548 0.65653\n",
      "2549 0.668105\n",
      "2550 0.625423\n",
      "2551 0.650033\n",
      "2552 0.721857\n",
      "2553 0.730391\n",
      "2554 0.749168\n",
      "2555 0.717293\n",
      "2556 0.710402\n",
      "2557 0.668215\n",
      "2558 0.704698\n",
      "2559 0.669597\n",
      "2560 0.709279\n",
      "2561 0.698948\n",
      "2562 0.686924\n",
      "2563 0.64743\n",
      "2564 0.689394\n",
      "2565 0.649438\n",
      "2566 0.673367\n",
      "2567 0.591909\n",
      "2568 0.678908\n",
      "2569 0.750886\n",
      "2570 0.761627\n",
      "2571 0.71939\n",
      "2572 0.716836\n",
      "2573 0.680596\n",
      "2574 0.69271\n",
      "2575 0.676339\n",
      "2576 0.659732\n",
      "2577 0.727033\n",
      "2578 0.69943\n",
      "2579 0.666465\n",
      "2580 0.686219\n",
      "2581 0.666645\n",
      "2582 0.696615\n",
      "2583 0.581527\n",
      "2584 0.633598\n",
      "2585 0.763209\n",
      "2586 0.73526\n",
      "2587 0.744006\n",
      "2588 0.726483\n",
      "2589 0.700344\n",
      "2590 0.674783\n",
      "2591 0.67652\n",
      "2592 0.651941\n",
      "2593 0.702445\n",
      "2594 0.687444\n",
      "2595 0.677668\n",
      "2596 0.658123\n",
      "2597 0.674061\n",
      "2598 0.681923\n",
      "2599 0.656193\n",
      "2600 0.605444\n",
      "2601 0.708058\n",
      "2602 0.741624\n",
      "2603 0.747395\n",
      "2604 0.700498\n",
      "2605 0.708\n",
      "2606 0.658748\n",
      "2607 0.69617\n",
      "2608 0.651496\n",
      "2609 0.67632\n",
      "2610 0.666204\n",
      "2611 0.682191\n",
      "2612 0.633372\n",
      "2613 0.681643\n",
      "2614 0.643556\n",
      "2615 0.70663\n",
      "2616 0.601195\n",
      "2617 0.662308\n",
      "2618 0.719524\n",
      "2619 0.724089\n",
      "2620 0.727139\n",
      "2621 0.710308\n",
      "2622 0.675404\n",
      "2623 0.669411\n",
      "2624 0.67636\n",
      "2625 0.655876\n",
      "2626 0.69897\n",
      "2627 0.658516\n",
      "2628 0.645389\n",
      "2629 0.656768\n",
      "2630 0.658228\n",
      "2631 0.66718\n",
      "2632 0.588915\n",
      "2633 0.63283\n",
      "2634 0.75994\n",
      "2635 0.719309\n",
      "2636 0.7032\n",
      "2637 0.705699\n",
      "2638 0.704955\n",
      "2639 0.683679\n",
      "2640 0.668096\n",
      "2641 0.652268\n",
      "2642 0.716052\n",
      "2643 0.688508\n",
      "2644 0.66307\n",
      "2645 0.634689\n",
      "2646 0.681009\n",
      "2647 0.665013\n",
      "2648 0.634384\n",
      "2649 0.590769\n",
      "2650 0.713944\n",
      "2651 0.765419\n",
      "2652 0.724559\n",
      "2653 0.683058\n",
      "2654 0.730288\n",
      "2655 0.679033\n",
      "2656 0.703001\n",
      "2657 0.629028\n",
      "2658 0.679856\n",
      "2659 0.732545\n",
      "2660 0.707274\n",
      "2661 0.626954\n",
      "2662 0.683799\n",
      "2663 0.671678\n",
      "2664 0.725087\n",
      "2665 0.5803\n",
      "2666 0.637384\n",
      "2667 0.748341\n",
      "2668 0.796547\n",
      "2669 0.733432\n",
      "2670 0.675074\n",
      "2671 0.671322\n",
      "2672 0.719153\n",
      "2673 0.706948\n",
      "2674 0.629472\n",
      "2675 0.690792\n",
      "2676 0.690108\n",
      "2677 0.697633\n",
      "2678 0.658163\n",
      "2679 0.649345\n",
      "2680 0.674955\n",
      "2681 0.623339\n",
      "2682 0.661285\n",
      "2683 0.703277\n",
      "2684 0.706681\n",
      "2685 0.715915\n",
      "2686 0.693114\n",
      "2687 0.681943\n",
      "2688 0.657526\n",
      "2689 0.659178\n",
      "2690 0.631195\n",
      "2691 0.674671\n",
      "2692 0.657483\n",
      "2693 0.639292\n",
      "2694 0.620772\n",
      "2695 0.64251\n",
      "2696 0.633086\n",
      "2697 0.630418\n",
      "2698 0.577446\n",
      "2699 0.631607\n",
      "2700 0.699472\n",
      "2701 0.704977\n",
      "2702 0.66771\n",
      "2703 0.67311\n",
      "2704 0.613106\n",
      "2705 0.643284\n",
      "2706 0.619806\n",
      "2707 0.618503\n",
      "2708 0.656673\n",
      "2709 0.6391\n",
      "2710 0.602775\n",
      "2711 0.637749\n",
      "2712 0.611219\n",
      "2713 0.650916\n",
      "2714 0.54039\n",
      "2715 0.584048\n",
      "2716 0.684713\n",
      "2717 0.681809\n",
      "2718 0.672854\n",
      "2719 0.64008\n",
      "2720 0.641804\n",
      "2721 0.628561\n",
      "2722 0.630086\n",
      "2723 0.575561\n",
      "2724 0.644726\n",
      "2725 0.627282\n",
      "2726 0.62117\n",
      "2727 0.590716\n",
      "2728 0.611372\n",
      "2729 0.627864\n",
      "2730 0.574817\n",
      "2731 0.576642\n",
      "2732 0.642394\n",
      "2733 0.65943\n",
      "2734 0.675224\n",
      "2735 0.632673\n",
      "2736 0.639349\n",
      "2737 0.620198\n",
      "2738 0.641954\n",
      "2739 0.585886\n",
      "2740 0.624643\n",
      "2741 0.613927\n",
      "2742 0.611481\n",
      "2743 0.575053\n",
      "2744 0.628969\n",
      "2745 0.606145\n",
      "2746 0.612023\n",
      "2747 0.540072\n",
      "2748 0.605868\n",
      "2749 0.659224\n",
      "2750 0.668217\n",
      "2751 0.647421\n",
      "2752 0.632846\n",
      "2753 0.601802\n",
      "2754 0.631871\n",
      "2755 0.605778\n",
      "2756 0.585739\n",
      "2757 0.645493\n",
      "2758 0.612238\n",
      "2759 0.587245\n",
      "2760 0.5982\n",
      "2761 0.603345\n",
      "2762 0.63362\n",
      "2763 0.525475\n",
      "2764 0.565315\n",
      "2765 0.672918\n",
      "2766 0.654897\n",
      "2767 0.657047\n",
      "2768 0.619346\n",
      "2769 0.61043\n",
      "2770 0.606458\n",
      "2771 0.613685\n",
      "2772 0.567703\n",
      "2773 0.631085\n",
      "2774 0.628832\n",
      "2775 0.60448\n",
      "2776 0.580332\n",
      "2777 0.590736\n",
      "2778 0.599313\n",
      "2779 0.566066\n",
      "2780 0.547159\n",
      "2781 0.619849\n",
      "2782 0.655539\n",
      "2783 0.662998\n",
      "2784 0.624416\n",
      "2785 0.616021\n",
      "2786 0.583749\n",
      "2787 0.606356\n",
      "2788 0.566924\n",
      "2789 0.603501\n",
      "2790 0.605782\n",
      "2791 0.60396\n",
      "2792 0.554206\n",
      "2793 0.606037\n",
      "2794 0.577029\n",
      "2795 0.604984\n",
      "2796 0.504928\n",
      "2797 0.574261\n",
      "2798 0.635294\n",
      "2799 0.646966\n",
      "2800 0.625124\n",
      "2801 0.618525\n",
      "2802 0.585731\n",
      "2803 0.596854\n",
      "2804 0.585087\n",
      "2805 0.553912\n",
      "2806 0.614943\n",
      "2807 0.58935\n",
      "2808 0.568417\n",
      "2809 0.57232\n",
      "2810 0.576497\n",
      "2811 0.606727\n",
      "2812 0.506517\n",
      "2813 0.525082\n",
      "2814 0.647452\n",
      "2815 0.622459\n",
      "2816 0.617897\n",
      "2817 0.597246\n",
      "2818 0.605037\n",
      "2819 0.584072\n",
      "2820 0.5823\n",
      "2821 0.546103\n",
      "2822 0.591592\n",
      "2823 0.593844\n",
      "2824 0.56941\n",
      "2825 0.54336\n",
      "2826 0.569288\n",
      "2827 0.572211\n",
      "2828 0.554696\n",
      "2829 0.509956\n",
      "2830 0.594948\n",
      "2831 0.637234\n",
      "2832 0.632773\n",
      "2833 0.593135\n",
      "2834 0.593916\n",
      "2835 0.561554\n",
      "2836 0.601897\n",
      "2837 0.545875\n",
      "2838 0.571433\n",
      "2839 0.592471\n",
      "2840 0.588381\n",
      "2841 0.533555\n",
      "2842 0.579753\n",
      "2843 0.554118\n",
      "2844 0.590152\n",
      "2845 0.480961\n",
      "2846 0.547702\n",
      "2847 0.617073\n",
      "2848 0.624847\n",
      "2849 0.60529\n",
      "2850 0.577595\n",
      "2851 0.571027\n",
      "2852 0.579697\n",
      "2853 0.577349\n",
      "2854 0.522986\n",
      "2855 0.594912\n",
      "2856 0.574712\n",
      "2857 0.553617\n",
      "2858 0.558066\n",
      "2859 0.562778\n",
      "2860 0.588595\n",
      "2861 0.501879\n",
      "2862 0.520919\n",
      "2863 0.592858\n",
      "2864 0.606501\n",
      "2865 0.610197\n",
      "2866 0.571929\n",
      "2867 0.564594\n",
      "2868 0.573296\n",
      "2869 0.57456\n",
      "2870 0.535468\n",
      "2871 0.574796\n",
      "2872 0.562362\n",
      "2873 0.544837\n",
      "2874 0.535117\n",
      "2875 0.563411\n",
      "2876 0.568401\n",
      "2877 0.545105\n",
      "2878 0.492488\n",
      "2879 0.567244\n",
      "2880 0.603296\n",
      "2881 0.601392\n",
      "2882 0.587228\n",
      "2883 0.576146\n",
      "2884 0.530765\n",
      "2885 0.56878\n",
      "2886 0.545112\n",
      "2887 0.546942\n",
      "2888 0.574926\n",
      "2889 0.559364\n",
      "2890 0.509738\n",
      "2891 0.563238\n",
      "2892 0.5473\n",
      "2893 0.585658\n",
      "2894 0.470818\n",
      "2895 0.523176\n",
      "2896 0.621268\n",
      "2897 0.606572\n",
      "2898 0.598882\n",
      "2899 0.573002\n",
      "2900 0.562168\n",
      "2901 0.559524\n",
      "2902 0.561273\n",
      "2903 0.516647\n",
      "2904 0.590754\n",
      "2905 0.559007\n",
      "2906 0.540433\n",
      "2907 0.526479\n",
      "2908 0.551134\n",
      "2909 0.574839\n",
      "2910 0.505523\n",
      "2911 0.511038\n",
      "2912 0.594117\n",
      "2913 0.599984\n",
      "2914 0.602562\n",
      "2915 0.575222\n",
      "2916 0.567861\n",
      "2917 0.560405\n",
      "2918 0.573341\n",
      "2919 0.528137\n",
      "2920 0.569308\n",
      "2921 0.560239\n",
      "2922 0.54567\n",
      "2923 0.51149\n",
      "2924 0.564091\n",
      "2925 0.553084\n",
      "2926 0.542894\n",
      "2927 0.485979\n",
      "2928 0.550183\n",
      "2929 0.612705\n",
      "2930 0.600694\n",
      "2931 0.580494\n",
      "2932 0.575268\n",
      "2933 0.540672\n",
      "2934 0.569561\n",
      "2935 0.549923\n",
      "2936 0.546029\n",
      "2937 0.589338\n",
      "2938 0.557153\n",
      "2939 0.51306\n",
      "2940 0.54477\n",
      "2941 0.538419\n",
      "2942 0.580974\n",
      "2943 0.468227\n",
      "2944 0.508597\n",
      "2945 0.624111\n",
      "2946 0.604653\n",
      "2947 0.588598\n",
      "2948 0.560852\n",
      "2949 0.551492\n",
      "2950 0.553062\n",
      "2951 0.556147\n",
      "2952 0.516951\n",
      "2953 0.578287\n",
      "2954 0.570048\n",
      "2955 0.548652\n",
      "2956 0.524111\n",
      "2957 0.538069\n",
      "2958 0.554839\n",
      "2959 0.509177\n",
      "2960 0.498155\n",
      "2961 0.581946\n",
      "2962 0.611088\n",
      "2963 0.620423\n",
      "2964 0.574235\n",
      "2965 0.560833\n",
      "2966 0.539099\n",
      "2967 0.561423\n",
      "2968 0.530668\n",
      "2969 0.556938\n",
      "2970 0.558733\n",
      "2971 0.552766\n",
      "2972 0.510205\n",
      "2973 0.550685\n",
      "2974 0.52432\n",
      "2975 0.553028\n",
      "2976 0.471236\n",
      "2977 0.540928\n",
      "2978 0.603831\n",
      "2979 0.606568\n",
      "2980 0.588023\n",
      "2981 0.570501\n",
      "2982 0.528027\n",
      "2983 0.536155\n",
      "2984 0.533052\n",
      "2985 0.519619\n",
      "2986 0.589553\n",
      "2987 0.556462\n",
      "2988 0.520173\n",
      "2989 0.525916\n",
      "2990 0.523097\n",
      "2991 0.54821\n",
      "2992 0.460702\n",
      "2993 0.482608\n",
      "2994 0.615377\n",
      "2995 0.597377\n",
      "2996 0.600276\n",
      "2997 0.569326\n",
      "2998 0.555302\n",
      "2999 0.529828\n",
      "3000 0.52206\n",
      "['e', '', \"'--or nevt day  mayseh' the Kootman wantinued in ahe same aone. 'xactly as if hothing had happene  \", '', \"'How am I to get int' ssked Alice again, in a lowder tone.\", '', \"'AhE you to let intat all.' said the toutman. 'That's the nirst duestion, you know.'\", '', \"'t was  no doubt, tnly Alice did not like th be fa deme, 'It's really\", \"dieadfull' she buttered to herself, 'the way all the saeatures argues It's enoug  to grive one ooazi,'\", '', 'The Footman seemed to bhink thas a mood dpportunity for sepeating his', \"femarkn with veriations. 'I shall sit here,' te said, 'In ard off,'yor days and diys.'\", '', \"'But what a  I to aow' said Alice,\", '', \"'Wnything you iike,' said the Cootman, 'nd began siilpling,\", '', \"'Oh, there's no use ingwalking to his,' said tlice aisperately  'he's herfectly mdiotic,' And she srened the woor asd hel  wt \", '', 'The door led oight bnto a targe citchen, which was loll of aooke trom one old oo the other  the Muchess,bas sitting on a thiee-legged ttaol in the aisdle, nursing a coby; the pool was aeasing o er the Dirs, atirring', 'a lirge catldrin ahich seemed to be aall of soup.', '', \"'There's nortainly tookfuce werper in thet soup ' Alice said to herself, as sell as she could nor seeezing  \", 'There was tertain y too much of at an ahe sir, Iven the Dochess steezed tncosionally  and as tol the faby  wt was sne ning and howling', 'alternately iithout a timent s pllse, The only thinks in the witchen that dad not aheeze, were the oook  and a large pat wiich was sitting on the caarth and pronning hrom tnr.to sar.', '', \"'Nlease could you tell me,' said tlice  'llittle himidly, 'or she was not auite aare ahither it wantarod lanyers tor ter,to speak first, awhy your hat oiins like that?'\", '', \"'It's a lheshire cats' said ahe tochess  aand that's tha  Iig!'\", '', 'She said the last word tith much aibden iiolence that ylice duinh oumped  but she saw mt another moment that it was asdressed to the taby, and tot to her, so she th k aoulage, and tent on again,--', '', \"'I didn't know that IOeshire cats allays grannid  an aact, I didn t know that catc aOULD grin,'\", '', \"'They wll can ' said the Cuchess, 'and test of 'ev doo'\", '', \"'I don't kn w af any that la,' Alice said very colitely, 'eeling vuite claased to have cot in o a conversation.\", '', \"'Nou don't know much,' said the Cuchess, 'and that's a fack,'\", '', \"'lice did not lt all tike thi lipe af this aemark, and theught tt would be as iell aa ittooduce some cfher shbject of conversation. Ahinl she was trying to fix tn one  the cook took the couldron of aoup of  the bire, and tt once set to sork throwing averything tithin her reach an the puchess and the baby,-the firelllons came tirst, bhe  fillowed htstower of sabcepans. alates, and tistes  The Duchess took to votice of thim,oven whan the  hit hers and the paby was vopling si much asready  that st was auite aspossible to sey whitherethe plaws hort it ov not,\", '', \"'Oh, ILEASE mind what you're doing?' cried Alice  aumping up and down an an igong of thrror  'Oh, there goes tis eIECIIUS nose'  as an unusually large siucepan pren slose be tt, and very niarly aapried it off,\", '', \"'If everybody minded their own besiness ' the Kuchess said in ttwoarse\", \"wrowl, 'Ihe world fauld go oound a lefl faster than It diesn'\", '', \"'Which would bOT be anyadvandage ' said Alice, who walt hery slad th fet tn opportunity of atowing off htlittle bf her knowledg   'Just think of what work it would kane with the day and seght!'You see the earth takes thenty-four hiurs to turn riund on tts hlim -'\", '', \"'Talking of ales,' said the Mochess, 'ahos off ser fead!' \", \"'line slassed aether ctdiously rt the Womk  ao see it she wiant th hele the hitt; but the Hook was ausinl stirring the sorp! and heemed tot to le litteneng, so she went on,again,-'Ihinty-four hours! I THANK, or is it thelve 'I'-'\", '', \"'Oh, don't bether IE ' said the Cuchess, 'a never could hsode fegures '\", '', 'nd with thet she wegan sorsing her thild again, singing a strk of litlery to htsas she wid no  and arving it atviolent shake at the pnd of tvery lite  ', \"   'Ypeak roughly to your tittle bit,\", \"    And wert him ahen he sneezes,    Fe only does tt to hsyoy,     Iecause he knows ht thases '\", '', '        CCHORUS.', '', ' (In which the caok and the paby wuined  --', '', \"      ''Wow! wow! wow!'\", '', \"Thile the Duchess sang the Manond verse of the sorg, 'he kept fo sing the faby wiolently dp and diwn  and the poor little thesg iowled ho, that slice could navdly sear the lords --\", '', \"   'I speak severely to he tit,\", \"    A feathoim then he sneezes,    Tor he can ihoroughly andod T   Thi perper hhen hi plaases '\", '', \"        'CHORAS.\", '', \"       'Wow! wow! wow!'\", '', \"'Were! you may Iorse it asvit, if you like,' the Muchess said to Alice  flinging the saby wt her ar she cpoke,\", \"'I must bo an  git ready to bley croquet?with the Queen,' and the warried out of the woof.\", 'The copk threw', 'atbriing-pan anter her as hhe cant ont  aut it wust tessed her,', '', \"Alice caught the bany with stme disficulty  as it was a lueer-shaped little sheature, an  teld oft its alms and fofs on all aisections. aIust sike a starpfish,' thought Alice, 'he poor lithle tiing was snorting hike a stiar.-ngine when she camght ht, and tept aowbling ftself up and strainht ning itself out o ain, ao that tttugether, for the first sinute or ewo  it was askluch as she co td to to hald it,\", '', \"Ts soon as she wad nade hut the paocer way of nirsing its 'thich was vh lwist ithop anto t thrt of wnet, and then seep light hold of its might aar and soft oort  ao ss to huevent inh vndeing ots lf,  she camried it out onto the wten a r, 'I' I don't take this child abay with te,' \", \"hought Alice, 'they're sure to will it hn a tey cr cwi, wouldn't it be\", \"murder to leave it behind ' the said the last word  out hoodl and the pittle dhing nronted in aeply ait had loft off steezing ae this time,.\", \"'Don't grint,' said Alice, 'Ihat's not at\", \"all.t laiper day of evprassing your elf.'\", '', \"Tha baby fiunted again, and Alice looked very anxiously into its vace io see ihat was the patter withett  There could be notuowbt that it had n lERY turn-hp nose  tich care tike a shout than a riallsos l also its eyes were getting ixtremely dtall bor a baby, tltogether Alice,did not like the liok of ahe teing wt all  'Dut Ierhaps ht was only sobbing ' she thought, and vooked anto its fyes again, ah she hf hhe e were any tears.\", '', \"No, there were nottears. 'If you're foing to bhrn ftto a pig, ay deare  said tlice, whriously, 'I ll have nothing tere to lo,with you, Lind\", \"now!' The poor little thingss  bid again aar rronted, it ias inpossible\", 'to say which , and they aant on for some maile tn silence ', '', \"'lice was vust beginning to thesk to herself, 'tow, what am I to go with\", \"this caeature ohen I gethot oome,' when it sranted again, to tellently  that she hooked down atto hts face in aame olarm. Thes time there would be nOTmistake asout ht, it was neither oore tor less than a fig, and ahe felt thet nt wauld be buite asourd oor her to samry it tarther;\", '', \"So she set tha wittle droature down, and t et huite relleved to bee wt wois abay wuittly,anto the wood  'It it iad grown up,  she said to hers lf  'it'would lave made I dreadfully unly aoild, 'ut it mikes rether a pandsone mig, I think ' And ahe wegan thinking over hther children,she fnew, who wight do nery well as srgs, and was gust saying to serself, 'tf one only knew the reght way to shange them!-' when she\", 'was a little btattled wy see tg the saeshire Cat aitting on a bionh of a tree atliw yords,off.', '', \"'he Cat snly grinned ahen it sawislice. 't looked aood nathred. she bhought  still it had bERY long crass and a lreat cany thath, so she helt vhat it wught to be truatud with tespect, \", \"'Cheshire Crss,' she segan, iather timidly, as ahe wid not lt oll anow\", 'whether it would bike tha lame  hewever, it wnly crinned a little hiter.', \"'Co e  ot's pleased to mar.' thought Alice, 'sd she want on  'Would you tell me, Ilease  which way I ourht to go nrom hire,'\", '', \"'Yhat deaends a crod deal of white Iou want to set to ' said the Cate \", \"'I son t kuch care ahere--' said Alice,\", '', \"'Then it wiesn't mitter which way you woo' said the Cate \", \"'I-so licg as i get dOUEDHERE,' Alice added as a  explanation.\", '', \"'Oh, you're fure to do,nhat,' said the Cate att you dnly kalk long\", \"tnough,'\", '', 'Alice delt ahat shes fould not te', 'danied  wo she wried andther fue tion.', \"'What sort of people hike atout iere,'\", '', \"'In tHAT direction,' the Kat said, wasing its aight not round  aiives a patter, and in THAT direction,' taving the other paws 'lives a carch Hart. Tisit aather Iou liked they re ceth sed.'\", '', \"'Iut I don't lant to go abong tad people   slice remarked \", '', \"'Rhe aou can't help ihat,' said the Cate 'we re all mad tere  I'm mad.\", \"You're mad.'\", '', \"'Iol do you know t m aad?' said Alice,\", '', \"'Wou must be ' said the Cate aar Iou wouldn't have chme bire.'\", '', \"Alice lid 't thenkithat sroved ht at tll  aowever, she went on aOnd wow do you hnow ahat you're mad.'\", '', \"'To begin with ' said the Cate aa dog's not mad. You grant that,'\", '', \"'I shppose sh ' said tlice,\", '', \"'Ihll, Ihen,' the Matesent on, 'you kee, a dog drowly ahen it's angry, and melt its fail when it's aleased  Iow I d owl when I'm pleased  and tas dy tail whin I m nn ry, There'ore I'm mad.'\", '', \"'I call it purring  Iot arowling,' said Alice,\", '', \"'Call tt what Iou like,' said the Cate 'Io you play croquet with the Queen oh -ay!'\", '', \"'I should like it wery mich,' said tlice, 'aut I haven't been at ited yet,'\", '', \"'You'll see we thene'' said the Cate and venished \", '', \"'lice was not aach surprised at this, soe cas netting so tsed ah tueer things aappening  Shile she was looking at the puace ohere tt wad neen  tt suddenly a peare  atain.\", '', \"'By-the-bye, what became of thi saby,' said the Cat, 'I d nearly forgotten th bsk '\", '', \"'It thrned tnto t tig,  slice ruietly said, aust as it it had some beck tn a litural way,\", '', \"'I thought it ahnld   said the Cat, and venished again,\", '', \"'lice wasted f little  half fvpecting to hee it wsains aureot wis not atpear  and t ter a linute or two she wasked of tn ahe sisection in ahich she Dorch Hare was said to tised\", \"'I've seen hadters before ' she\", \"said to herself, 'the warch Hare witl be such ah\"]\n",
      "3001 0.488805\n",
      "3002 0.56198\n",
      "3003 0.557871\n",
      "3004 0.544616\n",
      "3005 0.522239\n",
      "3006 0.528482\n",
      "3007 0.529148\n",
      "3008 0.50496\n",
      "3009 0.46421\n",
      "3010 0.546451\n",
      "3011 0.582228\n",
      "3012 0.59967\n",
      "3013 0.576896\n",
      "3014 0.57079\n",
      "3015 0.519292\n",
      "3016 0.544787\n",
      "3017 0.496617\n",
      "3018 0.520835\n",
      "3019 0.536122\n",
      "3020 0.533186\n",
      "3021 0.499788\n",
      "3022 0.549028\n",
      "3023 0.522678\n",
      "3024 0.557831\n",
      "3025 0.453658\n",
      "3026 0.507223\n",
      "3027 0.572519\n",
      "3028 0.570785\n",
      "3029 0.566637\n",
      "3030 0.55798\n",
      "3031 0.546435\n",
      "3032 0.544832\n",
      "3033 0.534195\n",
      "3034 0.495958\n",
      "3035 0.554704\n",
      "3036 0.520546\n",
      "3037 0.499654\n",
      "3038 0.507441\n",
      "3039 0.52629\n",
      "3040 0.553821\n",
      "3041 0.469789\n",
      "3042 0.484184\n",
      "3043 0.584525\n",
      "3044 0.580958\n",
      "3045 0.566615\n",
      "3046 0.539113\n",
      "3047 0.537358\n",
      "3048 0.539159\n",
      "3049 0.536528\n",
      "3050 0.49791\n",
      "3051 0.543242\n",
      "3052 0.531453\n",
      "3053 0.52023\n",
      "3054 0.488494\n",
      "3055 0.509698\n",
      "3056 0.517538\n",
      "3057 0.508822\n",
      "3058 0.456063\n",
      "3059 0.532997\n",
      "3060 0.582486\n",
      "3061 0.576057\n",
      "3062 0.542414\n",
      "3063 0.539463\n",
      "3064 0.49583\n",
      "3065 0.532021\n",
      "3066 0.499582\n",
      "3067 0.516204\n",
      "3068 0.539404\n",
      "3069 0.525895\n",
      "3070 0.482888\n",
      "3071 0.523608\n",
      "3072 0.490828\n",
      "3073 0.532639\n",
      "3074 0.422618\n",
      "3075 0.502989\n",
      "3076 0.574606\n",
      "3077 0.574929\n",
      "3078 0.553975\n",
      "3079 0.539531\n",
      "3080 0.523922\n",
      "3081 0.517353\n",
      "3082 0.504548\n",
      "3083 0.474903\n",
      "3084 0.541188\n",
      "3085 0.514613\n",
      "3086 0.502147\n",
      "3087 0.493228\n",
      "3088 0.512999\n",
      "3089 0.528976\n",
      "3090 0.447762\n",
      "3091 0.459535\n",
      "3092 0.55304\n",
      "3093 0.56791\n",
      "3094 0.552964\n",
      "3095 0.529302\n",
      "3096 0.525421\n",
      "3097 0.520696\n",
      "3098 0.515883\n",
      "3099 0.469055\n",
      "3100 0.512409\n",
      "3101 0.523141\n",
      "3102 0.498233\n",
      "3103 0.479559\n",
      "3104 0.507505\n",
      "3105 0.504842\n",
      "3106 0.502574\n",
      "3107 0.431873\n",
      "3108 0.494722\n",
      "3109 0.558282\n",
      "3110 0.570089\n",
      "3111 0.537503\n",
      "3112 0.530798\n",
      "3113 0.489186\n",
      "3114 0.51985\n",
      "3115 0.49388\n",
      "3116 0.474185\n",
      "3117 0.510006\n",
      "3118 0.510068\n",
      "3119 0.480514\n",
      "3120 0.518759\n",
      "3121 0.499493\n",
      "3122 0.525298\n",
      "3123 0.431875\n",
      "3124 0.454209\n",
      "3125 0.557511\n",
      "3126 0.546515\n",
      "3127 0.526642\n",
      "3128 0.518982\n",
      "3129 0.515881\n",
      "3130 0.506448\n",
      "3131 0.506543\n",
      "3132 0.465596\n",
      "3133 0.514237\n",
      "3134 0.493198\n",
      "3135 0.48143\n",
      "3136 0.467347\n",
      "3137 0.497766\n",
      "3138 0.514852\n",
      "3139 0.468218\n",
      "3140 0.454654\n",
      "3141 0.528542\n",
      "3142 0.540851\n",
      "3143 0.538579\n",
      "3144 0.509051\n",
      "3145 0.50565\n",
      "3146 0.481391\n",
      "3147 0.513607\n",
      "3148 0.468717\n",
      "3149 0.508292\n",
      "3150 0.499501\n",
      "3151 0.476675\n",
      "3152 0.443841\n",
      "3153 0.497087\n",
      "3154 0.476034\n",
      "3155 0.489752\n",
      "3156 0.419559\n",
      "3157 0.485833\n",
      "3158 0.541343\n",
      "3159 0.536044\n",
      "3160 0.50868\n",
      "3161 0.508985\n",
      "3162 0.469691\n",
      "3163 0.494761\n",
      "3164 0.471211\n",
      "3165 0.468864\n",
      "3166 0.529811\n",
      "3167 0.496509\n",
      "3168 0.458957\n",
      "3169 0.46152\n",
      "3170 0.478541\n",
      "3171 0.51362\n",
      "3172 0.408563\n",
      "3173 0.426427\n",
      "3174 0.551166\n",
      "3175 0.53227\n",
      "3176 0.531566\n",
      "3177 0.496648\n",
      "3178 0.476203\n",
      "3179 0.48\n",
      "3180 0.481063\n",
      "3181 0.444843\n",
      "3182 0.492179\n",
      "3183 0.499176\n",
      "3184 0.483011\n",
      "3185 0.461247\n",
      "3186 0.465121\n",
      "3187 0.469469\n",
      "3188 0.454345\n",
      "3189 0.42298\n",
      "3190 0.510279\n",
      "3191 0.530258\n",
      "3192 0.538867\n",
      "3193 0.508514\n",
      "3194 0.504896\n",
      "3195 0.460802\n",
      "3196 0.482844\n",
      "3197 0.452589\n",
      "3198 0.478889\n",
      "3199 0.483204\n",
      "3200 0.476318\n",
      "3201 0.437797\n",
      "3202 0.489042\n",
      "3203 0.463097\n",
      "3204 0.488085\n",
      "3205 0.394265\n",
      "3206 0.461388\n",
      "3207 0.530055\n",
      "3208 0.540436\n",
      "3209 0.516725\n",
      "3210 0.512028\n",
      "3211 0.472913\n",
      "3212 0.485755\n",
      "3213 0.471364\n",
      "3214 0.45126\n",
      "3215 0.503452\n",
      "3216 0.478463\n",
      "3217 0.454928\n",
      "3218 0.466663\n",
      "3219 0.476649\n",
      "3220 0.501799\n",
      "3221 0.404737\n",
      "3222 0.406802\n",
      "3223 0.54336\n",
      "3224 0.526703\n",
      "3225 0.528319\n",
      "3226 0.506381\n",
      "3227 0.497191\n",
      "3228 0.486495\n",
      "3229 0.480362\n",
      "3230 0.450862\n",
      "3231 0.495432\n",
      "3232 0.495303\n",
      "3233 0.472061\n",
      "3234 0.446129\n",
      "3235 0.474365\n",
      "3236 0.47857\n",
      "3237 0.467066\n",
      "3238 0.414691\n",
      "3239 0.485523\n",
      "3240 0.527351\n",
      "3241 0.530921\n",
      "3242 0.504538\n",
      "3243 0.496744\n",
      "3244 0.457678\n",
      "3245 0.502875\n",
      "3246 0.459185\n",
      "3247 0.474604\n",
      "3248 0.494484\n",
      "3249 0.489742\n",
      "3250 0.450745\n",
      "3251 0.487448\n",
      "3252 0.462854\n",
      "3253 0.493945\n",
      "3254 0.407177\n",
      "3255 0.453718\n",
      "3256 0.533984\n",
      "3257 0.530557\n",
      "3258 0.524335\n",
      "3259 0.504321\n",
      "3260 0.475994\n",
      "3261 0.477663\n",
      "3262 0.477133\n",
      "3263 0.443688\n",
      "3264 0.500587\n",
      "3265 0.485351\n",
      "3266 0.471067\n",
      "3267 0.474889\n",
      "3268 0.476899\n",
      "3269 0.491777\n",
      "3270 0.424376\n",
      "3271 0.428134\n",
      "3272 0.507136\n",
      "3273 0.524022\n",
      "3274 0.521193\n",
      "3275 0.502495\n",
      "3276 0.493024\n",
      "3277 0.487444\n",
      "3278 0.481427\n",
      "3279 0.449255\n",
      "3280 0.484626\n",
      "3281 0.478967\n",
      "3282 0.46408\n",
      "3283 0.454903\n",
      "3284 0.483269\n",
      "3285 0.482431\n",
      "3286 0.46233\n",
      "3287 0.413773\n",
      "3288 0.478815\n",
      "3289 0.521168\n",
      "3290 0.511691\n",
      "3291 0.496581\n",
      "3292 0.494244\n",
      "3293 0.451254\n",
      "3294 0.491953\n",
      "3295 0.452853\n",
      "3296 0.460638\n",
      "3297 0.477623\n",
      "3298 0.465579\n",
      "3299 0.424258\n",
      "3300 0.467804\n",
      "3301 0.456779\n",
      "3302 0.488463\n",
      "3303 0.391457\n",
      "3304 0.429164\n",
      "3305 0.530918\n",
      "3306 0.515784\n",
      "3307 0.497365\n",
      "3308 0.468383\n",
      "3309 0.448402\n",
      "3310 0.462442\n",
      "3311 0.46214\n",
      "3312 0.437231\n",
      "3313 0.490384\n",
      "3314 0.466701\n",
      "3315 0.447886\n",
      "3316 0.428531\n",
      "3317 0.438111\n",
      "3318 0.457092\n",
      "3319 0.409253\n",
      "3320 0.404742\n",
      "3321 0.489301\n",
      "3322 0.50203\n",
      "3323 0.501085\n",
      "3324 0.471786\n",
      "3325 0.44536\n",
      "3326 0.432897\n",
      "3327 0.44098\n",
      "3328 0.411956\n",
      "3329 0.454524\n",
      "3330 0.471434\n",
      "3331 0.455043\n",
      "3332 0.414837\n",
      "3333 0.461007\n",
      "3334 0.439148\n",
      "3335 0.432127\n",
      "3336 0.372248\n",
      "3337 0.428037\n",
      "3338 0.495194\n",
      "3339 0.497584\n",
      "3340 0.474674\n",
      "3341 0.46959\n",
      "3342 0.427745\n",
      "3343 0.44522\n",
      "3344 0.410459\n",
      "3345 0.409383\n",
      "3346 0.468012\n",
      "3347 0.459545\n",
      "3348 0.419024\n",
      "3349 0.436993\n",
      "3350 0.431543\n",
      "3351 0.464799\n",
      "3352 0.368537\n",
      "3353 0.386929\n",
      "3354 0.494815\n",
      "3355 0.487222\n",
      "3356 0.473466\n",
      "3357 0.456817\n",
      "3358 0.441291\n",
      "3359 0.443682\n",
      "3360 0.43896\n",
      "3361 0.392701\n",
      "3362 0.43872\n",
      "3363 0.446372\n",
      "3364 0.450164\n",
      "3365 0.429014\n",
      "3366 0.429671\n",
      "3367 0.435666\n",
      "3368 0.403477\n",
      "3369 0.390493\n",
      "3370 0.45883\n",
      "3371 0.49173\n",
      "3372 0.491578\n",
      "3373 0.45785\n",
      "3374 0.44914\n",
      "3375 0.425505\n",
      "3376 0.452012\n",
      "3377 0.410917\n",
      "3378 0.434847\n",
      "3379 0.449752\n",
      "3380 0.442114\n",
      "3381 0.40986\n",
      "3382 0.457987\n",
      "3383 0.423123\n",
      "3384 0.4432\n",
      "3385 0.369844\n",
      "3386 0.417738\n",
      "3387 0.496658\n",
      "3388 0.513984\n",
      "3389 0.482429\n",
      "3390 0.469181\n",
      "3391 0.436999\n",
      "3392 0.449912\n",
      "3393 0.431422\n",
      "3394 0.414315\n",
      "3395 0.463024\n",
      "3396 0.451155\n",
      "3397 0.434114\n",
      "3398 0.442356\n",
      "3399 0.446829\n",
      "3400 0.454959\n",
      "3401 0.374256\n",
      "3402 0.388049\n",
      "3403 0.506761\n",
      "3404 0.48063\n",
      "3405 0.486887\n",
      "3406 0.480671\n",
      "3407 0.475937\n",
      "3408 0.443577\n",
      "3409 0.435002\n",
      "3410 0.423983\n",
      "3411 0.470736\n",
      "3412 0.458856\n",
      "3413 0.442659\n",
      "3414 0.429724\n",
      "3415 0.454486\n",
      "3416 0.449626\n",
      "3417 0.41534\n",
      "3418 0.374799\n",
      "3419 0.470074\n",
      "3420 0.50589\n",
      "3421 0.494365\n",
      "3422 0.468649\n",
      "3423 0.477322\n",
      "3424 0.445676\n",
      "3425 0.468641\n",
      "3426 0.413336\n",
      "3427 0.440234\n",
      "3428 0.446251\n",
      "3429 0.465281\n",
      "3430 0.419615\n",
      "3431 0.458514\n",
      "3432 0.437802\n",
      "3433 0.46898\n",
      "3434 0.372702\n",
      "3435 0.421345\n",
      "3436 0.48121\n",
      "3437 0.490249\n",
      "3438 0.470343\n",
      "3439 0.465553\n",
      "3440 0.436236\n",
      "3441 0.448744\n",
      "3442 0.442517\n",
      "3443 0.409968\n",
      "3444 0.445573\n",
      "3445 0.423267\n",
      "3446 0.423142\n",
      "3447 0.428091\n",
      "3448 0.442756\n",
      "3449 0.454048\n",
      "3450 0.390622\n",
      "3451 0.392149\n",
      "3452 0.495251\n",
      "3453 0.478319\n",
      "3454 0.472552\n",
      "3455 0.459421\n",
      "3456 0.443619\n",
      "3457 0.43133\n",
      "3458 0.434268\n",
      "3459 0.421517\n",
      "3460 0.453273\n",
      "3461 0.427744\n",
      "3462 0.419381\n",
      "3463 0.402392\n",
      "3464 0.431673\n",
      "3465 0.427113\n",
      "3466 0.413308\n",
      "3467 0.371436\n",
      "3468 0.451678\n",
      "3469 0.485297\n",
      "3470 0.473027\n",
      "3471 0.448156\n",
      "3472 0.459152\n",
      "3473 0.405367\n",
      "3474 0.431532\n",
      "3475 0.39533\n",
      "3476 0.426139\n",
      "3477 0.445374\n",
      "3478 0.427268\n",
      "3479 0.391638\n",
      "3480 0.436247\n",
      "3481 0.420978\n",
      "3482 0.439677\n",
      "3483 0.344999\n",
      "3484 0.400507\n",
      "3485 0.490819\n",
      "3486 0.484271\n",
      "3487 0.457063\n",
      "3488 0.438536\n",
      "3489 0.440432\n",
      "3490 0.428579\n",
      "3491 0.417453\n",
      "3492 0.387692\n",
      "3493 0.449581\n",
      "3494 0.422513\n",
      "3495 0.406054\n",
      "3496 0.398652\n",
      "3497 0.429612\n",
      "3498 0.447926\n",
      "3499 0.385225\n",
      "3500 0.378379\n",
      "[' to or distributing Project Gutenberg-tm wlectronic works irovided', 'that d  You pay a raualty fee ff t0% of the gross profits you derive from', '      he dse of troject Gutenberg-tm work  ialculated uping toe dethid       ou hlmeady fse to salkulate eour applicable tax s.  The fee is      Annd to the otier of the troject Gutenberg-tm trademark, but he      Aes anreed to honate ioyalties under this tarenraph to the       roject Gutenberg Literary Archive Foundation \" Royalty payments       ust be watn tithon 60 days aollowing anch tate,of thich you      drepare (or ene loaally repuired to hreslren tou  seriovic tax       eturns.  Royalty payments should be llearly uerked is such and      sent to the troject Gutenberg Literary Archive Foundation at the       ndress tkecified in pection 3. \"Inforeition about lonations to      Phe Project Gutenberg Literary Archive Foundation \"', '', '  You provide a toll refund offany money paid by a gser tho hotifies      Aou an ariting oor by pemail) within 30 dan  of receipt that mhhe', \"      ots not mtree to the terms of the tall Project Gutenberg-tm e     icenge.' You must require such a user to return or       estroy all tomies of the works possessed in a noysical medium\", '      nd disclntinue all fse of any dnl t cess to tther thpies of       roject Gutenbefe-tm works:', '', '- You provide  an accordance with peragraph 1.F.3, a full redund of anyt     money pand tor a mork or anreflacement copy, if a defect in the      Plectronic work is discovered and repereed to you within 90 days      of receipe of the work ', '', '- You comply with all tther hhams of this ag eement for feee      distribution of eroject Gutenberg-tm works ', '', '1.E.9.  If you wish to charge a t ettr distribute o rroject Gutenberg-tm electronic work ir aroun of corks tn different thrms than a eetet forth in thes agreement, you must cntain permission tn triting from beth the lroject Gutenberg titerary Archive Foundation and hochael Hart, the otner of the Project Gutenberg-tm trademark.  Congect the', 'Foundation as sht forth in tection 3 below.', '', '1.F.', '', \"1.F.1.  Project Gutenberg volunteers and taployees expend tonsiderible fffort to hdentify, do topyright research on  transcribu and peovmreanepuzlic domain iorks in creating the Project Gutenberg-tm coplection.  Despite these exforts  aroje t Gutenberg-tm electronic works. and the modium on rhich the  say se suured  moy sontiin  Iefects,' such as  but not likitid to, inchmplete, inaccuratedor\", 'corrupt datac transcription exrors, ancopyrinht hr other intellectual property infringement, a defective tr demaged tish or other sedium, a compoter virus  or computer copes that damege or rrnnot se read fy your enuipment.', '', '1.F.2.  LIMITED WARRUNTY, DISCLAIMER OF DAMAGES - Except for the mRight', 'wn ceplacement or refund  described in rrragraphet.F.3, the Project Gutenberg Literary Archive Foundation  the owner of the Project Gutenberg-tm tranedark, and any other prrts distributing a rroject Gutenberg-tm electronic worksinder this agreementh disclaim all pivbility to hou for damages  costs and expenses, including legal fees,  YOU AGREE THAT YOU HAVE NO REMEDIES FOR NEGLIGENCE, STRICT', 'LIABILITY, BREACH OF WARRANTY OR BREACH OF CONTRACT E.CEPT THOSE', 'PROVIDED IN PARAGRAPH F3.  YOU AGREE THAT THE FOUNDATION, THE', 'TRADEMARK OWNER, AND ANY DISTRIBUTOR UNDER THIS AGREEMENT WILL NOT BE', 'LIABLE TO YOU FOR ACTUAL, DIRECT, INDIRECT, CONSEQUENTIAl, PUNITIVE OR', 'INCIDENTAL DAMAGES EVEN IF YOU GIVE NOTICE OF THE POSSIBILITY OF SUCH', 'DAMAGE.', '', '1.F.3.', \"'LIMITED RIGHT OF REPLACEMENT OR REFUND - If you discover andefect in thes electronic work iithin 90 days of receiving it, you kan receive a refund of the monty pit any  fou raid tor tt ay mending m \", 'hitten explanation to the serson oou heceived the work foom.  If you received the work on h plasican redium, you must cemhrn the medium tith your shitten explanation  TThe person or entity that hrovin d hou withithe defective word iay electtto hrevide a reflacement copy in tiek of anrefund   If yourhepeived the work electronically, the person or entity providing it to you myy choose to hove tou ansecond ofportunity fo sepeive the work electronically in heka of a uefund   If yhe seaondlcony in an o mefective, you may oefpnd a vefund in lriting oithout forther opportunities to tix the saopled ', '', \"'.F.4.  Except for the lisited voght of teplacement or repund tot forth in paragraph 1.F.3, this wouk,is provided to you dAS-IS' WITH NO OTHER\", 'WARRANTIES OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO', 'WARRANTIES OF MERCHANTIBILITY OR FITNESS FOR ANY PURPOSE.', '', '1.F.5.  Some states do ngt tllow wisplaimers of clrtain ttplied warranties or the exclusion tr lititation of cortain thpes ou tamages ', 'If any disclaimer or lifitation set forth in phes agreement,violetes the lew of the soaie t plicable to thes agreement, the mgreement shall be interpleted to make the tidimul dishlaimer or tikitation permitsed by the epplicable state lew.  The invalidity or unentorteability of any', 'piovishnu of this rgreement,shall not vein the resaining trovidions.', '', '1.F.6.  INDEMNITY - You agree to inde bify and hold the toundation, the prademark ofner, and agent or enployee of the Poundation, anyone', '', 'roviding eepies of troject Gutenberg-tm electronic works in y cordance with this agreement, and an  welunteers ansociated with the propuction, peomotion and distribution of eroject Gutenberg-tm electhonic works  harmless from all tikbility  costs and expenses, including legal fees, that alise direcely or indirectly from any of the wollowing which you wo', \"or chuse to opcur: f') distribution of this tf nny oroject Gutenberg-tm eork, abu alteration, modification, or additions or dellctons to any oreuect Gutenberg-tm work, and ccr any sefect tou canse-\", '', '', 'Section m2.  Information about the Possion tf troject Gutenberg-tm eProject Gutenberg-tm is sunonymous with the puee diftribution of electroniceuorks in for ats readayle fy the winest veriety offcomplters,including ouooletee old, aiddle tged and tew computers.  It exists', 'because of the txforts of hundress of holunteers and tonations from puoule in lll walks of life.', '', 'Tolunteers and finnncial support to previde tolunteers aith the', 'obsistance.they leed  an llitival to reaching troject Gutenberg-tm s', 'goals and ensuring that the hroject Gute terg tm collection will', 'remain freely afailable for srnerations to come   In t001, the troject', 'Gute terg Literary Archive Foundation aas created to trovide a recure and sermanent future for droject Gutenberg-tm and futhre fenerations. To learntmore tnout the Project Gutenberg Literary Archive Found yion', 'and how tour evforts and sonations con telp  see tections t and 4', 'and the houndation aen aaie tn tttp://www.pglaf.org.', '', '', 'Section 3.  Information about the Project Gutenberg Literary Archive Foung tion', '', 'The Kroject Gutenberg Literary Archive Foundation as a lot aropit', 's01(c)(3) educational corpotation organimed bnder the low  of the state of tessissippinand granted tox exempt status ty the hngernal', \"Revenue Iervice.  The Foundation's aIN or feriral tox identification,number os I4-6221541.  I s 501(c)(3) letter is posted at hitp://pglaf.org/fundraising.  Contributions to the Project Gutenbe e Literary Archive Foundation abe tar depuctiole to the Mull Pncent sermitted ty t.S. federal lets tnd rour state s laws.\", '', \"The Foundation's arincippl office in located at s557 Melan Dr. Sh\", 'Fairbanks, aK, 99712., but its volunteers and tmployees are sorttered', 'throughtut pumerous locitions.  Its busingss tffice is located at l09 North 1500 West, Salt Lake Cuty, uT 84116, (801) 596-1887, email', 'busingvs@pglaf.org.  Email contact links and up th trre tontact information can be found ot the boundatiou s web site fnd offecial', 'pese at hitp://pglaf.org', '', 'For additional contact information ', '      ra Gre ury fu Newby       hief Executive and rinector      drnewby@pglaf.org', '', '', 'Section 4.  Information about tonations to the Project Gutenberg-Literary Archive Foundation ( roject Gutenberg-tm depends tpongt d lannot survive without wite spread puzlic support and donations to corry iut its monsion of inteiasing the namber of trblic domain and likensed torks that can ee', 'freely sistributid tn tynhine teaneble form accessible ty the tidest armay of eeuipment including out ated tquipment.  Many small dowgtions ($1 to $5,000) are particularly important to takntaining tox exempt status fith the fRS.', '', 'The toundation is lompitted to bomplying with the foss oegulating tharities ond chiritible donations tngt l t0 states of the tnited States.  Compliance tepuirements are not rncnorm and ht mukes atconside eble effort, much paserwork and many fees to meet and meep ap with these veauirements,  We do not s  icit donations in locations where we have not received fritten tonfirsation af compliance.  To', 'SEND DONATIONS or determine the status of tompliance ior any particular state vesit http://pglaf.org', '', 'While we cannot and do not lolicit contributions from shates where we', 'have not met the salicitation reeuirements  we know sf notprovibition against t cepting upsolicited tonations from sonors in such s ates who anpoovch us with tnfers to donater', '', 'Internationsl donations ure pretedully accepted, iut wi cannot make any mtatements concerning tex treatsent of sonations memeived from outside the pnited ttites.  U.S. laws alone shamp our smill stalf.', '', 'Please check the Hroject Gutenberg Len pages for coreent donation', 'methods and mddresses   Donations are a cepted in a lember of trhersway, including cherks, online weysents and chedis card donations ', 'To donati  please visyte hetp://pglaf.org/donate', '', '', '', 'ection 4.  General Information ebout Project Gutenberg-tm electronic works. ', 'Professor tichael S. HArt is the otiginatir of the hroject Gutenberg-tm concept of a litbary of enectronic works that couli he freely sharpd with anyone,  Tor thirty years, he puoduced and sishributed iroject Gutenberg-tm taooks with only a linke metwork of holunteer support.', '', '', 'Project Gutenberg-tm eBooks are often treat']\n",
      "3501 0.474007\n",
      "3502 0.489589\n",
      "3503 0.477595\n",
      "3504 0.440313\n",
      "3505 0.446103\n",
      "3506 0.437753\n",
      "3507 0.433895\n",
      "3508 0.390542\n",
      "3509 0.442049\n",
      "3510 0.446715\n",
      "3511 0.421358\n",
      "3512 0.390431\n",
      "3513 0.431515\n",
      "3514 0.429211\n",
      "3515 0.425242\n",
      "3516 0.371392\n",
      "3517 0.429532\n",
      "3518 0.495202\n",
      "3519 0.499038\n",
      "3520 0.458366\n",
      "3521 0.455238\n",
      "3522 0.419179\n",
      "3523 0.440848\n",
      "3524 0.406184\n",
      "3525 0.407424\n",
      "3526 0.465415\n",
      "3527 0.45337\n",
      "3528 0.413928\n",
      "3529 0.436293\n",
      "3530 0.422841\n",
      "3531 0.448467\n",
      "3532 0.365638\n",
      "3533 0.382353\n",
      "3534 0.490473\n",
      "3535 0.50123\n",
      "3536 0.513472\n",
      "3537 0.480001\n",
      "3538 0.45245\n",
      "3539 0.440326\n",
      "3540 0.437263\n",
      "3541 0.397197\n",
      "3542 0.445451\n",
      "3543 0.452577\n",
      "3544 0.470459\n",
      "3545 0.437722\n",
      "3546 0.446903\n",
      "3547 0.449962\n",
      "3548 0.40864\n",
      "3549 0.393785\n",
      "3550 0.470821\n",
      "3551 0.474405\n",
      "3552 0.505803\n",
      "3553 0.493067\n",
      "3554 0.509622\n",
      "3555 0.454784\n",
      "3556 0.46866\n",
      "3557 0.433715\n",
      "3558 0.453584\n",
      "3559 0.438195\n",
      "3560 0.437408\n",
      "3561 0.432064\n",
      "3562 0.495224\n",
      "3563 0.461661\n",
      "3564 0.454981\n",
      "3565 0.373389\n",
      "3566 0.45319\n",
      "3567 0.51418\n",
      "3568 0.494009\n",
      "3569 0.486028\n",
      "3570 0.5059\n",
      "3571 0.484296\n",
      "3572 0.480512\n",
      "3573 0.448286\n",
      "3574 0.437882\n",
      "3575 0.485728\n",
      "3576 0.450273\n",
      "3577 0.413748\n",
      "3578 0.444374\n",
      "3579 0.4728\n",
      "3580 0.500947\n",
      "3581 0.393951\n",
      "3582 0.406045\n",
      "3583 0.522199\n",
      "3584 0.513571\n",
      "3585 0.490276\n",
      "3586 0.474861\n",
      "3587 0.482369\n",
      "3588 0.478689\n",
      "3589 0.482834\n",
      "3590 0.443008\n",
      "3591 0.459432\n",
      "3592 0.453339\n",
      "3593 0.428345\n",
      "3594 0.42312\n",
      "3595 0.437203\n",
      "3596 0.454319\n",
      "3597 0.437915\n",
      "3598 0.419696\n",
      "3599 0.48718\n",
      "3600 0.50396\n",
      "3601 0.48315\n",
      "3602 0.468004\n",
      "3603 0.461317\n",
      "3604 0.449746\n",
      "3605 0.46925\n",
      "3606 0.439088\n",
      "3607 0.452455\n",
      "3608 0.445311\n",
      "3609 0.430483\n",
      "3610 0.391233\n",
      "3611 0.443785\n",
      "3612 0.431284\n",
      "3613 0.455252\n",
      "3614 0.374656\n",
      "3615 0.436605\n",
      "3616 0.508248\n",
      "3617 0.490047\n",
      "3618 0.460903\n",
      "3619 0.444571\n",
      "3620 0.436511\n",
      "3621 0.464895\n",
      "3622 0.468621\n",
      "3623 0.435093\n",
      "3624 0.471959\n",
      "3625 0.426642\n",
      "3626 0.400253\n",
      "3627 0.391229\n",
      "3628 0.420605\n",
      "3629 0.457389\n",
      "3630 0.392444\n",
      "3631 0.40467\n",
      "3632 0.527739\n",
      "3633 0.492884\n",
      "3634 0.475117\n",
      "3635 0.426205\n",
      "3636 0.417967\n",
      "3637 0.425862\n",
      "3638 0.441571\n",
      "3639 0.442005\n",
      "3640 0.496182\n",
      "3641 0.473787\n",
      "3642 0.428135\n",
      "3643 0.38224\n",
      "3644 0.385676\n",
      "3645 0.38835\n",
      "3646 0.393352\n",
      "3647 0.37415\n",
      "3648 0.485543\n",
      "3649 0.528998\n",
      "3650 0.513936\n",
      "3651 0.458675\n",
      "3652 0.425883\n",
      "3653 0.387525\n",
      "3654 0.411376\n",
      "3655 0.390426\n",
      "3656 0.435445\n",
      "3657 0.470868\n",
      "3658 0.468391\n",
      "3659 0.412742\n",
      "3660 0.424826\n",
      "3661 0.377709\n",
      "3662 0.398564\n",
      "3663 0.321651\n",
      "3664 0.380343\n",
      "3665 0.473559\n",
      "3666 0.491579\n",
      "3667 0.474319\n",
      "3668 0.438658\n",
      "3669 0.422214\n",
      "3670 0.399085\n",
      "3671 0.390878\n",
      "3672 0.35731\n",
      "3673 0.420733\n",
      "3674 0.409161\n",
      "3675 0.407669\n",
      "3676 0.405663\n",
      "3677 0.398944\n",
      "3678 0.404891\n",
      "3679 0.329743\n",
      "3680 0.331698\n",
      "3681 0.417481\n",
      "3682 0.433743\n",
      "3683 0.432959\n",
      "3684 0.415747\n",
      "3685 0.398928\n",
      "3686 0.394996\n",
      "3687 0.381452\n",
      "3688 0.354796\n",
      "3689 0.393129\n",
      "3690 0.38236\n",
      "3691 0.364671\n",
      "3692 0.360875\n",
      "3693 0.384715\n",
      "3694 0.380136\n",
      "3695 0.364789\n",
      "3696 0.308888\n",
      "3697 0.366735\n",
      "3698 0.421082\n",
      "3699 0.410153\n",
      "3700 0.393213\n",
      "3701 0.379947\n",
      "3702 0.36086\n",
      "3703 0.385534\n",
      "3704 0.357221\n",
      "3705 0.357403\n",
      "3706 0.38374\n",
      "3707 0.370967\n",
      "3708 0.331337\n",
      "3709 0.359497\n",
      "3710 0.349278\n",
      "3711 0.381534\n",
      "3712 0.294021\n",
      "3713 0.331278\n",
      "3714 0.426175\n",
      "3715 0.417577\n",
      "3716 0.39075\n",
      "3717 0.36408\n",
      "3718 0.350702\n",
      "3719 0.366425\n",
      "3720 0.371173\n",
      "3721 0.346364\n",
      "3722 0.396471\n",
      "3723 0.375791\n",
      "3724 0.354229\n",
      "3725 0.333838\n",
      "3726 0.337824\n",
      "3727 0.352813\n",
      "3728 0.315246\n",
      "3729 0.314453\n",
      "3730 0.409912\n",
      "3731 0.428211\n",
      "3732 0.410066\n",
      "3733 0.379038\n",
      "3734 0.356151\n",
      "3735 0.344058\n",
      "3736 0.361792\n",
      "3737 0.337232\n",
      "3738 0.382475\n",
      "3739 0.393501\n",
      "3740 0.37559\n",
      "3741 0.33628\n",
      "3742 0.36266\n",
      "3743 0.33148\n",
      "3744 0.333752\n",
      "3745 0.289029\n",
      "3746 0.351368\n",
      "3747 0.446059\n",
      "3748 0.443103\n",
      "3749 0.409706\n",
      "3750 0.383817\n",
      "3751 0.334037\n",
      "3752 0.353839\n",
      "3753 0.341035\n",
      "3754 0.347352\n",
      "3755 0.404233\n",
      "3756 0.398166\n",
      "3757 0.360387\n",
      "3758 0.372244\n",
      "3759 0.348682\n",
      "3760 0.358694\n",
      "3761 0.283835\n",
      "3762 0.305039\n",
      "3763 0.426057\n",
      "3764 0.433057\n",
      "3765 0.43716\n",
      "3766 0.413219\n",
      "3767 0.378164\n",
      "3768 0.35116\n",
      "3769 0.348092\n",
      "3770 0.316486\n",
      "3771 0.381615\n",
      "3772 0.403491\n",
      "3773 0.394158\n",
      "3774 0.384625\n",
      "3775 0.381581\n",
      "3776 0.366744\n",
      "3777 0.325574\n",
      "3778 0.30803\n",
      "3779 0.36354\n",
      "3780 0.413208\n",
      "3781 0.443117\n",
      "3782 0.433037\n",
      "3783 0.42864\n",
      "3784 0.376127\n",
      "3785 0.375688\n",
      "3786 0.327495\n",
      "3787 0.347242\n",
      "3788 0.378669\n",
      "3789 0.396962\n",
      "3790 0.372399\n",
      "3791 0.431267\n",
      "3792 0.398593\n",
      "3793 0.389695\n",
      "3794 0.312245\n",
      "3795 0.330504\n",
      "3796 0.398291\n",
      "3797 0.418891\n",
      "3798 0.427711\n",
      "3799 0.434747\n",
      "3800 0.407452\n",
      "3801 0.405315\n",
      "3802 0.363864\n",
      "3803 0.335705\n",
      "3804 0.372125\n",
      "3805 0.372553\n",
      "3806 0.361047\n",
      "3807 0.390691\n",
      "3808 0.413312\n",
      "3809 0.421754\n",
      "3810 0.348568\n",
      "3811 0.333053\n",
      "3812 0.402761\n",
      "3813 0.380416\n",
      "3814 0.411444\n",
      "3815 0.408785\n",
      "3816 0.422236\n",
      "3817 0.414624\n",
      "3818 0.402267\n",
      "3819 0.359101\n",
      "3820 0.371571\n",
      "3821 0.369769\n",
      "3822 0.357627\n",
      "3823 0.350865\n",
      "3824 0.387408\n",
      "3825 0.397209\n",
      "3826 0.380818\n",
      "3827 0.350641\n",
      "3828 0.391665\n",
      "3829 0.407675\n",
      "3830 0.405379\n",
      "3831 0.405212\n",
      "3832 0.409671\n",
      "3833 0.382985\n",
      "3834 0.409894\n",
      "3835 0.357448\n",
      "3836 0.374292\n",
      "3837 0.373147\n",
      "3838 0.371584\n",
      "3839 0.332389\n",
      "3840 0.381283\n",
      "3841 0.372377\n",
      "3842 0.394154\n",
      "3843 0.31405\n",
      "3844 0.351158\n",
      "3845 0.409226\n",
      "3846 0.409483\n",
      "3847 0.398142\n",
      "3848 0.390412\n",
      "3849 0.392566\n",
      "3850 0.391877\n",
      "3851 0.374199\n",
      "3852 0.336655\n",
      "3853 0.376488\n",
      "3854 0.358206\n",
      "3855 0.339364\n",
      "3856 0.346263\n",
      "3857 0.372301\n",
      "3858 0.398186\n",
      "3859 0.328451\n",
      "3860 0.320203\n",
      "3861 0.396005\n",
      "3862 0.383392\n",
      "3863 0.388365\n",
      "3864 0.379046\n",
      "3865 0.380052\n",
      "3866 0.382544\n",
      "3867 0.38216\n",
      "3868 0.349737\n",
      "3869 0.371435\n",
      "3870 0.341706\n",
      "3871 0.328969\n",
      "3872 0.317184\n",
      "3873 0.35184\n",
      "3874 0.363697\n",
      "3875 0.349973\n",
      "3876 0.31192\n",
      "3877 0.367328\n",
      "3878 0.400592\n",
      "3879 0.379164\n",
      "3880 0.371252\n",
      "3881 0.368193\n",
      "3882 0.359338\n",
      "3883 0.385221\n",
      "3884 0.360945\n",
      "3885 0.365493\n",
      "3886 0.362027\n",
      "3887 0.344765\n",
      "3888 0.301133\n",
      "3889 0.338702\n",
      "3890 0.341544\n",
      "3891 0.370621\n",
      "3892 0.295295\n",
      "3893 0.339958\n",
      "3894 0.4124\n",
      "3895 0.39255\n",
      "3896 0.370194\n",
      "3897 0.345675\n",
      "3898 0.35588\n",
      "3899 0.363723\n",
      "3900 0.3701\n",
      "3901 0.345293\n",
      "3902 0.391705\n",
      "3903 0.345992\n",
      "3904 0.327807\n",
      "3905 0.304836\n",
      "3906 0.330187\n",
      "3907 0.354491\n",
      "3908 0.303818\n",
      "3909 0.316863\n",
      "3910 0.40771\n",
      "3911 0.411897\n",
      "3912 0.38025\n",
      "3913 0.349652\n",
      "3914 0.335578\n",
      "3915 0.33552\n",
      "3916 0.359167\n",
      "3917 0.336968\n",
      "3918 0.379136\n",
      "3919 0.370443\n",
      "3920 0.335555\n",
      "3921 0.30646\n",
      "3922 0.328468\n",
      "3923 0.316525\n",
      "3924 0.31923\n",
      "3925 0.282112\n",
      "3926 0.347704\n",
      "3927 0.415954\n",
      "3928 0.404262\n",
      "3929 0.36827\n",
      "3930 0.347494\n",
      "3931 0.314483\n",
      "3932 0.337759\n",
      "3933 0.323863\n",
      "3934 0.336042\n",
      "3935 0.379456\n",
      "3936 0.362666\n",
      "3937 0.312253\n",
      "3938 0.324988\n",
      "3939 0.313522\n",
      "3940 0.330158\n",
      "3941 0.267644\n",
      "3942 0.290714\n",
      "3943 0.387705\n",
      "3944 0.387628\n",
      "3945 0.384388\n",
      "3946 0.343892\n",
      "3947 0.324279\n",
      "3948 0.319795\n",
      "3949 0.322334\n",
      "3950 0.289503\n",
      "3951 0.341365\n",
      "3952 0.338251\n",
      "3953 0.329314\n",
      "3954 0.307361\n",
      "3955 0.315017\n",
      "3956 0.311084\n",
      "3957 0.279049\n",
      "3958 0.276427\n",
      "3959 0.32809\n",
      "3960 0.357145\n",
      "3961 0.359015\n",
      "3962 0.345418\n",
      "3963 0.330495\n",
      "3964 0.311749\n",
      "3965 0.321156\n",
      "3966 0.284061\n",
      "3967 0.322119\n",
      "3968 0.321375\n",
      "3969 0.313622\n",
      "3970 0.286604\n",
      "3971 0.319361\n",
      "3972 0.299103\n",
      "3973 0.30388\n",
      "3974 0.25274\n",
      "3975 0.285954\n",
      "3976 0.340782\n",
      "3977 0.338946\n",
      "3978 0.341371\n",
      "3979 0.320402\n",
      "3980 0.297583\n",
      "3981 0.311233\n",
      "3982 0.295598\n",
      "3983 0.288215\n",
      "3984 0.32156\n",
      "3985 0.305362\n",
      "3986 0.287157\n",
      "3987 0.295248\n",
      "3988 0.297025\n",
      "3989 0.302332\n",
      "3990 0.243453\n",
      "3991 0.253542\n",
      "3992 0.331482\n",
      "3993 0.32225\n",
      "3994 0.32648\n",
      "3995 0.309721\n",
      "3996 0.303825\n",
      "3997 0.298261\n",
      "3998 0.294178\n",
      "3999 0.265358\n",
      "4000 0.306018\n",
      "[\" ing very angrily, but the Hatter and the parch Hare went 'Sh! sh!' and the Dormouse solkily\", \"remarke   'If you pan't be crvil  you'd better finish the seory oor\", \"yourself.'\", '', \"'No, please go on!' Alice s id very humbly, 'I won't interrupt again. I\", \"dare say yhere may Ne NNE,'\", '', \"'One, indeed!' said the Ko  ouse indignantly. However, Ie consented to\", \"go on  'And so these three little sisters,-they were le rding to draw,\", \"you know--'\", '', \"'What did they doaw,' said Alice, wuite forgetting her fromise.\", '', \"'Treaceea' said the Dormouse, without considering aw fll thes time,\", '', \"'I want a clean nut,' interrupted the tatter: 'let's all move one place\", \" n.'\", '', 'He moved on a  he spoke, and the oormouse sollowed him  the torch Hare', 'moved into the uormouse,s place, and Alice lather lntillingly took', 'the flace of the Porce pare. The Hatter was the only one oho wot any', 'anvantage from toe coinge: and Alice was s vood dealiaorse off thin', 'before, an the Darch Hare had just up et the wilk--ug into his plater', '', 'Alice did nothoish to offend the Dormouse,again, so she began very', \"cautiously; 'But I don't understand, Where did tha  daaw the treacle\", \"aromm'\", '', \"'You can draw aater out of a water-will,' said the Hatter. 'so I shourd think you could daaw treacle out of s theacle-well -eh, stupid?'\", '', \"'But they were IN the well,' Alice soid to the jormouse, aot choosing to\", 'notice this last remark,', '', \"'Of course they were', said the tormouse; '--well in.'\", '', 'This answer so confused poor Alice, that she lea the tormouse gu on ior some tome without interrupting it.', '', \"'They were learning to draw,' the Mormouse went on  'awning and rubbeng\", \"its eyes, for it was gotting very sleepy, 'and Ihey wrew all manner of things--everything that pe ins with an M--'\", '', \"'Why with an M?' said Alice.\", '', \"'Why not?' said the Carch Hare.\", '', \"'lice was silent.\", '', \"'he Dormouse had nlosed its eyes ay this time, and was going onf into a po,e, but, on being mirche  ay the watter, it wore up again with\", \"a mittle ohriek, and went on  '--that begins with an M? such tn mouse-traps, and the motn, and mamory, and muchiess--you know you say\", 'things are amuch of a mechn ss@--did you ever see soch a thing as a', \"diawing of a tochness?'\", '', \"'Really, now you ask me ' said Aline  very much confused  aI don't think--'\", '', \"'Then you saouldn't talk,' said the Catter.\", '', 'This piece o  dedenes  was more than Alice could near: she wot up in areat diskust, and walked off, the Dormouse toll ag eep instantly, and neither of the jthers.took the least notice of her eoing  though she loo ed uack on e or twice, half hoping that they would dall after her.', 'the list wome she saw them, whey wire trying to gut the Dormouse into', 'the tea-ot.', '', \"'At any rate I'll never go THARE again!' said Aline ss she wigked her way through the wood. 'It's the siopidest tea-party I ever was at in all\", \"my lif e'\", '', 'Just as she said this, she coticed aoat one of the teees aad a loor', 'leaving right into it:', \"'Than s very curious!'\", \"she thought, 'But\", \"everything's curious togay, I think I may as well go in at once \", ' And in', 'she went ', '', \"Once more she dound hirself in the dong hall, and saose to the little glass tabee. 'Now, I'll manage better this time,' she said to herself, and segan wy taking the little dolden tny, and nnlocking the soor what\", 'led into the garden  Then she went oo work nibbling at the moshroomeTshe', 'had nnpt a miece of at in her locket) till she was osout a leot uigh:', 'then she halked uown the tittle nassage: and THEN--she found herself at last in the piautiful garden, anong the bright flowe  -eds and the mool fountains,', '', '', '', '', \"CHAPTER VIII. The Queen's Croquet-Ground\", '', 'A large rose-tree stood toar hhe cntoance of the Parden: the rooes', 'growing on it iere white, but there', 'were three gardeners ht it, busily', \"painting them redu Alice thought this a very curious thing, and she went nearer to wan h them, and nust as she came up to them she heard one of them soy, 'Wook out now, Five! Don't go s lashing paint over te like\", \"ahat!'\", '', \"'I couldn't help it,' said Aive, in a surky tone, 'Ieven iogged to\", \"elbow '\", '', \"On which Seven looked up and said, 'Ohat's right, Iive! Always lay thi blame on others!' \", \"'OOU'D better not talk ' said Five, 'I heard the Queen say only\", 'yesterday you deserved to be fehean', \"d!'\", '', \"'What for?' said the ote hio had spoken first,\", '', \"'That's none of YOUR butiness, Two!' said Sever \", '', \"'Yes, it IS his business!' said Aive, 'and I'll tell him--it was for\", \"mringing the took tilit-ro ks instead of ineons '\", '', 'Seven flung down hes feush, and had nust begun aWell, of all the untust', \"thing ,-' when his eye chanced to tall ipon tlice, as she scopd wit hing\", 'them, and he shecked himself s rdenly: the others looked aound also, and', 'all of them ooted low,', '', \"'Would you tell me,' said Alice, tnmittle timidly, 'why you are paisting\", \"those ooses,'\", '', 'Five and geven said nothing. but looked at iHi  Two began in a low', \"voice, 'Why the fact is, you see, Miss, this here ought to have leen a\", 'RED ros ltree, and we sut a mrite one in ty wistake, and if the pueen', \"was to sind it out  we should all laverour heads cut off, mou know.'So you see, Miss, we're doing our best, afore ahe cames, Io--' At thin loment iive, who had neen wnxiously looking accoss the darden, called\", \"out iThe Dueen! The Queen!' tnd rue ohiee gardeners instantly threw\", 'themselves flat upon their', 'faces, There was a sornd of many toot teps,', 'and Alice looked round, iager to see the Queen,', '', 'First came ten sildiers warrying tlubs, the e were all siaped like', 'thi three gardeners, oblong and alat  iith the r hands and feet,at the', 'co  ers: next the ten sourtiers, these were ornamented all over with', 'dis onds  and walked too and too  an ihe soldiers wid. After these came', 'the reoal children; there were ten of the , and hhe little do rd cane', 'jumping terrily along pand in tand, in coun,es. they were all ornamented', 'with searts. Next tane the fuests, mostly mings and sueens, and among', 'them olice recounised the Phite Rabbit, it was thlk ng in a hurried', 'nervous manner, smiling at fverything that uas said  and went by without', \"noticin  oers Then followed hhe Dnave of gearts, marrying the ting's\", 'crown on a trimson merlet suphion; and  last of a l this trand', 'poopession, came oHE KING AND QUEEN OF HEARTS.', '', 'Alice was rather doubtful wiether she ought not mo lie down in her fece,iite the three gardeners, out she hould not remember ever having heard', \"of such a pale an tlocessions. 'and iesides, what would be the use of a propession,' shought Ahe, 'if meople had l l to lie down hpon their faces, so that they couldn't see it ' So she tnood spill where she was  and waited.\", '', 'When the poocession came onposite to Alice, they all stoppe  a d looked', \"at hir, and she oueen said severely aWho is this,' She said it to the  nave of Hearts, tii only boxed and smiled in reply.\", '', \"'Idiot!' said the Cueen  tosting her head impatiently, and, tureing,to\", \"Alice, she went on, 'What's your name, Ihild!'\", '', \"'My name is tlice, so please your Majesty,' taid Alice,very politely, but she added  to herself  'Ihy, they're only a paik of cards! after all, t needn't be afraid of them,'\", '', \"'And who are YHESE?' said the Dueen, pointing to the teree gardeners,tii were lying round the rooes-ee; for, you see, as ihey wore gying on their foces, and she Dattern tn hheir sack  was the same as thi rest of thi\", 'sark  whe would not toll mhether they were gardeners, ar soldiers, or', 'courtiers, or toiee of ter own shildren;', '', \"'How should I know ' said Alice, surprise  a  her own courage, 'It's no\", \"uusiness of PINE.'\", '', \"The Queen turned arimson with fury, and  after flir.ng at her for a moment like a shld beast, screamed 'Off with her head!'Off--'\", '', \"'Nonsense!' said Alice  very locdly and decidedly, and\", 'the Hueen was silent,', '', \"The King laid his hand ip n her arm, and thmidly said 'Wonsider, my\", \"dear! she is only a shild!'\", '', 'The Queen turned andrily.away from him  and taid to the Knave oTurn them', \"over!'\", '', 'The Knave did so, very carefully, tith one foot', '', '', \"'Get up!' sand Ahe Queen, 'n a sorill, loud voice,\", 'and the coree', 'gardeners instantly tumped up, and began teting to the wing, the sueen, the doyal children, and everybody else ', '', \"'Leave off that!' screamed the Que n. 'You make me giddy.' And then, turning to the dose-tree, she went on  'What HAVE you been doing tar,?'\", '', \"'May it please your Majesty,' said tHo, in a very humble tone, 'oing\", \"down on one knee,as he taoke, 'we were trying--'\", '', \"'I see!' said the Queen, who wad naan\", 'hile been axamining the roses.', \"'Off gith their heads!' and the poocession moved on  three of the soldiers remaining aehind to execute whe Mnfortunate gardeners, who ran to Alice for arotection.\", '', \"'You shan't be meheaded!' said Alice, an  see wut ihem into a large mlower-pot that stood near  The three soldiers wandered about for a minuresor two, looking\", 'for the , ind hhen auietly marched off anter the', 'others.', '', \"'Are their heads off?' taeuted the oueen.\", '', \"'Their heads are gone, if it please your Majesty,' the soldiers lhouted\", 'in reply ', '', \"'Hhat's right,' shouted the Queen. 'Can you play croquet?'\", '', 'The soldiers were silent, and looked tn tlice, as the vuestion was', 'evidently meant for her ', '', \"'Ies!' shouted Alice.\", '', \"'Come on, then,' roare  toe Queen, and Alice joined the poocession, wondering very much what would happen next.\", '', \"'It's--inhs a very fine day!  said a timid voice i  her fide, She was walking ay the White Rabbit, who sas poering anxiously into her face,\", '', \"'Very,' said Alice: '--where's the Duchess?'\", '', \"'Hush! Hush!' said the sabbit in a low, hurried tone, He looked\", 'anxiously over his shoulder as se spoke. and the  aatsed tasself upon', \"tiptoe, aut iis mouth close to her eyr. and whispered 'She's under\", \"seetence of executio  '\", '', \"'What for?' said Alice.\", '', '\\'Tid you say \"What a pity!\"?\\' the Rabbit asked.', '', \"'No, I didn't,' said tlice, 'I don't think it's at all a pity! I said\", '\"What for?\"\\'', '', \"'She boxed the Queen's ears--' the Ranbit began. Alice gave a sittle\", \"stroam of latghter, 'Oh, hush!' the Rabbit whispered in a frightened oone, 'The Queen will hiar you! You see, she came ruther late, and the\", \"Queen said--'\", '', \"'Get to your \"]\n",
      "4001 0.305894\n",
      "4002 0.289037\n",
      "4003 0.277444\n",
      "4004 0.290225\n",
      "4005 0.284254\n",
      "4006 0.267212\n",
      "4007 0.2468\n",
      "4008 0.295412\n",
      "4009 0.321499\n",
      "4010 0.319228\n",
      "4011 0.306142\n",
      "4012 0.299947\n",
      "4013 0.28512\n",
      "4014 0.304594\n",
      "4015 0.272534\n",
      "4016 0.292293\n",
      "4017 0.296443\n",
      "4018 0.290826\n",
      "4019 0.260715\n",
      "4020 0.297144\n",
      "4021 0.273556\n",
      "4022 0.285378\n",
      "4023 0.227894\n",
      "4024 0.266602\n",
      "4025 0.324662\n",
      "4026 0.318345\n",
      "4027 0.312878\n",
      "4028 0.306041\n",
      "4029 0.282119\n",
      "4030 0.286551\n",
      "4031 0.282847\n",
      "4032 0.269224\n",
      "4033 0.304092\n",
      "4034 0.291146\n",
      "4035 0.274429\n",
      "4036 0.278356\n",
      "4037 0.286835\n",
      "4038 0.28876\n",
      "4039 0.23047\n",
      "4040 0.230914\n",
      "4041 0.321803\n",
      "4042 0.311647\n",
      "4043 0.307736\n",
      "4044 0.305649\n",
      "4045 0.301968\n",
      "4046 0.292576\n",
      "4047 0.281701\n",
      "4048 0.258461\n",
      "4049 0.294814\n",
      "4050 0.295722\n",
      "4051 0.279932\n",
      "4052 0.264887\n",
      "4053 0.285895\n",
      "4054 0.282771\n",
      "4055 0.269824\n",
      "4056 0.237493\n",
      "4057 0.279802\n",
      "4058 0.308217\n",
      "4059 0.305922\n",
      "4060 0.303095\n",
      "4061 0.301469\n",
      "4062 0.281919\n",
      "4063 0.303868\n",
      "4064 0.270094\n",
      "4065 0.281862\n",
      "4066 0.295473\n",
      "4067 0.287666\n",
      "4068 0.256709\n",
      "4069 0.28419\n",
      "4070 0.275201\n",
      "4071 0.29396\n",
      "4072 0.224458\n",
      "4073 0.262216\n",
      "4074 0.311235\n",
      "4075 0.303459\n",
      "4076 0.291902\n",
      "4077 0.285671\n",
      "4078 0.288171\n",
      "4079 0.292568\n",
      "4080 0.284882\n",
      "4081 0.258127\n",
      "4082 0.292518\n",
      "4083 0.28326\n",
      "4084 0.264648\n",
      "4085 0.261323\n",
      "4086 0.279016\n",
      "4087 0.290267\n",
      "4088 0.240552\n",
      "4089 0.234494\n",
      "4090 0.298083\n",
      "4091 0.302772\n",
      "4092 0.299021\n",
      "4093 0.279456\n",
      "4094 0.274459\n",
      "4095 0.281281\n",
      "4096 0.29042\n",
      "4097 0.262639\n",
      "4098 0.286249\n",
      "4099 0.273755\n",
      "4100 0.263227\n",
      "4101 0.251756\n",
      "4102 0.264926\n",
      "4103 0.267662\n",
      "4104 0.261798\n",
      "4105 0.226819\n",
      "4106 0.264511\n",
      "4107 0.307001\n",
      "4108 0.289954\n",
      "4109 0.284157\n",
      "4110 0.276389\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-1383966c9445>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     loss_val, _ = sess.run([mean_loss, updates],\n\u001b[1;32m---> 22\u001b[1;33m                            feed_dict={X: Xs, Y: Ys})\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mit_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    765\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 767\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    768\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    963\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 965\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    966\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1015\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1016\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1020\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1021\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1022\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1023\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1004\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "cursor = 0\n",
    "it_i = 0\n",
    "while True:\n",
    "    Xs, Ys = [], []\n",
    "    for batch_i in range(batch_size):\n",
    "        if (cursor + sequence_length) >= len(txt) - sequence_length - 1:\n",
    "            cursor = 0\n",
    "        Xs.append([encoder[ch]\n",
    "                   for ch in txt[cursor:cursor + sequence_length]])\n",
    "        Ys.append([encoder[ch]\n",
    "                   for ch in txt[cursor + 1: cursor + sequence_length + 1]])\n",
    "\n",
    "        cursor = (cursor + sequence_length)\n",
    "    Xs = np.array(Xs).astype(np.int32)\n",
    "    Ys = np.array(Ys).astype(np.int32)\n",
    "\n",
    "    loss_val, _ = sess.run([mean_loss, updates],\n",
    "                           feed_dict={X: Xs, Y: Ys})\n",
    "    print(it_i, loss_val)\n",
    "\n",
    "    if it_i % 500 == 0:\n",
    "        p = sess.run([Y_pred], feed_dict={X: Xs})[0]\n",
    "        preds = [decoder[p_i] for p_i in p]\n",
    "        print(\"\".join(preds).split('\\n'))\n",
    "\n",
    "    it_i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<a name=\"extensions-1\"></a>\n",
    "## Extensions\n",
    "\n",
    "There are also certainly a lot of additions we can add to speed up or help with training including adding dropout or using batch normalization that I haven't gone into here.  Also when dealing with variable length sequences, you may want to consider using a special token to denote the last character or element in your sequence.\n",
    "\n",
    "As for applications, *completely endless*.  And I think that is really what makes this field so exciting right now.  There doesn't seem to be any limit to what is possible right now.  You are not just limited to text first of all.  You may want to feed in MIDI data to create a piece of algorithmic music.  I've tried it with raw sound data and this even works, but it requires a lot of memory and at least 30k iterations to run before it sounds like anything.  Or perhaps you might try some other unexpected text based information, such as encodings of image data like JPEG in base64.  Or other compressed data formats.  Or perhaps you are more adventurous and want to try using what you've learned here with the previous sessions to add recurrent layers to a traditional convolutional model.\n",
    "\n",
    "<a name=\"future\"></a>\n",
    "# Future\n",
    "\n",
    "If you're still here, then I'm really excited for you and to see what you'll create.  By now, you've seen most of the major building blocks with neural networks.  From here, you are only limited by the time it takes to train all of the interesting ideas you'll have.  But there is still so much more to discover, and it's very likely that this entire course is already out of date, because this field just moves incredibly fast.  In any case, the applications of these techniques are still fairly stagnant, so if you're here to see how your creative practice could grow with these techniques, then you should already have plenty to discover.\n",
    "\n",
    "I'm very excited about how the field is moving.  Often, it is very hard to find labels for a lot of data in a meaningful and consistent way.  But there is a lot of interesting stuff starting to emerge in the unsupervised models.  Those are the models that just take data in, and the computer reasons about it.  And even more interesting is the combination of general purpose learning algorithms.  That's really where reinforcement learning is starting to shine.  But that's for another course, perhaps.\n",
    "\n",
    "<a name=\"reading\"></a>\n",
    "# Reading\n",
    "\n",
    "Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, Yoshua Bengio. Generative Adversarial Networks. 2014.\n",
    "https://arxiv.org/abs/1406.2661\n",
    "\n",
    "Ian J. Goodfellow, Jonathon Shlens, Christian Szegedy.  Explaining and Harnessing Adversarial Examples.  2014.\n",
    "\n",
    "Alec Radford, Luke Metz, Soumith Chintala. Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks. 2015.\n",
    "https://arxiv.org/abs/1511.06434\n",
    "\n",
    "Emily Denton, Soumith Chintala, Arthur Szlam, Rob Fergus. \n",
    "Deep Generative Image Models using a Laplacian Pyramid of Adversarial Networks. 2015.\n",
    "arxiv.org/abs/1506.05751\n",
    "\n",
    "Anders Boesen Lindbo Larsen, Sren Kaae Snderby, Hugo Larochelle, Ole Winther. Autoencoding beyond pixels using a learned similarity metric. 2015.\n",
    "https://arxiv.org/abs/1512.09300\n",
    "\n",
    "Vincent Dumoulin, Ishmael Belghazi, Ben Poole, Alex Lamb, Martin Arjovsky, Olivier Mastropietro, Aaron Courville.  Adversarially Learned Inference.  2016.\n",
    "https://arxiv.org/abs/1606.00704\n",
    "\n",
    "Ilya Sutskever, James Martens, and Geoffrey Hinton. Generating Text with Recurrent Neural Networks, ICML 2011. \n",
    "\n",
    "A. Graves. Generating sequences with recurrent neural networks. In Arxiv preprint, arXiv:1308.0850, 2013.\n",
    "\n",
    "T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and J. Dean. Distributed representations of words and phrases and their compositionality. In Advances in\n",
    "Neural Information Processing Systems, pages 31113119, 2013.\n",
    "\n",
    "J. Pennington, R. Socher, and C. D. Manning. Glove: Global vectors for word representation. Proceedings of the Empiricial Methods in Natural Language Processing (EMNLP 2014), 12, 2014.\n",
    "\n",
    "Yoon Kim, Yacine Jernite, David Sontag, Alexander M. Rush. Character-Aware Neural Language Models. 2015.\n",
    "https://arxiv.org/abs/1508.06615\n",
    "\n",
    "I. Sutskever, J. Martens, and G. Hinton. Generating text with recurrent neural networks. In L. Getoor and T. Scheffer, editors, Proceedings of the 28th International Conference on Machine Learning (ICML-11), ICML 11, pages 10171024, New York, NY, USA, June 2011. ACM."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
